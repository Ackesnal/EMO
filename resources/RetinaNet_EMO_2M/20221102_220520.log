2022-11-02 22:05:21,077 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.9.5 (default, Jun  4 2021, 12:28:51) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: Tesla V100-SXM2-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.0, V11.0.221
GCC: gcc (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
PyTorch: 1.10.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2+cu113
OpenCV: 4.5.4
MMCV: 1.6.2
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMDetection: 2.25.2+
------------------------------------------------------------

2022-11-02 22:05:22,282 - mmdet - INFO - Distributed training: True
2022-11-02 22:05:23,193 - mmdet - INFO - Config:
model = dict(
    type='RetinaNet',
    backbone=dict(
        type='MetaMobile',
        depths=[3, 3, 9, 3],
        stem_dim=24,
        embed_dims=[32, 48, 120, 200],
        exp_ratios=[2.0, 2.5, 3.0, 3.5],
        norm_layers=['bn_2d', 'bn_2d', 'ln_2d', 'ln_2d'],
        act_layers=['silu', 'silu', 'gelu', 'gelu'],
        dw_kss=[3, 3, 5, 5],
        group_size=1,
        se_ratios=[0.0, 0.0, 0.0, 0.0],
        dim_heads=[16, 16, 20, 20],
        window_sizes=[7, 7, 7, 7],
        attn_ss=[False, False, True, True],
        attn_s_skips=[False, False, False, False],
        qkv_bias=True,
        attn_drop=0.0,
        drop=0.0,
        drop_path=0.05,
        v_group=False,
        attn_pre=True,
        conv_l=True,
        skip_l=True,
        pre_dim=0,
        sync_bn=True,
        out_indices=(1, 2, 3, 4),
        pretrained='../../ckpt_models/MetaMobile_2M/net_E.pth',
        frozen_stages=1,
        norm_eval=True),
    neck=dict(
        type='FPN',
        in_channels=[32, 48, 120, 200],
        out_channels=256,
        start_level=1,
        add_extra_convs='on_input',
        num_outs=5),
    bbox_head=dict(
        type='RetinaHead',
        num_classes=80,
        in_channels=256,
        stacked_convs=4,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            octave_base_scale=4,
            scales_per_octave=3,
            ratios=[0.5, 1.0, 2.0],
            strides=[8, 16, 32, 64, 128]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    train_cfg=dict(
        assigner=dict(
            type='MaxIoUAssigner',
            pos_iou_thr=0.5,
            neg_iou_thr=0.4,
            min_pos_iou=0,
            ignore_iof_thr=-1),
        allowed_border=-1,
        pos_weight=-1,
        debug=False),
    test_cfg=dict(
        nms_pre=1000,
        min_bbox_size=0,
        score_thr=0.05,
        nms=dict(type='nms', iou_threshold=0.5),
        max_per_img=100))
dataset_type = 'CocoDataset'
data_root = 'data/coco/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_train2017.json',
        img_prefix='data/coco/train2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric='bbox')
optimizer_config = dict(grad_clip=None)
runner = dict(type='EpochBasedRunner', max_epochs=12)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
auto_scale_lr = dict(enable=False, base_batch_size=16)
bs_ratio = 1
optimizer = dict(
    type='AdamW',
    lr=0.0002,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    min_lr=0)
work_dir = './work_dirs/retinanet_metamobile2M_fpn_1x_coco'
auto_resume = False
gpu_ids = range(0, 8)

2022-11-02 22:05:23,195 - mmdet - INFO - Set random seed to 0, deterministic: False
2022-11-02 22:05:24,382 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2022-11-02 22:05:24,463 - mmdet - INFO - initialize RetinaHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'retina_cls', 'std': 0.01, 'bias_prob': 0.01}}
Name of parameter - Initialization information

backbone.stage0.0.convs.0.0.weight - torch.Size([24, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.0.convs.0.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.0.convs.0.1.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.0.convs.0.1.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.conv_local.conv.weight - torch.Size([24, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.conv_local.norm.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.conv_local.norm.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.se.conv_reduce.weight - torch.Size([24, 24, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.se.conv_reduce.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.se.conv_expand.weight - torch.Size([24, 24, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.se.conv_expand.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.proj.conv.weight - torch.Size([24, 24, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.norm.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.norm.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.v.conv.weight - torch.Size([96, 24, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.v.conv.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.conv_local.conv.weight - torch.Size([96, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.conv_local.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.conv_local.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.proj.conv.weight - torch.Size([32, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.norm.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.norm.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.v.conv.weight - torch.Size([64, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.v.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.conv_local.conv.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.conv_local.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.conv_local.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.proj.conv.weight - torch.Size([32, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.norm.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.norm.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.v.conv.weight - torch.Size([64, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.v.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.conv_local.conv.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.conv_local.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.conv_local.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.proj.conv.weight - torch.Size([32, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.norm.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.norm.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.v.conv.weight - torch.Size([160, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.v.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.conv_local.conv.weight - torch.Size([160, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.conv_local.norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.conv_local.norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.proj.conv.weight - torch.Size([48, 160, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.norm.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.norm.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.v.conv.weight - torch.Size([120, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.v.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.conv_local.conv.weight - torch.Size([120, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.conv_local.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.conv_local.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.proj.conv.weight - torch.Size([48, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.norm.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.norm.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.v.conv.weight - torch.Size([120, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.v.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.conv_local.conv.weight - torch.Size([120, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.conv_local.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.conv_local.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.proj.conv.weight - torch.Size([48, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.norm.norm.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.norm.norm.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.v.conv.weight - torch.Size([288, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.v.conv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.conv_local.conv.weight - torch.Size([288, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.conv_local.norm.weight - torch.Size([288]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.conv_local.norm.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.proj.conv.weight - torch.Size([120, 288, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.v.conv.weight - torch.Size([840, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.v.conv.bias - torch.Size([840]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.conv_local.conv.weight - torch.Size([840, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.conv_local.norm.weight - torch.Size([840]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.conv_local.norm.bias - torch.Size([840]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.proj.conv.weight - torch.Size([200, 840, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.norm.norm.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.norm.norm.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.qk.conv.weight - torch.Size([400, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.qk.conv.bias - torch.Size([400]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.v.conv.weight - torch.Size([700, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.v.conv.bias - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.conv_local.conv.weight - torch.Size([700, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.conv_local.norm.weight - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.conv_local.norm.bias - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.proj.conv.weight - torch.Size([200, 700, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.norm.norm.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.norm.norm.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.qk.conv.weight - torch.Size([400, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.qk.conv.bias - torch.Size([400]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.v.conv.weight - torch.Size([700, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.v.conv.bias - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.conv_local.conv.weight - torch.Size([700, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.conv_local.norm.weight - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.conv_local.norm.bias - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.proj.conv.weight - torch.Size([200, 700, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.0.conv.weight - torch.Size([256, 48, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.1.conv.weight - torch.Size([256, 120, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.2.conv.weight - torch.Size([256, 200, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.3.conv.weight - torch.Size([256, 200, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.4.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.retina_cls.weight - torch.Size([720, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

bbox_head.retina_cls.bias - torch.Size([720]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

bbox_head.retina_reg.weight - torch.Size([36, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.retina_reg.bias - torch.Size([36]): 
NormalInit: mean=0, std=0.01, bias=0 
2022-11-02 22:06:38,384 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.
2022-11-02 22:06:38,923 - mmdet - INFO - Start running, host: root@ts-678a5febbc40428e926e8b60227da51d-launcher, work_dir: /youtu_fuxi_team1_ceph/vtzhang/codes/pts_cls/down-stream-tasks/mmdetection/work_dirs/retinanet_metamobile2M_fpn_1x_coco
2022-11-02 22:06:38,923 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) NumClassCheckHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-11-02 22:06:38,924 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs
2022-11-02 22:06:38,924 - mmdet - INFO - Checkpoints will be saved to /youtu_fuxi_team1_ceph/vtzhang/codes/pts_cls/down-stream-tasks/mmdetection/work_dirs/retinanet_metamobile2M_fpn_1x_coco by HardDiskBackend.
2022-11-02 22:07:10,524 - mmdet - INFO - Epoch [1][50/3665]	lr: 1.978e-05, eta: 7:42:17, time: 0.631, data_time: 0.081, memory: 5275, loss_cls: 1.1922, loss_bbox: 0.6900, loss: 1.8822
2022-11-02 22:07:36,579 - mmdet - INFO - Epoch [1][100/3665]	lr: 3.976e-05, eta: 7:01:20, time: 0.521, data_time: 0.015, memory: 5275, loss_cls: 1.0111, loss_bbox: 0.6705, loss: 1.6816
2022-11-02 22:08:02,337 - mmdet - INFO - Epoch [1][150/3665]	lr: 5.974e-05, eta: 6:46:00, time: 0.515, data_time: 0.014, memory: 5275, loss_cls: 0.8478, loss_bbox: 0.6018, loss: 1.4496
2022-11-02 22:08:27,488 - mmdet - INFO - Epoch [1][200/3665]	lr: 7.972e-05, eta: 6:35:55, time: 0.503, data_time: 0.014, memory: 5275, loss_cls: 0.8137, loss_bbox: 0.5521, loss: 1.3658
2022-11-02 22:08:52,961 - mmdet - INFO - Epoch [1][250/3665]	lr: 9.970e-05, eta: 6:30:40, time: 0.510, data_time: 0.014, memory: 5275, loss_cls: 0.7735, loss_bbox: 0.5266, loss: 1.3001
2022-11-02 22:09:17,653 - mmdet - INFO - Epoch [1][300/3665]	lr: 1.197e-04, eta: 6:25:06, time: 0.494, data_time: 0.014, memory: 5275, loss_cls: 0.7667, loss_bbox: 0.5070, loss: 1.2737
2022-11-02 22:09:42,906 - mmdet - INFO - Epoch [1][350/3665]	lr: 1.397e-04, eta: 6:22:10, time: 0.505, data_time: 0.013, memory: 5275, loss_cls: 0.7021, loss_bbox: 0.4892, loss: 1.1913
2022-11-02 22:10:07,342 - mmdet - INFO - Epoch [1][400/3665]	lr: 1.596e-04, eta: 6:18:23, time: 0.489, data_time: 0.014, memory: 5275, loss_cls: 0.6596, loss_bbox: 0.4700, loss: 1.1296
2022-11-02 22:10:32,437 - mmdet - INFO - Epoch [1][450/3665]	lr: 1.796e-04, eta: 6:16:25, time: 0.502, data_time: 0.014, memory: 5275, loss_cls: 0.6386, loss_bbox: 0.4653, loss: 1.1039
2022-11-02 22:10:57,664 - mmdet - INFO - Epoch [1][500/3665]	lr: 1.996e-04, eta: 6:14:56, time: 0.504, data_time: 0.015, memory: 5275, loss_cls: 0.6228, loss_bbox: 0.4597, loss: 1.0825
2022-11-02 22:11:23,307 - mmdet - INFO - Epoch [1][550/3665]	lr: 2.000e-04, eta: 6:14:13, time: 0.513, data_time: 0.022, memory: 5275, loss_cls: 0.6151, loss_bbox: 0.4506, loss: 1.0657
2022-11-02 22:11:48,239 - mmdet - INFO - Epoch [1][600/3665]	lr: 2.000e-04, eta: 6:12:40, time: 0.499, data_time: 0.015, memory: 5275, loss_cls: 0.5970, loss_bbox: 0.4427, loss: 1.0398
2022-11-02 22:12:14,084 - mmdet - INFO - Epoch [1][650/3665]	lr: 2.000e-04, eta: 6:12:19, time: 0.517, data_time: 0.015, memory: 5275, loss_cls: 0.5749, loss_bbox: 0.4384, loss: 1.0133
2022-11-02 22:12:54,045 - mmdet - INFO - Epoch [1][700/3665]	lr: 2.000e-04, eta: 6:26:31, time: 0.799, data_time: 0.033, memory: 5275, loss_cls: 0.5761, loss_bbox: 0.4315, loss: 1.0076
2022-11-02 22:13:39,038 - mmdet - INFO - Epoch [1][750/3665]	lr: 2.000e-04, eta: 6:43:34, time: 0.900, data_time: 0.039, memory: 5275, loss_cls: 0.5923, loss_bbox: 0.4278, loss: 1.0202
2022-11-02 22:14:24,197 - mmdet - INFO - Epoch [1][800/3665]	lr: 2.000e-04, eta: 6:58:31, time: 0.903, data_time: 0.038, memory: 5275, loss_cls: 0.5689, loss_bbox: 0.4211, loss: 0.9900
2022-11-02 22:15:08,940 - mmdet - INFO - Epoch [1][850/3665]	lr: 2.000e-04, eta: 7:11:17, time: 0.895, data_time: 0.039, memory: 5275, loss_cls: 0.5312, loss_bbox: 0.4169, loss: 0.9481
2022-11-02 22:15:53,251 - mmdet - INFO - Epoch [1][900/3665]	lr: 2.000e-04, eta: 7:22:12, time: 0.886, data_time: 0.039, memory: 5275, loss_cls: 0.5248, loss_bbox: 0.4171, loss: 0.9419
2022-11-02 22:16:38,222 - mmdet - INFO - Epoch [1][950/3665]	lr: 2.000e-04, eta: 7:32:23, time: 0.899, data_time: 0.039, memory: 5275, loss_cls: 0.5232, loss_bbox: 0.4148, loss: 0.9380
2022-11-02 22:17:23,332 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-02 22:17:23,333 - mmdet - INFO - Epoch [1][1000/3665]	lr: 2.000e-04, eta: 7:41:35, time: 0.902, data_time: 0.038, memory: 5275, loss_cls: 0.5097, loss_bbox: 0.4122, loss: 0.9219
2022-11-02 22:18:07,778 - mmdet - INFO - Epoch [1][1050/3665]	lr: 2.000e-04, eta: 7:49:23, time: 0.889, data_time: 0.039, memory: 5275, loss_cls: 0.5186, loss_bbox: 0.4052, loss: 0.9238
2022-11-02 22:18:52,740 - mmdet - INFO - Epoch [1][1100/3665]	lr: 2.000e-04, eta: 7:56:44, time: 0.899, data_time: 0.038, memory: 5275, loss_cls: 0.5055, loss_bbox: 0.4029, loss: 0.9084
2022-11-02 22:19:37,877 - mmdet - INFO - Epoch [1][1150/3665]	lr: 2.000e-04, eta: 8:03:29, time: 0.903, data_time: 0.040, memory: 5275, loss_cls: 0.5071, loss_bbox: 0.4014, loss: 0.9085
2022-11-02 22:20:23,518 - mmdet - INFO - Epoch [1][1200/3665]	lr: 2.000e-04, eta: 8:09:55, time: 0.913, data_time: 0.042, memory: 5275, loss_cls: 0.4992, loss_bbox: 0.3985, loss: 0.8977
2022-11-02 22:21:08,947 - mmdet - INFO - Epoch [1][1250/3665]	lr: 2.000e-04, eta: 8:15:39, time: 0.909, data_time: 0.042, memory: 5275, loss_cls: 0.5046, loss_bbox: 0.4014, loss: 0.9060
2022-11-02 22:21:55,316 - mmdet - INFO - Epoch [1][1300/3665]	lr: 2.000e-04, eta: 8:21:24, time: 0.927, data_time: 0.028, memory: 5275, loss_cls: 0.5009, loss_bbox: 0.4009, loss: 0.9018
2022-11-02 22:22:42,204 - mmdet - INFO - Epoch [1][1350/3665]	lr: 2.000e-04, eta: 8:26:56, time: 0.938, data_time: 0.013, memory: 5275, loss_cls: 0.4806, loss_bbox: 0.3935, loss: 0.8741
2022-11-02 22:23:28,893 - mmdet - INFO - Epoch [1][1400/3665]	lr: 2.000e-04, eta: 8:31:55, time: 0.934, data_time: 0.013, memory: 5275, loss_cls: 0.4760, loss_bbox: 0.3904, loss: 0.8665
2022-11-02 22:24:16,128 - mmdet - INFO - Epoch [1][1450/3665]	lr: 2.000e-04, eta: 8:36:47, time: 0.945, data_time: 0.013, memory: 5275, loss_cls: 0.4650, loss_bbox: 0.3866, loss: 0.8516
2022-11-02 22:25:02,979 - mmdet - INFO - Epoch [1][1500/3665]	lr: 2.000e-04, eta: 8:41:04, time: 0.937, data_time: 0.014, memory: 5275, loss_cls: 0.4712, loss_bbox: 0.3875, loss: 0.8586
2022-11-02 22:25:49,035 - mmdet - INFO - Epoch [1][1550/3665]	lr: 2.000e-04, eta: 8:44:41, time: 0.921, data_time: 0.014, memory: 5275, loss_cls: 0.4685, loss_bbox: 0.3876, loss: 0.8561
2022-11-02 22:26:36,151 - mmdet - INFO - Epoch [1][1600/3665]	lr: 2.000e-04, eta: 8:48:29, time: 0.942, data_time: 0.013, memory: 5275, loss_cls: 0.4596, loss_bbox: 0.3815, loss: 0.8411
2022-11-02 22:27:23,295 - mmdet - INFO - Epoch [1][1650/3665]	lr: 2.000e-04, eta: 8:52:02, time: 0.943, data_time: 0.013, memory: 5275, loss_cls: 0.4818, loss_bbox: 0.3855, loss: 0.8672
2022-11-02 22:28:09,910 - mmdet - INFO - Epoch [1][1700/3665]	lr: 2.000e-04, eta: 8:55:06, time: 0.933, data_time: 0.034, memory: 5275, loss_cls: 0.4957, loss_bbox: 0.3854, loss: 0.8811
2022-11-02 22:28:56,082 - mmdet - INFO - Epoch [1][1750/3665]	lr: 2.000e-04, eta: 8:57:46, time: 0.923, data_time: 0.040, memory: 5275, loss_cls: 0.4666, loss_bbox: 0.3792, loss: 0.8459
2022-11-02 22:29:42,865 - mmdet - INFO - Epoch [1][1800/3665]	lr: 2.000e-04, eta: 9:00:29, time: 0.936, data_time: 0.041, memory: 5275, loss_cls: 0.4622, loss_bbox: 0.3833, loss: 0.8455
2022-11-02 22:30:29,110 - mmdet - INFO - Epoch [1][1850/3665]	lr: 2.000e-04, eta: 9:02:48, time: 0.925, data_time: 0.039, memory: 5275, loss_cls: 0.4565, loss_bbox: 0.3739, loss: 0.8303
2022-11-02 22:31:15,861 - mmdet - INFO - Epoch [1][1900/3665]	lr: 2.000e-04, eta: 9:05:09, time: 0.935, data_time: 0.040, memory: 5275, loss_cls: 0.4776, loss_bbox: 0.3750, loss: 0.8527
2022-11-02 22:32:01,023 - mmdet - INFO - Epoch [1][1950/3665]	lr: 2.000e-04, eta: 9:06:45, time: 0.903, data_time: 0.021, memory: 5275, loss_cls: 0.4786, loss_bbox: 0.3854, loss: 0.8640
2022-11-02 22:32:45,714 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-02 22:32:45,715 - mmdet - INFO - Epoch [1][2000/3665]	lr: 2.000e-04, eta: 9:08:05, time: 0.894, data_time: 0.017, memory: 5275, loss_cls: 0.4435, loss_bbox: 0.3702, loss: 0.8137
2022-11-02 22:33:29,837 - mmdet - INFO - Epoch [1][2050/3665]	lr: 2.000e-04, eta: 9:09:07, time: 0.883, data_time: 0.017, memory: 5275, loss_cls: 0.4456, loss_bbox: 0.3659, loss: 0.8115
2022-11-02 22:34:14,530 - mmdet - INFO - Epoch [1][2100/3665]	lr: 2.000e-04, eta: 9:10:16, time: 0.894, data_time: 0.016, memory: 5275, loss_cls: 0.4425, loss_bbox: 0.3700, loss: 0.8125
2022-11-02 22:35:01,062 - mmdet - INFO - Epoch [1][2150/3665]	lr: 2.000e-04, eta: 9:11:55, time: 0.931, data_time: 0.014, memory: 5275, loss_cls: 0.4372, loss_bbox: 0.3648, loss: 0.8020
2022-11-02 22:35:47,170 - mmdet - INFO - Epoch [1][2200/3665]	lr: 2.000e-04, eta: 9:13:19, time: 0.922, data_time: 0.014, memory: 5275, loss_cls: 0.4388, loss_bbox: 0.3685, loss: 0.8073
2022-11-02 22:36:33,236 - mmdet - INFO - Epoch [1][2250/3665]	lr: 2.000e-04, eta: 9:14:37, time: 0.921, data_time: 0.014, memory: 5275, loss_cls: 0.4386, loss_bbox: 0.3668, loss: 0.8054
2022-11-02 22:37:18,291 - mmdet - INFO - Epoch [1][2300/3665]	lr: 2.000e-04, eta: 9:15:31, time: 0.901, data_time: 0.014, memory: 5275, loss_cls: 0.4475, loss_bbox: 0.3691, loss: 0.8166
2022-11-02 22:38:03,752 - mmdet - INFO - Epoch [1][2350/3665]	lr: 2.000e-04, eta: 9:16:28, time: 0.909, data_time: 0.015, memory: 5275, loss_cls: 0.4261, loss_bbox: 0.3620, loss: 0.7881
2022-11-02 22:38:50,671 - mmdet - INFO - Epoch [1][2400/3665]	lr: 2.000e-04, eta: 9:17:46, time: 0.938, data_time: 0.013, memory: 5275, loss_cls: 0.4179, loss_bbox: 0.3623, loss: 0.7802
2022-11-02 22:39:37,382 - mmdet - INFO - Epoch [1][2450/3665]	lr: 2.000e-04, eta: 9:18:55, time: 0.934, data_time: 0.014, memory: 5275, loss_cls: 0.4247, loss_bbox: 0.3654, loss: 0.7900
2022-11-02 22:40:24,539 - mmdet - INFO - Epoch [1][2500/3665]	lr: 2.000e-04, eta: 9:20:07, time: 0.943, data_time: 0.013, memory: 5275, loss_cls: 0.4252, loss_bbox: 0.3657, loss: 0.7909
2022-11-02 22:41:09,506 - mmdet - INFO - Epoch [1][2550/3665]	lr: 2.000e-04, eta: 9:20:39, time: 0.899, data_time: 0.013, memory: 5275, loss_cls: 0.4269, loss_bbox: 0.3640, loss: 0.7909
2022-11-02 22:41:55,355 - mmdet - INFO - Epoch [1][2600/3665]	lr: 2.000e-04, eta: 9:21:22, time: 0.917, data_time: 0.015, memory: 5275, loss_cls: 0.4185, loss_bbox: 0.3613, loss: 0.7798
2022-11-02 22:42:41,368 - mmdet - INFO - Epoch [1][2650/3665]	lr: 2.000e-04, eta: 9:22:04, time: 0.920, data_time: 0.014, memory: 5275, loss_cls: 0.4206, loss_bbox: 0.3597, loss: 0.7803
2022-11-02 22:43:26,933 - mmdet - INFO - Epoch [1][2700/3665]	lr: 2.000e-04, eta: 9:22:36, time: 0.911, data_time: 0.014, memory: 5275, loss_cls: 0.4297, loss_bbox: 0.3664, loss: 0.7961
2022-11-02 22:44:11,996 - mmdet - INFO - Epoch [1][2750/3665]	lr: 2.000e-04, eta: 9:22:58, time: 0.901, data_time: 0.014, memory: 5275, loss_cls: 0.4095, loss_bbox: 0.3567, loss: 0.7662
2022-11-02 22:44:57,671 - mmdet - INFO - Epoch [1][2800/3665]	lr: 2.000e-04, eta: 9:23:26, time: 0.913, data_time: 0.014, memory: 5275, loss_cls: 0.4080, loss_bbox: 0.3617, loss: 0.7696
2022-11-02 22:45:44,585 - mmdet - INFO - Epoch [1][2850/3665]	lr: 2.000e-04, eta: 9:24:10, time: 0.938, data_time: 0.015, memory: 5275, loss_cls: 0.4146, loss_bbox: 0.3565, loss: 0.7711
2022-11-02 22:46:29,984 - mmdet - INFO - Epoch [1][2900/3665]	lr: 2.000e-04, eta: 9:24:29, time: 0.908, data_time: 0.015, memory: 5275, loss_cls: 0.4252, loss_bbox: 0.3593, loss: 0.7845
2022-11-02 22:47:15,779 - mmdet - INFO - Epoch [1][2950/3665]	lr: 2.000e-04, eta: 9:24:52, time: 0.916, data_time: 0.028, memory: 5275, loss_cls: 0.4109, loss_bbox: 0.3555, loss: 0.7664
2022-11-02 22:48:02,317 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-02 22:48:02,318 - mmdet - INFO - Epoch [1][3000/3665]	lr: 2.000e-04, eta: 9:25:22, time: 0.931, data_time: 0.042, memory: 5275, loss_cls: 0.4181, loss_bbox: 0.3542, loss: 0.7724
2022-11-02 22:48:47,646 - mmdet - INFO - Epoch [1][3050/3665]	lr: 2.000e-04, eta: 9:25:33, time: 0.906, data_time: 0.040, memory: 5275, loss_cls: 0.4331, loss_bbox: 0.3583, loss: 0.7914
2022-11-02 22:49:33,478 - mmdet - INFO - Epoch [1][3100/3665]	lr: 2.000e-04, eta: 9:25:50, time: 0.917, data_time: 0.042, memory: 5275, loss_cls: 0.4356, loss_bbox: 0.3551, loss: 0.7906
2022-11-02 22:50:20,891 - mmdet - INFO - Epoch [1][3150/3665]	lr: 2.000e-04, eta: 9:26:24, time: 0.948, data_time: 0.043, memory: 5275, loss_cls: 0.4217, loss_bbox: 0.3588, loss: 0.7805
2022-11-02 22:51:08,527 - mmdet - INFO - Epoch [1][3200/3665]	lr: 2.000e-04, eta: 9:27:00, time: 0.953, data_time: 0.043, memory: 5275, loss_cls: 0.4111, loss_bbox: 0.3533, loss: 0.7644
2022-11-02 22:51:55,789 - mmdet - INFO - Epoch [1][3250/3665]	lr: 2.000e-04, eta: 9:27:27, time: 0.945, data_time: 0.042, memory: 5275, loss_cls: 0.4040, loss_bbox: 0.3544, loss: 0.7583
2022-11-02 22:52:42,828 - mmdet - INFO - Epoch [1][3300/3665]	lr: 2.000e-04, eta: 9:27:50, time: 0.941, data_time: 0.042, memory: 5275, loss_cls: 0.3988, loss_bbox: 0.3523, loss: 0.7511
2022-11-02 22:53:29,632 - mmdet - INFO - Epoch [1][3350/3665]	lr: 2.000e-04, eta: 9:28:08, time: 0.936, data_time: 0.041, memory: 5275, loss_cls: 0.4245, loss_bbox: 0.3525, loss: 0.7770
2022-11-02 22:54:16,503 - mmdet - INFO - Epoch [1][3400/3665]	lr: 2.000e-04, eta: 9:28:25, time: 0.937, data_time: 0.040, memory: 5275, loss_cls: 0.4143, loss_bbox: 0.3451, loss: 0.7595
2022-11-02 22:55:04,503 - mmdet - INFO - Epoch [1][3450/3665]	lr: 2.000e-04, eta: 9:28:53, time: 0.960, data_time: 0.041, memory: 5275, loss_cls: 0.4023, loss_bbox: 0.3450, loss: 0.7472
2022-11-02 22:55:52,808 - mmdet - INFO - Epoch [1][3500/3665]	lr: 2.000e-04, eta: 9:29:23, time: 0.966, data_time: 0.041, memory: 5275, loss_cls: 0.4065, loss_bbox: 0.3483, loss: 0.7548
2022-11-02 22:56:38,695 - mmdet - INFO - Epoch [1][3550/3665]	lr: 2.000e-04, eta: 9:29:22, time: 0.917, data_time: 0.037, memory: 5275, loss_cls: 0.3985, loss_bbox: 0.3526, loss: 0.7511
2022-11-02 22:57:24,509 - mmdet - INFO - Epoch [1][3600/3665]	lr: 2.000e-04, eta: 9:29:20, time: 0.916, data_time: 0.015, memory: 5275, loss_cls: 0.4012, loss_bbox: 0.3505, loss: 0.7517
2022-11-02 22:58:11,111 - mmdet - INFO - Epoch [1][3650/3665]	lr: 2.000e-04, eta: 9:29:25, time: 0.933, data_time: 0.024, memory: 5275, loss_cls: 0.4014, loss_bbox: 0.3483, loss: 0.7497
2022-11-02 22:58:25,690 - mmdet - INFO - Saving checkpoint at 1 epochs
2022-11-02 23:00:56,364 - mmdet - INFO - Evaluating bbox...
2022-11-02 23:04:46,239 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.351
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.196
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.104
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.220
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.213
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.432
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.548

2022-11-02 23:04:48,620 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-02 23:04:48,621 - mmdet - INFO - Epoch(val) [1][625]	bbox_mAP: 0.1980, bbox_mAP_50: 0.3510, bbox_mAP_75: 0.1960, bbox_mAP_s: 0.1040, bbox_mAP_m: 0.2200, bbox_mAP_l: 0.2670, bbox_mAP_copypaste: 0.198 0.351 0.196 0.104 0.220 0.267
2022-11-02 23:05:39,265 - mmdet - INFO - Epoch [2][50/3665]	lr: 1.966e-04, eta: 9:27:42, time: 1.011, data_time: 0.126, memory: 5275, loss_cls: 0.3904, loss_bbox: 0.3414, loss: 0.7318
2022-11-02 23:06:21,942 - mmdet - INFO - Epoch [2][100/3665]	lr: 1.966e-04, eta: 9:27:03, time: 0.854, data_time: 0.015, memory: 5275, loss_cls: 0.3937, loss_bbox: 0.3385, loss: 0.7322
2022-11-02 23:07:03,043 - mmdet - INFO - Epoch [2][150/3665]	lr: 1.966e-04, eta: 9:26:08, time: 0.822, data_time: 0.014, memory: 5275, loss_cls: 0.3925, loss_bbox: 0.3445, loss: 0.7370
2022-11-02 23:07:44,017 - mmdet - INFO - Epoch [2][200/3665]	lr: 1.966e-04, eta: 9:25:12, time: 0.819, data_time: 0.016, memory: 5275, loss_cls: 0.3884, loss_bbox: 0.3371, loss: 0.7255
2022-11-02 23:08:28,274 - mmdet - INFO - Epoch [2][250/3665]	lr: 1.966e-04, eta: 9:24:51, time: 0.886, data_time: 0.033, memory: 5275, loss_cls: 0.3978, loss_bbox: 0.3499, loss: 0.7477
2022-11-02 23:09:13,913 - mmdet - INFO - Epoch [2][300/3665]	lr: 1.966e-04, eta: 9:24:42, time: 0.913, data_time: 0.040, memory: 5275, loss_cls: 0.3823, loss_bbox: 0.3429, loss: 0.7252
2022-11-02 23:09:59,803 - mmdet - INFO - Epoch [2][350/3665]	lr: 1.966e-04, eta: 9:24:35, time: 0.918, data_time: 0.039, memory: 5275, loss_cls: 0.3822, loss_bbox: 0.3422, loss: 0.7244
2022-11-02 23:10:46,269 - mmdet - INFO - Epoch [2][400/3665]	lr: 1.966e-04, eta: 9:24:33, time: 0.929, data_time: 0.039, memory: 5275, loss_cls: 0.3816, loss_bbox: 0.3410, loss: 0.7226
2022-11-02 23:11:32,589 - mmdet - INFO - Epoch [2][450/3665]	lr: 1.966e-04, eta: 9:24:28, time: 0.926, data_time: 0.039, memory: 5275, loss_cls: 0.3819, loss_bbox: 0.3398, loss: 0.7217
2022-11-02 23:12:19,093 - mmdet - INFO - Epoch [2][500/3665]	lr: 1.966e-04, eta: 9:24:24, time: 0.930, data_time: 0.038, memory: 5275, loss_cls: 0.3812, loss_bbox: 0.3357, loss: 0.7169
2022-11-02 23:13:05,389 - mmdet - INFO - Epoch [2][550/3665]	lr: 1.966e-04, eta: 9:24:17, time: 0.926, data_time: 0.034, memory: 5275, loss_cls: 0.3852, loss_bbox: 0.3434, loss: 0.7286
2022-11-02 23:13:51,249 - mmdet - INFO - Epoch [2][600/3665]	lr: 1.966e-04, eta: 9:24:05, time: 0.917, data_time: 0.015, memory: 5275, loss_cls: 0.3782, loss_bbox: 0.3421, loss: 0.7203
2022-11-02 23:14:36,166 - mmdet - INFO - Epoch [2][650/3665]	lr: 1.966e-04, eta: 9:23:43, time: 0.898, data_time: 0.014, memory: 5275, loss_cls: 0.3736, loss_bbox: 0.3349, loss: 0.7085
2022-11-02 23:15:22,073 - mmdet - INFO - Epoch [2][700/3665]	lr: 1.966e-04, eta: 9:23:30, time: 0.918, data_time: 0.015, memory: 5275, loss_cls: 0.3881, loss_bbox: 0.3426, loss: 0.7307
2022-11-02 23:16:08,409 - mmdet - INFO - Epoch [2][750/3665]	lr: 1.966e-04, eta: 9:23:21, time: 0.927, data_time: 0.015, memory: 5275, loss_cls: 0.3771, loss_bbox: 0.3403, loss: 0.7174
2022-11-02 23:16:54,347 - mmdet - INFO - Epoch [2][800/3665]	lr: 1.966e-04, eta: 9:23:06, time: 0.919, data_time: 0.014, memory: 5275, loss_cls: 0.3741, loss_bbox: 0.3294, loss: 0.7035
2022-11-02 23:17:41,101 - mmdet - INFO - Epoch [2][850/3665]	lr: 1.966e-04, eta: 9:22:59, time: 0.935, data_time: 0.014, memory: 5275, loss_cls: 0.3765, loss_bbox: 0.3327, loss: 0.7093
2022-11-02 23:18:28,215 - mmdet - INFO - Epoch [2][900/3665]	lr: 1.966e-04, eta: 9:22:53, time: 0.942, data_time: 0.015, memory: 5275, loss_cls: 0.3751, loss_bbox: 0.3301, loss: 0.7052
2022-11-02 23:19:13,336 - mmdet - INFO - Epoch [2][950/3665]	lr: 1.966e-04, eta: 9:22:30, time: 0.902, data_time: 0.014, memory: 5275, loss_cls: 0.3765, loss_bbox: 0.3365, loss: 0.7130
2022-11-02 23:19:58,902 - mmdet - INFO - Epoch [2][1000/3665]	lr: 1.966e-04, eta: 9:22:10, time: 0.911, data_time: 0.013, memory: 5275, loss_cls: 0.3714, loss_bbox: 0.3349, loss: 0.7063
2022-11-02 23:20:44,454 - mmdet - INFO - Epoch [2][1050/3665]	lr: 1.966e-04, eta: 9:21:49, time: 0.911, data_time: 0.014, memory: 5275, loss_cls: 0.3821, loss_bbox: 0.3348, loss: 0.7168
2022-11-02 23:21:31,730 - mmdet - INFO - Epoch [2][1100/3665]	lr: 1.966e-04, eta: 9:21:42, time: 0.946, data_time: 0.042, memory: 5275, loss_cls: 0.3821, loss_bbox: 0.3332, loss: 0.7154
2022-11-02 23:22:17,092 - mmdet - INFO - Epoch [2][1150/3665]	lr: 1.966e-04, eta: 9:21:18, time: 0.907, data_time: 0.040, memory: 5275, loss_cls: 0.3750, loss_bbox: 0.3334, loss: 0.7083
2022-11-02 23:23:03,248 - mmdet - INFO - Epoch [2][1200/3665]	lr: 1.966e-04, eta: 9:21:01, time: 0.923, data_time: 0.040, memory: 5275, loss_cls: 0.3695, loss_bbox: 0.3307, loss: 0.7002
2022-11-02 23:23:49,240 - mmdet - INFO - Epoch [2][1250/3665]	lr: 1.966e-04, eta: 9:20:41, time: 0.919, data_time: 0.022, memory: 5275, loss_cls: 0.3741, loss_bbox: 0.3384, loss: 0.7125
2022-11-02 23:24:36,128 - mmdet - INFO - Epoch [2][1300/3665]	lr: 1.966e-04, eta: 9:20:28, time: 0.938, data_time: 0.015, memory: 5275, loss_cls: 0.3713, loss_bbox: 0.3319, loss: 0.7032
2022-11-02 23:25:22,117 - mmdet - INFO - Epoch [2][1350/3665]	lr: 1.966e-04, eta: 9:20:07, time: 0.920, data_time: 0.014, memory: 5275, loss_cls: 0.3723, loss_bbox: 0.3417, loss: 0.7140
2022-11-02 23:26:06,990 - mmdet - INFO - Epoch [2][1400/3665]	lr: 1.966e-04, eta: 9:19:38, time: 0.897, data_time: 0.014, memory: 5275, loss_cls: 0.3702, loss_bbox: 0.3354, loss: 0.7056
2022-11-02 23:26:54,702 - mmdet - INFO - Epoch [2][1450/3665]	lr: 1.966e-04, eta: 9:19:29, time: 0.954, data_time: 0.034, memory: 5275, loss_cls: 0.3623, loss_bbox: 0.3291, loss: 0.6914
2022-11-02 23:27:41,896 - mmdet - INFO - Epoch [2][1500/3665]	lr: 1.966e-04, eta: 9:19:16, time: 0.944, data_time: 0.042, memory: 5275, loss_cls: 0.3695, loss_bbox: 0.3298, loss: 0.6993
2022-11-02 23:28:27,720 - mmdet - INFO - Epoch [2][1550/3665]	lr: 1.966e-04, eta: 9:18:52, time: 0.916, data_time: 0.044, memory: 5275, loss_cls: 0.3708, loss_bbox: 0.3369, loss: 0.7076
2022-11-02 23:29:14,401 - mmdet - INFO - Epoch [2][1600/3665]	lr: 1.966e-04, eta: 9:18:34, time: 0.934, data_time: 0.044, memory: 5275, loss_cls: 0.3604, loss_bbox: 0.3312, loss: 0.6916
2022-11-02 23:30:01,152 - mmdet - INFO - Epoch [2][1650/3665]	lr: 1.966e-04, eta: 9:18:16, time: 0.935, data_time: 0.041, memory: 5275, loss_cls: 0.3683, loss_bbox: 0.3248, loss: 0.6931
2022-11-02 23:30:47,761 - mmdet - INFO - Epoch [2][1700/3665]	lr: 1.966e-04, eta: 9:17:57, time: 0.932, data_time: 0.041, memory: 5275, loss_cls: 0.3652, loss_bbox: 0.3291, loss: 0.6944
2022-11-02 23:31:34,000 - mmdet - INFO - Epoch [2][1750/3665]	lr: 1.966e-04, eta: 9:17:34, time: 0.924, data_time: 0.043, memory: 5275, loss_cls: 0.3660, loss_bbox: 0.3330, loss: 0.6990
2022-11-02 23:32:19,650 - mmdet - INFO - Epoch [2][1800/3665]	lr: 1.966e-04, eta: 9:17:07, time: 0.913, data_time: 0.042, memory: 5275, loss_cls: 0.3615, loss_bbox: 0.3277, loss: 0.6893
2022-11-02 23:33:05,247 - mmdet - INFO - Epoch [2][1850/3665]	lr: 1.966e-04, eta: 9:16:38, time: 0.912, data_time: 0.042, memory: 5275, loss_cls: 0.3592, loss_bbox: 0.3271, loss: 0.6863
2022-11-02 23:33:51,812 - mmdet - INFO - Epoch [2][1900/3665]	lr: 1.966e-04, eta: 9:16:17, time: 0.931, data_time: 0.042, memory: 5275, loss_cls: 0.3772, loss_bbox: 0.3355, loss: 0.7127
2022-11-02 23:34:38,021 - mmdet - INFO - Epoch [2][1950/3665]	lr: 1.966e-04, eta: 9:15:52, time: 0.924, data_time: 0.043, memory: 5275, loss_cls: 0.3630, loss_bbox: 0.3258, loss: 0.6888
2022-11-02 23:35:23,863 - mmdet - INFO - Epoch [2][2000/3665]	lr: 1.966e-04, eta: 9:15:25, time: 0.917, data_time: 0.041, memory: 5275, loss_cls: 0.3572, loss_bbox: 0.3292, loss: 0.6864
2022-11-02 23:36:09,132 - mmdet - INFO - Epoch [2][2050/3665]	lr: 1.966e-04, eta: 9:14:53, time: 0.906, data_time: 0.043, memory: 5275, loss_cls: 0.3650, loss_bbox: 0.3320, loss: 0.6969
2022-11-02 23:36:55,321 - mmdet - INFO - Epoch [2][2100/3665]	lr: 1.966e-04, eta: 9:14:27, time: 0.923, data_time: 0.039, memory: 5275, loss_cls: 0.3675, loss_bbox: 0.3325, loss: 0.7000
2022-11-02 23:37:41,645 - mmdet - INFO - Epoch [2][2150/3665]	lr: 1.966e-04, eta: 9:14:02, time: 0.927, data_time: 0.030, memory: 5275, loss_cls: 0.3659, loss_bbox: 0.3311, loss: 0.6970
2022-11-02 23:38:28,512 - mmdet - INFO - Epoch [2][2200/3665]	lr: 1.966e-04, eta: 9:13:40, time: 0.937, data_time: 0.018, memory: 5275, loss_cls: 0.3637, loss_bbox: 0.3286, loss: 0.6922
2022-11-02 23:39:13,966 - mmdet - INFO - Epoch [2][2250/3665]	lr: 1.966e-04, eta: 9:13:09, time: 0.909, data_time: 0.014, memory: 5275, loss_cls: 0.3600, loss_bbox: 0.3272, loss: 0.6872
2022-11-02 23:39:57,943 - mmdet - INFO - Epoch [2][2300/3665]	lr: 1.966e-04, eta: 9:12:27, time: 0.880, data_time: 0.014, memory: 5275, loss_cls: 0.3714, loss_bbox: 0.3320, loss: 0.7035
2022-11-02 23:40:39,939 - mmdet - INFO - Epoch [2][2350/3665]	lr: 1.966e-04, eta: 9:11:34, time: 0.840, data_time: 0.015, memory: 5275, loss_cls: 0.3593, loss_bbox: 0.3260, loss: 0.6853
2022-11-02 23:41:21,513 - mmdet - INFO - Epoch [2][2400/3665]	lr: 1.966e-04, eta: 9:10:38, time: 0.831, data_time: 0.015, memory: 5275, loss_cls: 0.3674, loss_bbox: 0.3322, loss: 0.6996
2022-11-02 23:42:07,325 - mmdet - INFO - Epoch [2][2450/3665]	lr: 1.966e-04, eta: 9:10:08, time: 0.916, data_time: 0.015, memory: 5275, loss_cls: 0.3628, loss_bbox: 0.3274, loss: 0.6902
2022-11-02 23:42:53,845 - mmdet - INFO - Epoch [2][2500/3665]	lr: 1.966e-04, eta: 9:09:43, time: 0.931, data_time: 0.035, memory: 5275, loss_cls: 0.3636, loss_bbox: 0.3324, loss: 0.6960
2022-11-02 23:43:39,268 - mmdet - INFO - Epoch [2][2550/3665]	lr: 1.966e-04, eta: 9:09:10, time: 0.908, data_time: 0.020, memory: 5275, loss_cls: 0.3637, loss_bbox: 0.3280, loss: 0.6918
2022-11-02 23:44:25,579 - mmdet - INFO - Epoch [2][2600/3665]	lr: 1.966e-04, eta: 9:08:42, time: 0.926, data_time: 0.014, memory: 5275, loss_cls: 0.3558, loss_bbox: 0.3243, loss: 0.6801
2022-11-02 23:45:11,372 - mmdet - INFO - Epoch [2][2650/3665]	lr: 1.966e-04, eta: 9:08:11, time: 0.916, data_time: 0.014, memory: 5275, loss_cls: 0.3577, loss_bbox: 0.3226, loss: 0.6803
2022-11-02 23:45:56,415 - mmdet - INFO - Epoch [2][2700/3665]	lr: 1.966e-04, eta: 9:07:36, time: 0.901, data_time: 0.014, memory: 5275, loss_cls: 0.3599, loss_bbox: 0.3307, loss: 0.6906
2022-11-02 23:46:42,517 - mmdet - INFO - Epoch [2][2750/3665]	lr: 1.966e-04, eta: 9:07:07, time: 0.922, data_time: 0.030, memory: 5275, loss_cls: 0.3611, loss_bbox: 0.3280, loss: 0.6891
2022-11-02 23:47:24,796 - mmdet - INFO - Epoch [2][2800/3665]	lr: 1.966e-04, eta: 9:06:15, time: 0.846, data_time: 0.040, memory: 5275, loss_cls: 0.3610, loss_bbox: 0.3217, loss: 0.6827
2022-11-02 23:48:07,132 - mmdet - INFO - Epoch [2][2850/3665]	lr: 1.966e-04, eta: 9:05:23, time: 0.847, data_time: 0.041, memory: 5275, loss_cls: 0.3529, loss_bbox: 0.3272, loss: 0.6801
2022-11-02 23:48:52,327 - mmdet - INFO - Epoch [2][2900/3665]	lr: 1.966e-04, eta: 9:04:48, time: 0.904, data_time: 0.042, memory: 5275, loss_cls: 0.3604, loss_bbox: 0.3301, loss: 0.6906
2022-11-02 23:49:39,060 - mmdet - INFO - Epoch [2][2950/3665]	lr: 1.966e-04, eta: 9:04:22, time: 0.935, data_time: 0.043, memory: 5275, loss_cls: 0.3645, loss_bbox: 0.3269, loss: 0.6915
2022-11-02 23:50:25,005 - mmdet - INFO - Epoch [2][3000/3665]	lr: 1.966e-04, eta: 9:03:51, time: 0.919, data_time: 0.042, memory: 5275, loss_cls: 0.3503, loss_bbox: 0.3244, loss: 0.6747
2022-11-02 23:51:10,249 - mmdet - INFO - Epoch [2][3050/3665]	lr: 1.966e-04, eta: 9:03:15, time: 0.905, data_time: 0.041, memory: 5275, loss_cls: 0.3538, loss_bbox: 0.3188, loss: 0.6726
2022-11-02 23:51:54,176 - mmdet - INFO - Epoch [2][3100/3665]	lr: 1.966e-04, eta: 9:02:33, time: 0.879, data_time: 0.041, memory: 5275, loss_cls: 0.3614, loss_bbox: 0.3241, loss: 0.6855
2022-11-02 23:52:39,067 - mmdet - INFO - Epoch [2][3150/3665]	lr: 1.966e-04, eta: 9:01:55, time: 0.898, data_time: 0.043, memory: 5275, loss_cls: 0.3559, loss_bbox: 0.3271, loss: 0.6830
2022-11-02 23:53:25,305 - mmdet - INFO - Epoch [2][3200/3665]	lr: 1.966e-04, eta: 9:01:25, time: 0.925, data_time: 0.043, memory: 5275, loss_cls: 0.3599, loss_bbox: 0.3277, loss: 0.6876
2022-11-02 23:54:10,617 - mmdet - INFO - Epoch [2][3250/3665]	lr: 1.966e-04, eta: 9:00:49, time: 0.906, data_time: 0.041, memory: 5275, loss_cls: 0.3555, loss_bbox: 0.3251, loss: 0.6806
2022-11-02 23:54:56,954 - mmdet - INFO - Epoch [2][3300/3665]	lr: 1.966e-04, eta: 9:00:19, time: 0.927, data_time: 0.025, memory: 5275, loss_cls: 0.3647, loss_bbox: 0.3241, loss: 0.6889
2022-11-02 23:55:42,398 - mmdet - INFO - Epoch [2][3350/3665]	lr: 1.966e-04, eta: 8:59:44, time: 0.909, data_time: 0.016, memory: 5275, loss_cls: 0.3524, loss_bbox: 0.3245, loss: 0.6769
2022-11-02 23:56:28,002 - mmdet - INFO - Epoch [2][3400/3665]	lr: 1.966e-04, eta: 8:59:10, time: 0.912, data_time: 0.015, memory: 5275, loss_cls: 0.3503, loss_bbox: 0.3271, loss: 0.6774
2022-11-02 23:57:11,310 - mmdet - INFO - Epoch [2][3450/3665]	lr: 1.966e-04, eta: 8:58:23, time: 0.866, data_time: 0.015, memory: 5275, loss_cls: 0.3548, loss_bbox: 0.3255, loss: 0.6804
2022-11-02 23:57:51,723 - mmdet - INFO - Epoch [2][3500/3665]	lr: 1.966e-04, eta: 8:57:22, time: 0.808, data_time: 0.018, memory: 5275, loss_cls: 0.3547, loss_bbox: 0.3245, loss: 0.6792
2022-11-02 23:58:22,063 - mmdet - INFO - Epoch [2][3550/3665]	lr: 1.966e-04, eta: 8:55:30, time: 0.607, data_time: 0.016, memory: 5275, loss_cls: 0.3531, loss_bbox: 0.3255, loss: 0.6787
2022-11-02 23:58:51,743 - mmdet - INFO - Epoch [2][3600/3665]	lr: 1.966e-04, eta: 8:53:35, time: 0.594, data_time: 0.016, memory: 5275, loss_cls: 0.3518, loss_bbox: 0.3168, loss: 0.6686
2022-11-02 23:59:23,154 - mmdet - INFO - Epoch [2][3650/3665]	lr: 1.966e-04, eta: 8:51:50, time: 0.628, data_time: 0.016, memory: 5275, loss_cls: 0.3591, loss_bbox: 0.3245, loss: 0.6836
2022-11-02 23:59:38,882 - mmdet - INFO - Saving checkpoint at 2 epochs
2022-11-03 00:01:55,508 - mmdet - INFO - Evaluating bbox...
2022-11-03 00:05:44,594 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.412
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.251
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.139
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.269
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.328
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.441
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.441
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.247
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.590

2022-11-03 00:05:46,931 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 00:05:46,932 - mmdet - INFO - Epoch(val) [2][625]	bbox_mAP: 0.2450, bbox_mAP_50: 0.4120, bbox_mAP_75: 0.2510, bbox_mAP_s: 0.1390, bbox_mAP_m: 0.2690, bbox_mAP_l: 0.3280, bbox_mAP_copypaste: 0.245 0.412 0.251 0.139 0.269 0.328
2022-11-03 00:06:39,758 - mmdet - INFO - Epoch [3][50/3665]	lr: 1.866e-04, eta: 8:50:35, time: 1.055, data_time: 0.125, memory: 5275, loss_cls: 0.3439, loss_bbox: 0.3114, loss: 0.6554
2022-11-03 00:07:25,190 - mmdet - INFO - Epoch [3][100/3665]	lr: 1.866e-04, eta: 8:50:01, time: 0.908, data_time: 0.014, memory: 5275, loss_cls: 0.3349, loss_bbox: 0.3153, loss: 0.6502
2022-11-03 00:08:10,906 - mmdet - INFO - Epoch [3][150/3665]	lr: 1.866e-04, eta: 8:49:28, time: 0.914, data_time: 0.015, memory: 5275, loss_cls: 0.3456, loss_bbox: 0.3127, loss: 0.6583
2022-11-03 00:08:55,835 - mmdet - INFO - Epoch [3][200/3665]	lr: 1.866e-04, eta: 8:48:51, time: 0.898, data_time: 0.015, memory: 5275, loss_cls: 0.3425, loss_bbox: 0.3166, loss: 0.6591
2022-11-03 00:09:42,259 - mmdet - INFO - Epoch [3][250/3665]	lr: 1.866e-04, eta: 8:48:22, time: 0.929, data_time: 0.014, memory: 5275, loss_cls: 0.3347, loss_bbox: 0.3176, loss: 0.6523
2022-11-03 00:10:27,871 - mmdet - INFO - Epoch [3][300/3665]	lr: 1.866e-04, eta: 8:47:48, time: 0.912, data_time: 0.014, memory: 5275, loss_cls: 0.3315, loss_bbox: 0.3154, loss: 0.6469
2022-11-03 00:11:14,257 - mmdet - INFO - Epoch [3][350/3665]	lr: 1.866e-04, eta: 8:47:18, time: 0.928, data_time: 0.015, memory: 5275, loss_cls: 0.3365, loss_bbox: 0.3149, loss: 0.6514
2022-11-03 00:11:59,927 - mmdet - INFO - Epoch [3][400/3665]	lr: 1.866e-04, eta: 8:46:44, time: 0.913, data_time: 0.014, memory: 5275, loss_cls: 0.3329, loss_bbox: 0.3122, loss: 0.6451
2022-11-03 00:12:45,341 - mmdet - INFO - Epoch [3][450/3665]	lr: 1.866e-04, eta: 8:46:09, time: 0.908, data_time: 0.016, memory: 5275, loss_cls: 0.3346, loss_bbox: 0.3149, loss: 0.6495
2022-11-03 00:13:30,657 - mmdet - INFO - Epoch [3][500/3665]	lr: 1.866e-04, eta: 8:45:33, time: 0.907, data_time: 0.040, memory: 5275, loss_cls: 0.3338, loss_bbox: 0.3126, loss: 0.6464
2022-11-03 00:14:15,844 - mmdet - INFO - Epoch [3][550/3665]	lr: 1.866e-04, eta: 8:44:57, time: 0.904, data_time: 0.040, memory: 5275, loss_cls: 0.3405, loss_bbox: 0.3115, loss: 0.6520
2022-11-03 00:15:01,292 - mmdet - INFO - Epoch [3][600/3665]	lr: 1.866e-04, eta: 8:44:22, time: 0.909, data_time: 0.040, memory: 5275, loss_cls: 0.3457, loss_bbox: 0.3185, loss: 0.6642
2022-11-03 00:15:47,329 - mmdet - INFO - Epoch [3][650/3665]	lr: 1.866e-04, eta: 8:43:49, time: 0.920, data_time: 0.030, memory: 5275, loss_cls: 0.3380, loss_bbox: 0.3157, loss: 0.6537
2022-11-03 00:16:32,711 - mmdet - INFO - Epoch [3][700/3665]	lr: 1.866e-04, eta: 8:43:13, time: 0.908, data_time: 0.016, memory: 5275, loss_cls: 0.3244, loss_bbox: 0.3095, loss: 0.6339
2022-11-03 00:17:18,478 - mmdet - INFO - Epoch [3][750/3665]	lr: 1.866e-04, eta: 8:42:39, time: 0.915, data_time: 0.014, memory: 5275, loss_cls: 0.3373, loss_bbox: 0.3127, loss: 0.6500
2022-11-03 00:18:03,707 - mmdet - INFO - Epoch [3][800/3665]	lr: 1.866e-04, eta: 8:42:02, time: 0.905, data_time: 0.014, memory: 5275, loss_cls: 0.3397, loss_bbox: 0.3188, loss: 0.6585
2022-11-03 00:18:48,866 - mmdet - INFO - Epoch [3][850/3665]	lr: 1.866e-04, eta: 8:41:24, time: 0.903, data_time: 0.014, memory: 5275, loss_cls: 0.3365, loss_bbox: 0.3170, loss: 0.6535
2022-11-03 00:19:34,009 - mmdet - INFO - Epoch [3][900/3665]	lr: 1.866e-04, eta: 8:40:47, time: 0.903, data_time: 0.015, memory: 5275, loss_cls: 0.3307, loss_bbox: 0.3127, loss: 0.6434
2022-11-03 00:20:18,747 - mmdet - INFO - Epoch [3][950/3665]	lr: 1.866e-04, eta: 8:40:08, time: 0.895, data_time: 0.029, memory: 5275, loss_cls: 0.3392, loss_bbox: 0.3108, loss: 0.6500
2022-11-03 00:21:03,860 - mmdet - INFO - Epoch [3][1000/3665]	lr: 1.866e-04, eta: 8:39:30, time: 0.902, data_time: 0.040, memory: 5275, loss_cls: 0.3322, loss_bbox: 0.3157, loss: 0.6479
2022-11-03 00:21:48,762 - mmdet - INFO - Epoch [3][1050/3665]	lr: 1.866e-04, eta: 8:38:51, time: 0.898, data_time: 0.041, memory: 5275, loss_cls: 0.3297, loss_bbox: 0.3092, loss: 0.6390
2022-11-03 00:22:33,633 - mmdet - INFO - Epoch [3][1100/3665]	lr: 1.866e-04, eta: 8:38:13, time: 0.897, data_time: 0.040, memory: 5275, loss_cls: 0.3353, loss_bbox: 0.3112, loss: 0.6465
2022-11-03 00:23:19,873 - mmdet - INFO - Epoch [3][1150/3665]	lr: 1.866e-04, eta: 8:37:39, time: 0.925, data_time: 0.040, memory: 5275, loss_cls: 0.3313, loss_bbox: 0.3122, loss: 0.6435
2022-11-03 00:24:05,210 - mmdet - INFO - Epoch [3][1200/3665]	lr: 1.866e-04, eta: 8:37:02, time: 0.907, data_time: 0.041, memory: 5275, loss_cls: 0.3339, loss_bbox: 0.3096, loss: 0.6435
2022-11-03 00:24:49,331 - mmdet - INFO - Epoch [3][1250/3665]	lr: 1.866e-04, eta: 8:36:20, time: 0.882, data_time: 0.025, memory: 5275, loss_cls: 0.3336, loss_bbox: 0.3123, loss: 0.6459
2022-11-03 00:25:34,413 - mmdet - INFO - Epoch [3][1300/3665]	lr: 1.866e-04, eta: 8:35:42, time: 0.902, data_time: 0.036, memory: 5275, loss_cls: 0.3361, loss_bbox: 0.3098, loss: 0.6458
2022-11-03 00:26:18,584 - mmdet - INFO - Epoch [3][1350/3665]	lr: 1.866e-04, eta: 8:35:00, time: 0.884, data_time: 0.041, memory: 5275, loss_cls: 0.3344, loss_bbox: 0.3136, loss: 0.6481
2022-11-03 00:27:03,939 - mmdet - INFO - Epoch [3][1400/3665]	lr: 1.866e-04, eta: 8:34:22, time: 0.907, data_time: 0.042, memory: 5275, loss_cls: 0.3372, loss_bbox: 0.3170, loss: 0.6542
2022-11-03 00:27:49,596 - mmdet - INFO - Epoch [3][1450/3665]	lr: 1.866e-04, eta: 8:33:46, time: 0.913, data_time: 0.043, memory: 5275, loss_cls: 0.3277, loss_bbox: 0.3140, loss: 0.6417
2022-11-03 00:28:35,158 - mmdet - INFO - Epoch [3][1500/3665]	lr: 1.866e-04, eta: 8:33:09, time: 0.911, data_time: 0.044, memory: 5275, loss_cls: 0.3269, loss_bbox: 0.3118, loss: 0.6387
2022-11-03 00:29:20,296 - mmdet - INFO - Epoch [3][1550/3665]	lr: 1.866e-04, eta: 8:32:31, time: 0.903, data_time: 0.045, memory: 5275, loss_cls: 0.3342, loss_bbox: 0.3131, loss: 0.6473
2022-11-03 00:30:06,988 - mmdet - INFO - Epoch [3][1600/3665]	lr: 1.866e-04, eta: 8:31:58, time: 0.934, data_time: 0.042, memory: 5275, loss_cls: 0.3350, loss_bbox: 0.3115, loss: 0.6464
2022-11-03 00:30:54,553 - mmdet - INFO - Epoch [3][1650/3665]	lr: 1.866e-04, eta: 8:31:29, time: 0.951, data_time: 0.039, memory: 5275, loss_cls: 0.3302, loss_bbox: 0.3144, loss: 0.6446
2022-11-03 00:31:40,496 - mmdet - INFO - Epoch [3][1700/3665]	lr: 1.866e-04, eta: 8:30:53, time: 0.919, data_time: 0.043, memory: 5275, loss_cls: 0.3343, loss_bbox: 0.3139, loss: 0.6481
2022-11-03 00:32:26,806 - mmdet - INFO - Epoch [3][1750/3665]	lr: 1.866e-04, eta: 8:30:19, time: 0.926, data_time: 0.042, memory: 5275, loss_cls: 0.3280, loss_bbox: 0.3119, loss: 0.6399
2022-11-03 00:33:12,494 - mmdet - INFO - Epoch [3][1800/3665]	lr: 1.866e-04, eta: 8:29:42, time: 0.914, data_time: 0.043, memory: 5275, loss_cls: 0.3371, loss_bbox: 0.3149, loss: 0.6520
2022-11-03 00:33:59,413 - mmdet - INFO - Epoch [3][1850/3665]	lr: 1.866e-04, eta: 8:29:10, time: 0.938, data_time: 0.044, memory: 5275, loss_cls: 0.3316, loss_bbox: 0.3134, loss: 0.6450
2022-11-03 00:34:44,977 - mmdet - INFO - Epoch [3][1900/3665]	lr: 1.866e-04, eta: 8:28:32, time: 0.911, data_time: 0.045, memory: 5275, loss_cls: 0.3277, loss_bbox: 0.3081, loss: 0.6358
2022-11-03 00:35:30,279 - mmdet - INFO - Epoch [3][1950/3665]	lr: 1.866e-04, eta: 8:27:53, time: 0.906, data_time: 0.043, memory: 5275, loss_cls: 0.3367, loss_bbox: 0.3121, loss: 0.6488
2022-11-03 00:36:13,196 - mmdet - INFO - Epoch [3][2000/3665]	lr: 1.866e-04, eta: 8:27:06, time: 0.858, data_time: 0.042, memory: 5275, loss_cls: 0.3226, loss_bbox: 0.3113, loss: 0.6339
2022-11-03 00:36:58,101 - mmdet - INFO - Epoch [3][2050/3665]	lr: 1.866e-04, eta: 8:26:25, time: 0.898, data_time: 0.043, memory: 5275, loss_cls: 0.3313, loss_bbox: 0.3118, loss: 0.6431
2022-11-03 00:37:42,787 - mmdet - INFO - Epoch [3][2100/3665]	lr: 1.866e-04, eta: 8:25:44, time: 0.893, data_time: 0.041, memory: 5275, loss_cls: 0.3340, loss_bbox: 0.3153, loss: 0.6493
2022-11-03 00:38:28,064 - mmdet - INFO - Epoch [3][2150/3665]	lr: 1.866e-04, eta: 8:25:05, time: 0.906, data_time: 0.040, memory: 5275, loss_cls: 0.3330, loss_bbox: 0.3086, loss: 0.6416
2022-11-03 00:39:13,973 - mmdet - INFO - Epoch [3][2200/3665]	lr: 1.866e-04, eta: 8:24:29, time: 0.918, data_time: 0.040, memory: 5275, loss_cls: 0.3260, loss_bbox: 0.3090, loss: 0.6350
2022-11-03 00:39:58,618 - mmdet - INFO - Epoch [3][2250/3665]	lr: 1.866e-04, eta: 8:23:47, time: 0.893, data_time: 0.040, memory: 5275, loss_cls: 0.3299, loss_bbox: 0.3120, loss: 0.6419
2022-11-03 00:40:40,732 - mmdet - INFO - Epoch [3][2300/3665]	lr: 1.866e-04, eta: 8:22:57, time: 0.842, data_time: 0.040, memory: 5275, loss_cls: 0.3204, loss_bbox: 0.3072, loss: 0.6276
2022-11-03 00:41:22,748 - mmdet - INFO - Epoch [3][2350/3665]	lr: 1.866e-04, eta: 8:22:06, time: 0.841, data_time: 0.039, memory: 5275, loss_cls: 0.3331, loss_bbox: 0.3127, loss: 0.6458
2022-11-03 00:42:08,658 - mmdet - INFO - Epoch [3][2400/3665]	lr: 1.866e-04, eta: 8:21:29, time: 0.918, data_time: 0.032, memory: 5275, loss_cls: 0.3323, loss_bbox: 0.3071, loss: 0.6394
2022-11-03 00:42:55,966 - mmdet - INFO - Epoch [3][2450/3665]	lr: 1.866e-04, eta: 8:20:57, time: 0.946, data_time: 0.016, memory: 5275, loss_cls: 0.3367, loss_bbox: 0.3130, loss: 0.6497
2022-11-03 00:43:42,688 - mmdet - INFO - Epoch [3][2500/3665]	lr: 1.866e-04, eta: 8:20:23, time: 0.935, data_time: 0.016, memory: 5275, loss_cls: 0.3265, loss_bbox: 0.3104, loss: 0.6369
2022-11-03 00:44:28,940 - mmdet - INFO - Epoch [3][2550/3665]	lr: 1.866e-04, eta: 8:19:47, time: 0.925, data_time: 0.015, memory: 5275, loss_cls: 0.3255, loss_bbox: 0.3105, loss: 0.6360
2022-11-03 00:45:14,770 - mmdet - INFO - Epoch [3][2600/3665]	lr: 1.866e-04, eta: 8:19:09, time: 0.917, data_time: 0.016, memory: 5275, loss_cls: 0.3327, loss_bbox: 0.3109, loss: 0.6437
2022-11-03 00:45:59,814 - mmdet - INFO - Epoch [3][2650/3665]	lr: 1.866e-04, eta: 8:18:29, time: 0.901, data_time: 0.016, memory: 5275, loss_cls: 0.3292, loss_bbox: 0.3111, loss: 0.6403
2022-11-03 00:46:44,836 - mmdet - INFO - Epoch [3][2700/3665]	lr: 1.866e-04, eta: 8:17:48, time: 0.901, data_time: 0.016, memory: 5275, loss_cls: 0.3215, loss_bbox: 0.3081, loss: 0.6297
2022-11-03 00:47:26,472 - mmdet - INFO - Epoch [3][2750/3665]	lr: 1.866e-04, eta: 8:16:56, time: 0.832, data_time: 0.017, memory: 5275, loss_cls: 0.3346, loss_bbox: 0.3142, loss: 0.6488
2022-11-03 00:48:09,412 - mmdet - INFO - Epoch [3][2800/3665]	lr: 1.866e-04, eta: 8:16:09, time: 0.859, data_time: 0.018, memory: 5275, loss_cls: 0.3225, loss_bbox: 0.3078, loss: 0.6303
2022-11-03 00:48:55,187 - mmdet - INFO - Epoch [3][2850/3665]	lr: 1.866e-04, eta: 8:15:31, time: 0.916, data_time: 0.017, memory: 5275, loss_cls: 0.3269, loss_bbox: 0.3135, loss: 0.6403
2022-11-03 00:49:40,575 - mmdet - INFO - Epoch [3][2900/3665]	lr: 1.866e-04, eta: 8:14:52, time: 0.908, data_time: 0.017, memory: 5275, loss_cls: 0.3228, loss_bbox: 0.3076, loss: 0.6303
2022-11-03 00:50:25,307 - mmdet - INFO - Epoch [3][2950/3665]	lr: 1.866e-04, eta: 8:14:10, time: 0.895, data_time: 0.016, memory: 5275, loss_cls: 0.3291, loss_bbox: 0.3078, loss: 0.6369
2022-11-03 00:51:10,077 - mmdet - INFO - Epoch [3][3000/3665]	lr: 1.866e-04, eta: 8:13:29, time: 0.895, data_time: 0.017, memory: 5275, loss_cls: 0.3290, loss_bbox: 0.3115, loss: 0.6405
2022-11-03 00:51:56,084 - mmdet - INFO - Epoch [3][3050/3665]	lr: 1.866e-04, eta: 8:12:51, time: 0.921, data_time: 0.030, memory: 5275, loss_cls: 0.3233, loss_bbox: 0.3119, loss: 0.6352
2022-11-03 00:52:42,994 - mmdet - INFO - Epoch [3][3100/3665]	lr: 1.866e-04, eta: 8:12:17, time: 0.938, data_time: 0.044, memory: 5275, loss_cls: 0.3282, loss_bbox: 0.3092, loss: 0.6374
2022-11-03 00:53:29,641 - mmdet - INFO - Epoch [3][3150/3665]	lr: 1.866e-04, eta: 8:11:41, time: 0.933, data_time: 0.044, memory: 5275, loss_cls: 0.3338, loss_bbox: 0.3124, loss: 0.6462
2022-11-03 00:54:15,924 - mmdet - INFO - Epoch [3][3200/3665]	lr: 1.866e-04, eta: 8:11:04, time: 0.925, data_time: 0.038, memory: 5275, loss_cls: 0.3210, loss_bbox: 0.3043, loss: 0.6253
2022-11-03 00:55:01,427 - mmdet - INFO - Epoch [3][3250/3665]	lr: 1.866e-04, eta: 8:10:24, time: 0.910, data_time: 0.025, memory: 5275, loss_cls: 0.3290, loss_bbox: 0.3060, loss: 0.6350
2022-11-03 00:55:46,364 - mmdet - INFO - Epoch [3][3300/3665]	lr: 1.866e-04, eta: 8:09:43, time: 0.899, data_time: 0.020, memory: 5275, loss_cls: 0.3293, loss_bbox: 0.3100, loss: 0.6394
2022-11-03 00:56:33,816 - mmdet - INFO - Epoch [3][3350/3665]	lr: 1.866e-04, eta: 8:09:10, time: 0.949, data_time: 0.041, memory: 5275, loss_cls: 0.3248, loss_bbox: 0.3080, loss: 0.6329
2022-11-03 00:57:21,259 - mmdet - INFO - Epoch [3][3400/3665]	lr: 1.866e-04, eta: 8:08:36, time: 0.949, data_time: 0.046, memory: 5275, loss_cls: 0.3302, loss_bbox: 0.3129, loss: 0.6431
2022-11-03 08:21:55,819 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.9.5 (default, Jun  4 2021, 12:28:51) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: A100-SXM4-40GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.0, V11.0.221
GCC: gcc (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
PyTorch: 1.10.1+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2+cu113
OpenCV: 4.5.4
MMCV: 1.6.2
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMDetection: 2.25.2+
------------------------------------------------------------

2022-11-03 08:21:56,016 - mmdet - INFO - Distributed training: True
2022-11-03 08:21:56,309 - mmdet - INFO - Config:
model = dict(
    type='RetinaNet',
    backbone=dict(
        type='MetaMobile',
        depths=[3, 3, 9, 3],
        stem_dim=24,
        embed_dims=[32, 48, 120, 200],
        exp_ratios=[2.0, 2.5, 3.0, 3.5],
        norm_layers=['bn_2d', 'bn_2d', 'ln_2d', 'ln_2d'],
        act_layers=['silu', 'silu', 'gelu', 'gelu'],
        dw_kss=[3, 3, 5, 5],
        group_size=1,
        se_ratios=[0.0, 0.0, 0.0, 0.0],
        dim_heads=[16, 16, 20, 20],
        window_sizes=[7, 7, 7, 7],
        attn_ss=[False, False, True, True],
        attn_s_skips=[False, False, False, False],
        qkv_bias=True,
        attn_drop=0.0,
        drop=0.0,
        drop_path=0.05,
        v_group=False,
        attn_pre=True,
        conv_l=True,
        skip_l=True,
        pre_dim=0,
        sync_bn=True,
        out_indices=(1, 2, 3, 4),
        pretrained='../../ckpt_models/MetaMobile_2M/net_E.pth',
        frozen_stages=1,
        norm_eval=True),
    neck=dict(
        type='FPN',
        in_channels=[32, 48, 120, 200],
        out_channels=256,
        start_level=1,
        add_extra_convs='on_input',
        num_outs=5),
    bbox_head=dict(
        type='RetinaHead',
        num_classes=80,
        in_channels=256,
        stacked_convs=4,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            octave_base_scale=4,
            scales_per_octave=3,
            ratios=[0.5, 1.0, 2.0],
            strides=[8, 16, 32, 64, 128]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    train_cfg=dict(
        assigner=dict(
            type='MaxIoUAssigner',
            pos_iou_thr=0.5,
            neg_iou_thr=0.4,
            min_pos_iou=0,
            ignore_iof_thr=-1),
        allowed_border=-1,
        pos_weight=-1,
        debug=False),
    test_cfg=dict(
        nms_pre=1000,
        min_bbox_size=0,
        score_thr=0.05,
        nms=dict(type='nms', iou_threshold=0.5),
        max_per_img=100))
dataset_type = 'CocoDataset'
data_root = 'data/coco/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_train2017.json',
        img_prefix='data/coco/train2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file='data/coco/annotations/instances_val2017.json',
        img_prefix='data/coco/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric='bbox')
optimizer_config = dict(grad_clip=None)
runner = dict(type='EpochBasedRunner', max_epochs=12)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
auto_scale_lr = dict(enable=False, base_batch_size=16)
bs_ratio = 1
optimizer = dict(
    type='AdamW',
    lr=0.0002,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    min_lr=0)
work_dir = './work_dirs/retinanet_metamobile2M_fpn_1x_coco'
auto_resume = True
gpu_ids = range(0, 8)

2022-11-03 08:21:56,310 - mmdet - INFO - Set random seed to 0, deterministic: False
2022-11-03 08:21:56,515 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2022-11-03 08:21:56,529 - mmdet - INFO - initialize RetinaHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'retina_cls', 'std': 0.01, 'bias_prob': 0.01}}
Name of parameter - Initialization information

backbone.stage0.0.convs.0.0.weight - torch.Size([24, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.0.convs.0.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.0.convs.0.1.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.0.convs.0.1.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.conv_local.conv.weight - torch.Size([24, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.conv_local.norm.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.conv_local.norm.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.se.conv_reduce.weight - torch.Size([24, 24, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.se.conv_reduce.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.se.conv_expand.weight - torch.Size([24, 24, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.se.conv_expand.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage0.1.proj.conv.weight - torch.Size([24, 24, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.norm.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.norm.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.v.conv.weight - torch.Size([96, 24, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.v.conv.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.conv_local.conv.weight - torch.Size([96, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.conv_local.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.conv_local.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.0.proj.conv.weight - torch.Size([32, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.norm.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.norm.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.v.conv.weight - torch.Size([64, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.v.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.conv_local.conv.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.conv_local.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.conv_local.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.1.proj.conv.weight - torch.Size([32, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.norm.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.norm.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.v.conv.weight - torch.Size([64, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.v.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.conv_local.conv.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.conv_local.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.conv_local.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage1.2.proj.conv.weight - torch.Size([32, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.norm.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.norm.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.v.conv.weight - torch.Size([160, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.v.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.conv_local.conv.weight - torch.Size([160, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.conv_local.norm.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.conv_local.norm.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.0.proj.conv.weight - torch.Size([48, 160, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.norm.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.norm.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.v.conv.weight - torch.Size([120, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.v.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.conv_local.conv.weight - torch.Size([120, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.conv_local.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.conv_local.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.1.proj.conv.weight - torch.Size([48, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.norm.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.norm.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.v.conv.weight - torch.Size([120, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.v.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.conv_local.conv.weight - torch.Size([120, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.conv_local.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.conv_local.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage2.2.proj.conv.weight - torch.Size([48, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.norm.norm.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.norm.norm.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.v.conv.weight - torch.Size([288, 48, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.v.conv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.conv_local.conv.weight - torch.Size([288, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.conv_local.norm.weight - torch.Size([288]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.conv_local.norm.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.0.proj.conv.weight - torch.Size([120, 288, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.1.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.2.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.3.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.4.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.5.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.6.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.7.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.qk.conv.weight - torch.Size([240, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.qk.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.v.conv.weight - torch.Size([360, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.v.conv.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.conv_local.conv.weight - torch.Size([360, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.conv_local.norm.weight - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.conv_local.norm.bias - torch.Size([360]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage3.8.proj.conv.weight - torch.Size([120, 360, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.norm.norm.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.norm.norm.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.v.conv.weight - torch.Size([840, 120, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.v.conv.bias - torch.Size([840]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.conv_local.conv.weight - torch.Size([840, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.conv_local.norm.weight - torch.Size([840]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.conv_local.norm.bias - torch.Size([840]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.0.proj.conv.weight - torch.Size([200, 840, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.norm.norm.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.norm.norm.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.qk.conv.weight - torch.Size([400, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.qk.conv.bias - torch.Size([400]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.v.conv.weight - torch.Size([700, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.v.conv.bias - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.conv_local.conv.weight - torch.Size([700, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.conv_local.norm.weight - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.conv_local.norm.bias - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.1.proj.conv.weight - torch.Size([200, 700, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.norm.norm.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.norm.norm.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.qk.conv.weight - torch.Size([400, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.qk.conv.bias - torch.Size([400]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.v.conv.weight - torch.Size([700, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.v.conv.bias - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.conv_local.conv.weight - torch.Size([700, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.conv_local.norm.weight - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.conv_local.norm.bias - torch.Size([700]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.stage4.2.proj.conv.weight - torch.Size([200, 700, 1, 1]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.0.conv.weight - torch.Size([256, 48, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.1.conv.weight - torch.Size([256, 120, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.2.conv.weight - torch.Size([256, 200, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.3.conv.weight - torch.Size([256, 200, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.4.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.retina_cls.weight - torch.Size([720, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

bbox_head.retina_cls.bias - torch.Size([720]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

bbox_head.retina_reg.weight - torch.Size([36, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.retina_reg.bias - torch.Size([36]): 
NormalInit: mean=0, std=0.01, bias=0 
2022-11-03 08:22:25,040 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.
2022-11-03 08:22:25,490 - mmdet - INFO - load checkpoint from local path: ./work_dirs/retinanet_metamobile2M_fpn_1x_coco/latest.pth
2022-11-03 08:22:27,552 - mmdet - INFO - resumed epoch 2, iter 7330
2022-11-03 08:22:27,553 - mmdet - INFO - Start running, host: root@ts-8f168728d23e44df8b2aa939e7968482-launcher, work_dir: /youtu_fuxi_team1_ceph/vtzhang/codes/pts_cls/down-stream-tasks/mmdetection/work_dirs/retinanet_metamobile2M_fpn_1x_coco
2022-11-03 08:22:27,554 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) NumClassCheckHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-11-03 08:22:27,554 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs
2022-11-03 08:22:27,554 - mmdet - INFO - Checkpoints will be saved to /youtu_fuxi_team1_ceph/vtzhang/codes/pts_cls/down-stream-tasks/mmdetection/work_dirs/retinanet_metamobile2M_fpn_1x_coco by HardDiskBackend.
2022-11-03 08:22:44,272 - mmdet - INFO - Epoch [3][50/3665]	lr: 1.866e-04, eta: 3:20:39, time: 0.329, data_time: 0.080, memory: 5251, loss_cls: 0.3446, loss_bbox: 0.3112, loss: 0.6558
2022-11-03 08:22:54,673 - mmdet - INFO - Epoch [3][100/3665]	lr: 1.866e-04, eta: 2:43:33, time: 0.208, data_time: 0.016, memory: 5251, loss_cls: 0.3350, loss_bbox: 0.3149, loss: 0.6499
2022-11-03 08:23:13,971 - mmdet - INFO - Epoch [3][150/3665]	lr: 1.866e-04, eta: 3:07:03, time: 0.385, data_time: 0.018, memory: 5251, loss_cls: 0.3446, loss_bbox: 0.3124, loss: 0.6570
2022-11-03 08:23:38,589 - mmdet - INFO - Epoch [3][200/3665]	lr: 1.866e-04, eta: 3:34:56, time: 0.493, data_time: 0.016, memory: 5251, loss_cls: 0.3444, loss_bbox: 0.3173, loss: 0.6617
2022-11-03 08:24:02,233 - mmdet - INFO - Epoch [3][250/3665]	lr: 1.866e-04, eta: 3:49:04, time: 0.473, data_time: 0.016, memory: 5251, loss_cls: 0.3337, loss_bbox: 0.3170, loss: 0.6508
2022-11-03 08:24:26,156 - mmdet - INFO - Epoch [3][300/3665]	lr: 1.866e-04, eta: 3:58:56, time: 0.478, data_time: 0.017, memory: 5251, loss_cls: 0.3326, loss_bbox: 0.3165, loss: 0.6492
2022-11-03 08:24:50,797 - mmdet - INFO - Epoch [3][350/3665]	lr: 1.866e-04, eta: 4:07:07, time: 0.493, data_time: 0.017, memory: 5251, loss_cls: 0.3371, loss_bbox: 0.3146, loss: 0.6516
2022-11-03 08:25:15,408 - mmdet - INFO - Epoch [3][400/3665]	lr: 1.866e-04, eta: 4:13:06, time: 0.492, data_time: 0.018, memory: 5251, loss_cls: 0.3331, loss_bbox: 0.3125, loss: 0.6456
2022-11-03 08:25:39,905 - mmdet - INFO - Epoch [3][450/3665]	lr: 1.866e-04, eta: 4:17:30, time: 0.490, data_time: 0.018, memory: 5251, loss_cls: 0.3354, loss_bbox: 0.3145, loss: 0.6499
2022-11-03 08:26:02,741 - mmdet - INFO - Epoch [3][500/3665]	lr: 1.866e-04, eta: 4:18:57, time: 0.457, data_time: 0.018, memory: 5251, loss_cls: 0.3328, loss_bbox: 0.3115, loss: 0.6443
2022-11-03 08:26:26,399 - mmdet - INFO - Epoch [3][550/3665]	lr: 1.866e-04, eta: 4:20:58, time: 0.473, data_time: 0.018, memory: 5251, loss_cls: 0.3383, loss_bbox: 0.3130, loss: 0.6513
2022-11-03 08:26:50,432 - mmdet - INFO - Epoch [3][600/3665]	lr: 1.866e-04, eta: 4:22:58, time: 0.481, data_time: 0.018, memory: 5251, loss_cls: 0.3428, loss_bbox: 0.3191, loss: 0.6619
2022-11-03 08:27:14,021 - mmdet - INFO - Epoch [3][650/3665]	lr: 1.866e-04, eta: 4:24:09, time: 0.472, data_time: 0.018, memory: 5251, loss_cls: 0.3398, loss_bbox: 0.3174, loss: 0.6571
2022-11-03 08:27:37,066 - mmdet - INFO - Epoch [3][700/3665]	lr: 1.866e-04, eta: 4:24:41, time: 0.461, data_time: 0.017, memory: 5251, loss_cls: 0.3244, loss_bbox: 0.3099, loss: 0.6343
2022-11-03 08:28:01,222 - mmdet - INFO - Epoch [3][750/3665]	lr: 1.866e-04, eta: 4:25:58, time: 0.483, data_time: 0.018, memory: 5251, loss_cls: 0.3361, loss_bbox: 0.3127, loss: 0.6488
2022-11-03 08:28:24,393 - mmdet - INFO - Epoch [3][800/3665]	lr: 1.866e-04, eta: 4:26:18, time: 0.463, data_time: 0.017, memory: 5251, loss_cls: 0.3395, loss_bbox: 0.3185, loss: 0.6579
2022-11-03 08:28:48,000 - mmdet - INFO - Epoch [3][850/3665]	lr: 1.866e-04, eta: 4:26:51, time: 0.472, data_time: 0.018, memory: 5251, loss_cls: 0.3371, loss_bbox: 0.3152, loss: 0.6523
2022-11-03 08:29:11,478 - mmdet - INFO - Epoch [3][900/3665]	lr: 1.866e-04, eta: 4:27:13, time: 0.470, data_time: 0.018, memory: 5251, loss_cls: 0.3336, loss_bbox: 0.3143, loss: 0.6479
2022-11-03 08:29:35,404 - mmdet - INFO - Epoch [3][950/3665]	lr: 1.866e-04, eta: 4:27:47, time: 0.479, data_time: 0.019, memory: 5251, loss_cls: 0.3418, loss_bbox: 0.3105, loss: 0.6522
2022-11-03 08:29:59,769 - mmdet - INFO - Epoch [3][1000/3665]	lr: 1.866e-04, eta: 4:28:31, time: 0.487, data_time: 0.018, memory: 5251, loss_cls: 0.3318, loss_bbox: 0.3140, loss: 0.6458
2022-11-03 08:30:23,252 - mmdet - INFO - Epoch [3][1050/3665]	lr: 1.866e-04, eta: 4:28:38, time: 0.470, data_time: 0.016, memory: 5251, loss_cls: 0.3284, loss_bbox: 0.3080, loss: 0.6364
2022-11-03 08:30:47,730 - mmdet - INFO - Epoch [3][1100/3665]	lr: 1.866e-04, eta: 4:29:15, time: 0.490, data_time: 0.017, memory: 5251, loss_cls: 0.3353, loss_bbox: 0.3100, loss: 0.6453
2022-11-03 08:31:11,540 - mmdet - INFO - Epoch [3][1150/3665]	lr: 1.866e-04, eta: 4:29:26, time: 0.476, data_time: 0.019, memory: 5251, loss_cls: 0.3323, loss_bbox: 0.3124, loss: 0.6448
2022-11-03 08:31:35,286 - mmdet - INFO - Epoch [3][1200/3665]	lr: 1.866e-04, eta: 4:29:32, time: 0.475, data_time: 0.019, memory: 5251, loss_cls: 0.3330, loss_bbox: 0.3089, loss: 0.6419
2022-11-03 08:31:58,792 - mmdet - INFO - Epoch [3][1250/3665]	lr: 1.866e-04, eta: 4:29:29, time: 0.470, data_time: 0.018, memory: 5251, loss_cls: 0.3327, loss_bbox: 0.3128, loss: 0.6455
2022-11-03 08:32:22,760 - mmdet - INFO - Epoch [3][1300/3665]	lr: 1.866e-04, eta: 4:29:37, time: 0.479, data_time: 0.019, memory: 5251, loss_cls: 0.3374, loss_bbox: 0.3109, loss: 0.6483
2022-11-03 08:32:47,821 - mmdet - INFO - Epoch [3][1350/3665]	lr: 1.866e-04, eta: 4:30:11, time: 0.501, data_time: 0.018, memory: 5251, loss_cls: 0.3312, loss_bbox: 0.3115, loss: 0.6427
2022-11-03 08:33:12,207 - mmdet - INFO - Epoch [3][1400/3665]	lr: 1.866e-04, eta: 4:30:24, time: 0.488, data_time: 0.018, memory: 5251, loss_cls: 0.3394, loss_bbox: 0.3166, loss: 0.6560
2022-11-03 08:33:35,893 - mmdet - INFO - Epoch [3][1450/3665]	lr: 1.866e-04, eta: 4:30:17, time: 0.474, data_time: 0.019, memory: 5251, loss_cls: 0.3273, loss_bbox: 0.3139, loss: 0.6412
2022-11-03 08:33:59,394 - mmdet - INFO - Epoch [3][1500/3665]	lr: 1.866e-04, eta: 4:30:05, time: 0.470, data_time: 0.018, memory: 5251, loss_cls: 0.3265, loss_bbox: 0.3108, loss: 0.6373
2022-11-03 08:34:23,721 - mmdet - INFO - Epoch [3][1550/3665]	lr: 1.866e-04, eta: 4:30:11, time: 0.487, data_time: 0.018, memory: 5251, loss_cls: 0.3337, loss_bbox: 0.3118, loss: 0.6455
2022-11-03 08:34:47,719 - mmdet - INFO - Epoch [3][1600/3665]	lr: 1.866e-04, eta: 4:30:07, time: 0.479, data_time: 0.019, memory: 5251, loss_cls: 0.3325, loss_bbox: 0.3107, loss: 0.6432
2022-11-03 08:35:11,646 - mmdet - INFO - Epoch [3][1650/3665]	lr: 1.866e-04, eta: 4:30:01, time: 0.479, data_time: 0.019, memory: 5251, loss_cls: 0.3331, loss_bbox: 0.3146, loss: 0.6476
2022-11-03 08:35:34,890 - mmdet - INFO - Epoch [3][1700/3665]	lr: 1.866e-04, eta: 4:29:40, time: 0.465, data_time: 0.018, memory: 5251, loss_cls: 0.3342, loss_bbox: 0.3151, loss: 0.6493
2022-11-03 08:35:59,258 - mmdet - INFO - Epoch [3][1750/3665]	lr: 1.866e-04, eta: 4:29:41, time: 0.487, data_time: 0.018, memory: 5251, loss_cls: 0.3281, loss_bbox: 0.3118, loss: 0.6398
2022-11-03 08:36:23,289 - mmdet - INFO - Epoch [3][1800/3665]	lr: 1.866e-04, eta: 4:29:35, time: 0.481, data_time: 0.018, memory: 5251, loss_cls: 0.3336, loss_bbox: 0.3145, loss: 0.6481
2022-11-03 08:36:47,614 - mmdet - INFO - Epoch [3][1850/3665]	lr: 1.866e-04, eta: 4:29:32, time: 0.486, data_time: 0.018, memory: 5251, loss_cls: 0.3315, loss_bbox: 0.3143, loss: 0.6459
2022-11-03 08:37:12,216 - mmdet - INFO - Epoch [3][1900/3665]	lr: 1.866e-04, eta: 4:29:34, time: 0.492, data_time: 0.021, memory: 5252, loss_cls: 0.3251, loss_bbox: 0.3072, loss: 0.6323
2022-11-03 08:37:35,961 - mmdet - INFO - Epoch [3][1950/3665]	lr: 1.866e-04, eta: 4:29:19, time: 0.475, data_time: 0.018, memory: 5252, loss_cls: 0.3376, loss_bbox: 0.3124, loss: 0.6500
2022-11-03 08:37:59,455 - mmdet - INFO - Epoch [3][2000/3665]	lr: 1.866e-04, eta: 4:29:00, time: 0.470, data_time: 0.017, memory: 5252, loss_cls: 0.3235, loss_bbox: 0.3103, loss: 0.6338
2022-11-03 08:38:23,368 - mmdet - INFO - Epoch [3][2050/3665]	lr: 1.866e-04, eta: 4:28:47, time: 0.478, data_time: 0.018, memory: 5252, loss_cls: 0.3336, loss_bbox: 0.3117, loss: 0.6452
2022-11-03 08:38:46,947 - mmdet - INFO - Epoch [3][2100/3665]	lr: 1.866e-04, eta: 4:28:28, time: 0.471, data_time: 0.017, memory: 5252, loss_cls: 0.3337, loss_bbox: 0.3165, loss: 0.6503
2022-11-03 08:39:10,589 - mmdet - INFO - Epoch [3][2150/3665]	lr: 1.866e-04, eta: 4:28:10, time: 0.473, data_time: 0.017, memory: 5252, loss_cls: 0.3314, loss_bbox: 0.3085, loss: 0.6399
2022-11-03 08:39:34,297 - mmdet - INFO - Epoch [3][2200/3665]	lr: 1.866e-04, eta: 4:27:53, time: 0.474, data_time: 0.016, memory: 5252, loss_cls: 0.3283, loss_bbox: 0.3098, loss: 0.6380
2022-11-03 08:39:58,471 - mmdet - INFO - Epoch [3][2250/3665]	lr: 1.866e-04, eta: 4:27:42, time: 0.483, data_time: 0.024, memory: 5252, loss_cls: 0.3297, loss_bbox: 0.3116, loss: 0.6413
2022-11-03 08:40:22,849 - mmdet - INFO - Epoch [3][2300/3665]	lr: 1.866e-04, eta: 4:27:34, time: 0.488, data_time: 0.018, memory: 5252, loss_cls: 0.3212, loss_bbox: 0.3088, loss: 0.6300
2022-11-03 08:40:46,635 - mmdet - INFO - Epoch [3][2350/3665]	lr: 1.866e-04, eta: 4:27:17, time: 0.476, data_time: 0.022, memory: 5252, loss_cls: 0.3330, loss_bbox: 0.3124, loss: 0.6454
2022-11-03 08:41:11,157 - mmdet - INFO - Epoch [3][2400/3665]	lr: 1.866e-04, eta: 4:27:10, time: 0.490, data_time: 0.018, memory: 5252, loss_cls: 0.3311, loss_bbox: 0.3080, loss: 0.6390
2022-11-03 08:41:35,423 - mmdet - INFO - Epoch [3][2450/3665]	lr: 1.866e-04, eta: 4:26:59, time: 0.485, data_time: 0.017, memory: 5252, loss_cls: 0.3316, loss_bbox: 0.3119, loss: 0.6436
2022-11-03 08:41:59,806 - mmdet - INFO - Epoch [3][2500/3665]	lr: 1.866e-04, eta: 4:26:48, time: 0.488, data_time: 0.017, memory: 5252, loss_cls: 0.3234, loss_bbox: 0.3103, loss: 0.6338
2022-11-03 08:42:23,815 - mmdet - INFO - Epoch [3][2550/3665]	lr: 1.866e-04, eta: 4:26:33, time: 0.480, data_time: 0.017, memory: 5252, loss_cls: 0.3269, loss_bbox: 0.3104, loss: 0.6372
2022-11-03 08:42:47,759 - mmdet - INFO - Epoch [3][2600/3665]	lr: 1.866e-04, eta: 4:26:16, time: 0.479, data_time: 0.017, memory: 5252, loss_cls: 0.3345, loss_bbox: 0.3113, loss: 0.6458
2022-11-03 08:43:11,697 - mmdet - INFO - Epoch [3][2650/3665]	lr: 1.866e-04, eta: 4:25:58, time: 0.479, data_time: 0.027, memory: 5252, loss_cls: 0.3269, loss_bbox: 0.3114, loss: 0.6383
2022-11-03 08:43:35,561 - mmdet - INFO - Epoch [3][2700/3665]	lr: 1.866e-04, eta: 4:25:40, time: 0.477, data_time: 0.017, memory: 5252, loss_cls: 0.3242, loss_bbox: 0.3089, loss: 0.6331
2022-11-03 08:43:59,211 - mmdet - INFO - Epoch [3][2750/3665]	lr: 1.866e-04, eta: 4:25:18, time: 0.473, data_time: 0.018, memory: 5252, loss_cls: 0.3365, loss_bbox: 0.3158, loss: 0.6523
2022-11-03 08:44:22,554 - mmdet - INFO - Epoch [3][2800/3665]	lr: 1.866e-04, eta: 4:24:53, time: 0.467, data_time: 0.019, memory: 5252, loss_cls: 0.3240, loss_bbox: 0.3082, loss: 0.6322
2022-11-03 08:44:47,605 - mmdet - INFO - Epoch [3][2850/3665]	lr: 1.866e-04, eta: 4:24:49, time: 0.501, data_time: 0.030, memory: 5252, loss_cls: 0.3283, loss_bbox: 0.3136, loss: 0.6419
2022-11-03 08:45:12,716 - mmdet - INFO - Epoch [3][2900/3665]	lr: 1.866e-04, eta: 4:24:44, time: 0.502, data_time: 0.027, memory: 5252, loss_cls: 0.3250, loss_bbox: 0.3084, loss: 0.6334
2022-11-03 08:45:37,810 - mmdet - INFO - Epoch [3][2950/3665]	lr: 1.866e-04, eta: 4:24:38, time: 0.502, data_time: 0.032, memory: 5252, loss_cls: 0.3284, loss_bbox: 0.3085, loss: 0.6369
2022-11-03 08:46:03,192 - mmdet - INFO - Epoch [3][3000/3665]	lr: 1.866e-04, eta: 4:24:35, time: 0.508, data_time: 0.051, memory: 5252, loss_cls: 0.3285, loss_bbox: 0.3117, loss: 0.6402
2022-11-03 08:46:27,605 - mmdet - INFO - Epoch [3][3050/3665]	lr: 1.866e-04, eta: 4:24:20, time: 0.488, data_time: 0.034, memory: 5252, loss_cls: 0.3243, loss_bbox: 0.3104, loss: 0.6347
2022-11-03 08:46:51,938 - mmdet - INFO - Epoch [3][3100/3665]	lr: 1.866e-04, eta: 4:24:05, time: 0.487, data_time: 0.023, memory: 5252, loss_cls: 0.3306, loss_bbox: 0.3088, loss: 0.6395
2022-11-03 08:47:16,306 - mmdet - INFO - Epoch [3][3150/3665]	lr: 1.866e-04, eta: 4:23:49, time: 0.487, data_time: 0.019, memory: 5252, loss_cls: 0.3330, loss_bbox: 0.3127, loss: 0.6457
2022-11-03 08:47:40,249 - mmdet - INFO - Epoch [3][3200/3665]	lr: 1.866e-04, eta: 4:23:29, time: 0.479, data_time: 0.019, memory: 5252, loss_cls: 0.3198, loss_bbox: 0.3039, loss: 0.6237
2022-11-03 08:48:05,185 - mmdet - INFO - Epoch [3][3250/3665]	lr: 1.866e-04, eta: 4:23:19, time: 0.499, data_time: 0.019, memory: 5252, loss_cls: 0.3289, loss_bbox: 0.3059, loss: 0.6348
2022-11-03 08:48:29,481 - mmdet - INFO - Epoch [3][3300/3665]	lr: 1.866e-04, eta: 4:23:01, time: 0.486, data_time: 0.019, memory: 5252, loss_cls: 0.3279, loss_bbox: 0.3098, loss: 0.6377
2022-11-03 08:48:53,194 - mmdet - INFO - Epoch [3][3350/3665]	lr: 1.866e-04, eta: 4:22:38, time: 0.474, data_time: 0.019, memory: 5252, loss_cls: 0.3257, loss_bbox: 0.3072, loss: 0.6330
2022-11-03 08:49:18,352 - mmdet - INFO - Epoch [3][3400/3665]	lr: 1.866e-04, eta: 4:22:29, time: 0.503, data_time: 0.018, memory: 5252, loss_cls: 0.3286, loss_bbox: 0.3137, loss: 0.6423
2022-11-03 08:49:42,679 - mmdet - INFO - Epoch [3][3450/3665]	lr: 1.866e-04, eta: 4:22:12, time: 0.487, data_time: 0.018, memory: 5252, loss_cls: 0.3302, loss_bbox: 0.3065, loss: 0.6367
2022-11-03 08:50:07,514 - mmdet - INFO - Epoch [3][3500/3665]	lr: 1.866e-04, eta: 4:21:59, time: 0.497, data_time: 0.020, memory: 5252, loss_cls: 0.3199, loss_bbox: 0.3016, loss: 0.6215
2022-11-03 08:50:33,385 - mmdet - INFO - Epoch [3][3550/3665]	lr: 1.866e-04, eta: 4:21:55, time: 0.517, data_time: 0.041, memory: 5252, loss_cls: 0.3229, loss_bbox: 0.3047, loss: 0.6276
2022-11-03 08:50:57,813 - mmdet - INFO - Epoch [3][3600/3665]	lr: 1.866e-04, eta: 4:21:38, time: 0.489, data_time: 0.019, memory: 5252, loss_cls: 0.3281, loss_bbox: 0.3072, loss: 0.6353
2022-11-03 08:51:23,344 - mmdet - INFO - Epoch [3][3650/3665]	lr: 1.866e-04, eta: 4:21:30, time: 0.510, data_time: 0.044, memory: 5252, loss_cls: 0.3322, loss_bbox: 0.3078, loss: 0.6399
2022-11-03 08:51:32,148 - mmdet - INFO - Saving checkpoint at 3 epochs
2022-11-03 08:52:26,577 - mmdet - INFO - Evaluating bbox...
2022-11-03 08:53:27,778 - mmdet - INFO - 
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.456
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.286
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.154
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.304
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.374
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.469
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.469
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.266
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.504
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.629

2022-11-03 08:53:28,898 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 08:53:28,898 - mmdet - INFO - Epoch(val) [3][625]	bbox_mAP: 0.2770, bbox_mAP_50: 0.4560, bbox_mAP_75: 0.2860, bbox_mAP_s: 0.1540, bbox_mAP_m: 0.3040, bbox_mAP_l: 0.3740, bbox_mAP_copypaste: 0.277 0.456 0.286 0.154 0.304 0.374
2022-11-03 08:53:57,166 - mmdet - INFO - Epoch [4][50/3665]	lr: 1.707e-04, eta: 4:20:36, time: 0.565, data_time: 0.076, memory: 5252, loss_cls: 0.3058, loss_bbox: 0.2944, loss: 0.6002
2022-11-03 08:54:21,621 - mmdet - INFO - Epoch [4][100/3665]	lr: 1.707e-04, eta: 4:20:18, time: 0.489, data_time: 0.016, memory: 5252, loss_cls: 0.3053, loss_bbox: 0.2968, loss: 0.6021
2022-11-03 08:54:46,965 - mmdet - INFO - Epoch [4][150/3665]	lr: 1.707e-04, eta: 4:20:08, time: 0.507, data_time: 0.016, memory: 5252, loss_cls: 0.3068, loss_bbox: 0.2977, loss: 0.6045
2022-11-03 08:55:12,541 - mmdet - INFO - Epoch [4][200/3665]	lr: 1.707e-04, eta: 4:20:00, time: 0.511, data_time: 0.018, memory: 5252, loss_cls: 0.3107, loss_bbox: 0.2992, loss: 0.6099
2022-11-03 08:55:36,945 - mmdet - INFO - Epoch [4][250/3665]	lr: 1.707e-04, eta: 4:19:41, time: 0.488, data_time: 0.016, memory: 5252, loss_cls: 0.3027, loss_bbox: 0.2986, loss: 0.6013
2022-11-03 08:56:01,927 - mmdet - INFO - Epoch [4][300/3665]	lr: 1.707e-04, eta: 4:19:27, time: 0.500, data_time: 0.017, memory: 5252, loss_cls: 0.3091, loss_bbox: 0.2986, loss: 0.6077
2022-11-03 08:56:26,741 - mmdet - INFO - Epoch [4][350/3665]	lr: 1.707e-04, eta: 4:19:11, time: 0.496, data_time: 0.017, memory: 5252, loss_cls: 0.3095, loss_bbox: 0.3064, loss: 0.6160
2022-11-03 08:56:52,063 - mmdet - INFO - Epoch [4][400/3665]	lr: 1.707e-04, eta: 4:18:59, time: 0.506, data_time: 0.017, memory: 5252, loss_cls: 0.3069, loss_bbox: 0.2992, loss: 0.6061
2022-11-03 08:57:17,074 - mmdet - INFO - Epoch [4][450/3665]	lr: 1.707e-04, eta: 4:18:45, time: 0.500, data_time: 0.017, memory: 5252, loss_cls: 0.3110, loss_bbox: 0.3000, loss: 0.6110
2022-11-03 08:57:42,652 - mmdet - INFO - Epoch [4][500/3665]	lr: 1.707e-04, eta: 4:18:34, time: 0.511, data_time: 0.017, memory: 5252, loss_cls: 0.3085, loss_bbox: 0.2960, loss: 0.6045
2022-11-03 08:58:06,940 - mmdet - INFO - Epoch [4][550/3665]	lr: 1.707e-04, eta: 4:18:14, time: 0.486, data_time: 0.020, memory: 5252, loss_cls: 0.3114, loss_bbox: 0.3044, loss: 0.6158
2022-11-03 08:58:31,874 - mmdet - INFO - Epoch [4][600/3665]	lr: 1.707e-04, eta: 4:17:58, time: 0.499, data_time: 0.017, memory: 5252, loss_cls: 0.3059, loss_bbox: 0.2977, loss: 0.6036
2022-11-03 08:58:57,426 - mmdet - INFO - Epoch [4][650/3665]	lr: 1.707e-04, eta: 4:17:46, time: 0.511, data_time: 0.018, memory: 5252, loss_cls: 0.3152, loss_bbox: 0.3047, loss: 0.6198
2022-11-03 08:59:22,245 - mmdet - INFO - Epoch [4][700/3665]	lr: 1.707e-04, eta: 4:17:29, time: 0.497, data_time: 0.017, memory: 5252, loss_cls: 0.3057, loss_bbox: 0.3009, loss: 0.6065
2022-11-03 08:59:46,657 - mmdet - INFO - Epoch [4][750/3665]	lr: 1.707e-04, eta: 4:17:09, time: 0.488, data_time: 0.017, memory: 5252, loss_cls: 0.3030, loss_bbox: 0.2934, loss: 0.5964
2022-11-03 09:00:11,182 - mmdet - INFO - Epoch [4][800/3665]	lr: 1.707e-04, eta: 4:16:49, time: 0.490, data_time: 0.017, memory: 5252, loss_cls: 0.3146, loss_bbox: 0.2948, loss: 0.6094
2022-11-03 09:00:35,666 - mmdet - INFO - Epoch [4][850/3665]	lr: 1.707e-04, eta: 4:16:29, time: 0.490, data_time: 0.018, memory: 5252, loss_cls: 0.3108, loss_bbox: 0.3026, loss: 0.6134
2022-11-03 09:01:01,258 - mmdet - INFO - Epoch [4][900/3665]	lr: 1.707e-04, eta: 4:16:17, time: 0.512, data_time: 0.018, memory: 5252, loss_cls: 0.3054, loss_bbox: 0.2961, loss: 0.6014
2022-11-03 09:01:26,199 - mmdet - INFO - Epoch [4][950/3665]	lr: 1.707e-04, eta: 4:15:59, time: 0.499, data_time: 0.016, memory: 5252, loss_cls: 0.3062, loss_bbox: 0.3006, loss: 0.6068
2022-11-03 09:01:51,494 - mmdet - INFO - Epoch [4][1000/3665]	lr: 1.707e-04, eta: 4:15:44, time: 0.506, data_time: 0.017, memory: 5252, loss_cls: 0.3064, loss_bbox: 0.2917, loss: 0.5981
2022-11-03 09:02:15,519 - mmdet - INFO - Epoch [4][1050/3665]	lr: 1.707e-04, eta: 4:15:21, time: 0.481, data_time: 0.017, memory: 5252, loss_cls: 0.3083, loss_bbox: 0.3029, loss: 0.6112
2022-11-03 09:02:40,350 - mmdet - INFO - Epoch [4][1100/3665]	lr: 1.707e-04, eta: 4:15:02, time: 0.497, data_time: 0.018, memory: 5252, loss_cls: 0.3073, loss_bbox: 0.2990, loss: 0.6063
2022-11-03 09:03:05,205 - mmdet - INFO - Epoch [4][1150/3665]	lr: 1.707e-04, eta: 4:14:44, time: 0.497, data_time: 0.016, memory: 5252, loss_cls: 0.3096, loss_bbox: 0.2972, loss: 0.6067
2022-11-03 09:03:30,030 - mmdet - INFO - Epoch [4][1200/3665]	lr: 1.707e-04, eta: 4:14:25, time: 0.497, data_time: 0.017, memory: 5252, loss_cls: 0.3073, loss_bbox: 0.2967, loss: 0.6040
2022-11-03 09:03:55,226 - mmdet - INFO - Epoch [4][1250/3665]	lr: 1.707e-04, eta: 4:14:09, time: 0.504, data_time: 0.020, memory: 5252, loss_cls: 0.3165, loss_bbox: 0.2995, loss: 0.6161
2022-11-03 09:04:20,217 - mmdet - INFO - Epoch [4][1300/3665]	lr: 1.707e-04, eta: 4:13:51, time: 0.500, data_time: 0.020, memory: 5252, loss_cls: 0.3081, loss_bbox: 0.3012, loss: 0.6093
2022-11-03 09:04:44,323 - mmdet - INFO - Epoch [4][1350/3665]	lr: 1.707e-04, eta: 4:13:27, time: 0.482, data_time: 0.020, memory: 5252, loss_cls: 0.3050, loss_bbox: 0.2980, loss: 0.6030
2022-11-03 09:05:09,307 - mmdet - INFO - Epoch [4][1400/3665]	lr: 1.707e-04, eta: 4:13:09, time: 0.500, data_time: 0.020, memory: 5252, loss_cls: 0.3147, loss_bbox: 0.3039, loss: 0.6187
2022-11-03 09:05:33,735 - mmdet - INFO - Epoch [4][1450/3665]	lr: 1.707e-04, eta: 4:12:48, time: 0.489, data_time: 0.020, memory: 5252, loss_cls: 0.3039, loss_bbox: 0.2926, loss: 0.5965
2022-11-03 09:05:58,860 - mmdet - INFO - Epoch [4][1500/3665]	lr: 1.707e-04, eta: 4:12:30, time: 0.502, data_time: 0.020, memory: 5252, loss_cls: 0.3105, loss_bbox: 0.3017, loss: 0.6121
2022-11-03 09:06:23,541 - mmdet - INFO - Epoch [4][1550/3665]	lr: 1.707e-04, eta: 4:12:10, time: 0.494, data_time: 0.020, memory: 5252, loss_cls: 0.3085, loss_bbox: 0.2943, loss: 0.6028
2022-11-03 09:06:48,504 - mmdet - INFO - Epoch [4][1600/3665]	lr: 1.707e-04, eta: 4:11:51, time: 0.499, data_time: 0.019, memory: 5252, loss_cls: 0.3108, loss_bbox: 0.2965, loss: 0.6073
2022-11-03 09:07:13,729 - mmdet - INFO - Epoch [4][1650/3665]	lr: 1.707e-04, eta: 4:11:34, time: 0.504, data_time: 0.027, memory: 5252, loss_cls: 0.3142, loss_bbox: 0.3027, loss: 0.6169
2022-11-03 09:07:38,819 - mmdet - INFO - Epoch [4][1700/3665]	lr: 1.707e-04, eta: 4:11:16, time: 0.502, data_time: 0.020, memory: 5252, loss_cls: 0.3056, loss_bbox: 0.2954, loss: 0.6010
2022-11-03 09:08:03,845 - mmdet - INFO - Epoch [4][1750/3665]	lr: 1.707e-04, eta: 4:10:57, time: 0.500, data_time: 0.020, memory: 5252, loss_cls: 0.3118, loss_bbox: 0.2966, loss: 0.6084
2022-11-03 09:08:28,291 - mmdet - INFO - Epoch [4][1800/3665]	lr: 1.707e-04, eta: 4:10:35, time: 0.489, data_time: 0.020, memory: 5252, loss_cls: 0.3127, loss_bbox: 0.3086, loss: 0.6214
2022-11-03 09:08:52,901 - mmdet - INFO - Epoch [4][1850/3665]	lr: 1.707e-04, eta: 4:10:13, time: 0.492, data_time: 0.020, memory: 5252, loss_cls: 0.3143, loss_bbox: 0.3010, loss: 0.6153
2022-11-03 09:09:18,524 - mmdet - INFO - Epoch [4][1900/3665]	lr: 1.707e-04, eta: 4:09:58, time: 0.513, data_time: 0.024, memory: 5252, loss_cls: 0.3031, loss_bbox: 0.2953, loss: 0.5985
2022-11-03 09:09:44,396 - mmdet - INFO - Epoch [4][1950/3665]	lr: 1.707e-04, eta: 4:09:43, time: 0.517, data_time: 0.046, memory: 5252, loss_cls: 0.3074, loss_bbox: 0.2975, loss: 0.6049
2022-11-03 09:10:10,197 - mmdet - INFO - Epoch [4][2000/3665]	lr: 1.707e-04, eta: 4:09:28, time: 0.516, data_time: 0.020, memory: 5252, loss_cls: 0.3059, loss_bbox: 0.2930, loss: 0.5988
2022-11-03 09:10:35,188 - mmdet - INFO - Epoch [4][2050/3665]	lr: 1.707e-04, eta: 4:09:09, time: 0.500, data_time: 0.022, memory: 5252, loss_cls: 0.3080, loss_bbox: 0.2975, loss: 0.6055
2022-11-03 09:11:00,772 - mmdet - INFO - Epoch [4][2100/3665]	lr: 1.707e-04, eta: 4:08:52, time: 0.512, data_time: 0.021, memory: 5252, loss_cls: 0.3025, loss_bbox: 0.2966, loss: 0.5991
2022-11-03 09:11:26,449 - mmdet - INFO - Epoch [4][2150/3665]	lr: 1.707e-04, eta: 4:08:36, time: 0.514, data_time: 0.021, memory: 5252, loss_cls: 0.3025, loss_bbox: 0.3004, loss: 0.6028
2022-11-03 09:11:52,358 - mmdet - INFO - Epoch [4][2200/3665]	lr: 1.707e-04, eta: 4:08:21, time: 0.518, data_time: 0.022, memory: 5252, loss_cls: 0.3102, loss_bbox: 0.2983, loss: 0.6084
2022-11-03 09:12:16,978 - mmdet - INFO - Epoch [4][2250/3665]	lr: 1.707e-04, eta: 4:07:59, time: 0.492, data_time: 0.021, memory: 5252, loss_cls: 0.3081, loss_bbox: 0.2984, loss: 0.6065
2022-11-03 09:12:41,819 - mmdet - INFO - Epoch [4][2300/3665]	lr: 1.707e-04, eta: 4:07:38, time: 0.497, data_time: 0.021, memory: 5252, loss_cls: 0.3121, loss_bbox: 0.3028, loss: 0.6148
2022-11-03 09:13:06,911 - mmdet - INFO - Epoch [4][2350/3665]	lr: 1.707e-04, eta: 4:07:18, time: 0.502, data_time: 0.022, memory: 5252, loss_cls: 0.3099, loss_bbox: 0.3021, loss: 0.6120
2022-11-03 09:13:32,747 - mmdet - INFO - Epoch [4][2400/3665]	lr: 1.707e-04, eta: 4:07:02, time: 0.517, data_time: 0.021, memory: 5252, loss_cls: 0.3070, loss_bbox: 0.2990, loss: 0.6060
2022-11-03 09:13:58,796 - mmdet - INFO - Epoch [4][2450/3665]	lr: 1.707e-04, eta: 4:06:47, time: 0.521, data_time: 0.030, memory: 5252, loss_cls: 0.3071, loss_bbox: 0.2986, loss: 0.6056
2022-11-03 09:14:23,795 - mmdet - INFO - Epoch [4][2500/3665]	lr: 1.707e-04, eta: 4:06:26, time: 0.500, data_time: 0.023, memory: 5252, loss_cls: 0.3078, loss_bbox: 0.2963, loss: 0.6041
2022-11-03 09:14:49,102 - mmdet - INFO - Epoch [4][2550/3665]	lr: 1.707e-04, eta: 4:06:07, time: 0.506, data_time: 0.022, memory: 5252, loss_cls: 0.3104, loss_bbox: 0.2971, loss: 0.6075
2022-11-03 09:15:13,953 - mmdet - INFO - Epoch [4][2600/3665]	lr: 1.707e-04, eta: 4:05:46, time: 0.497, data_time: 0.022, memory: 5252, loss_cls: 0.3096, loss_bbox: 0.3028, loss: 0.6124
2022-11-03 09:15:39,090 - mmdet - INFO - Epoch [4][2650/3665]	lr: 1.707e-04, eta: 4:05:26, time: 0.503, data_time: 0.021, memory: 5252, loss_cls: 0.3142, loss_bbox: 0.2998, loss: 0.6140
2022-11-03 09:16:03,971 - mmdet - INFO - Epoch [4][2700/3665]	lr: 1.707e-04, eta: 4:05:04, time: 0.498, data_time: 0.020, memory: 5252, loss_cls: 0.3140, loss_bbox: 0.2972, loss: 0.6112
2022-11-03 09:16:20,512 - mmdet - INFO - Epoch [4][2750/3665]	lr: 1.707e-04, eta: 4:04:04, time: 0.331, data_time: 0.023, memory: 5252, loss_cls: 0.3111, loss_bbox: 0.3010, loss: 0.6121
2022-11-03 09:16:36,127 - mmdet - INFO - Epoch [4][2800/3665]	lr: 1.707e-04, eta: 4:02:59, time: 0.312, data_time: 0.019, memory: 5252, loss_cls: 0.3040, loss_bbox: 0.2987, loss: 0.6028
2022-11-03 09:16:51,792 - mmdet - INFO - Epoch [4][2850/3665]	lr: 1.707e-04, eta: 4:01:56, time: 0.313, data_time: 0.020, memory: 5252, loss_cls: 0.3144, loss_bbox: 0.2988, loss: 0.6132
2022-11-03 09:17:07,768 - mmdet - INFO - Epoch [4][2900/3665]	lr: 1.707e-04, eta: 4:00:55, time: 0.319, data_time: 0.019, memory: 5252, loss_cls: 0.3111, loss_bbox: 0.2978, loss: 0.6089
2022-11-03 09:17:26,310 - mmdet - INFO - Epoch [4][2950/3665]	lr: 1.707e-04, eta: 4:00:06, time: 0.371, data_time: 0.029, memory: 5252, loss_cls: 0.3118, loss_bbox: 0.3012, loss: 0.6130
2022-11-03 09:18:04,476 - mmdet - INFO - Epoch [4][3000/3665]	lr: 1.707e-04, eta: 4:00:45, time: 0.763, data_time: 0.019, memory: 5252, loss_cls: 0.3087, loss_bbox: 0.3006, loss: 0.6094
2022-11-03 09:18:42,101 - mmdet - INFO - Epoch [4][3050/3665]	lr: 1.707e-04, eta: 4:01:22, time: 0.752, data_time: 0.018, memory: 5252, loss_cls: 0.3030, loss_bbox: 0.2958, loss: 0.5987
2022-11-03 09:19:15,050 - mmdet - INFO - Epoch [4][3100/3665]	lr: 1.707e-04, eta: 4:01:36, time: 0.659, data_time: 0.018, memory: 5252, loss_cls: 0.3073, loss_bbox: 0.2964, loss: 0.6037
2022-11-03 09:19:40,073 - mmdet - INFO - Epoch [4][3150/3665]	lr: 1.707e-04, eta: 4:01:15, time: 0.500, data_time: 0.019, memory: 5252, loss_cls: 0.3068, loss_bbox: 0.2937, loss: 0.6005
2022-11-03 09:20:04,858 - mmdet - INFO - Epoch [4][3200/3665]	lr: 1.707e-04, eta: 4:00:53, time: 0.496, data_time: 0.020, memory: 5252, loss_cls: 0.3020, loss_bbox: 0.2991, loss: 0.6010
2022-11-03 09:20:29,632 - mmdet - INFO - Epoch [4][3250/3665]	lr: 1.707e-04, eta: 4:00:31, time: 0.496, data_time: 0.020, memory: 5252, loss_cls: 0.3079, loss_bbox: 0.3011, loss: 0.6090
2022-11-03 09:20:55,109 - mmdet - INFO - Epoch [4][3300/3665]	lr: 1.707e-04, eta: 4:00:12, time: 0.509, data_time: 0.020, memory: 5252, loss_cls: 0.3094, loss_bbox: 0.3012, loss: 0.6106
2022-11-03 09:21:20,587 - mmdet - INFO - Epoch [4][3350/3665]	lr: 1.707e-04, eta: 3:59:53, time: 0.509, data_time: 0.020, memory: 5252, loss_cls: 0.3056, loss_bbox: 0.2976, loss: 0.6033
2022-11-03 09:21:45,569 - mmdet - INFO - Epoch [4][3400/3665]	lr: 1.707e-04, eta: 3:59:32, time: 0.500, data_time: 0.022, memory: 5252, loss_cls: 0.3070, loss_bbox: 0.3031, loss: 0.6101
2022-11-03 09:22:10,135 - mmdet - INFO - Epoch [4][3450/3665]	lr: 1.707e-04, eta: 3:59:08, time: 0.491, data_time: 0.021, memory: 5252, loss_cls: 0.3053, loss_bbox: 0.2965, loss: 0.6018
2022-11-03 09:22:35,956 - mmdet - INFO - Epoch [4][3500/3665]	lr: 1.707e-04, eta: 3:58:50, time: 0.517, data_time: 0.022, memory: 5252, loss_cls: 0.3038, loss_bbox: 0.2951, loss: 0.5989
2022-11-03 09:23:01,335 - mmdet - INFO - Epoch [4][3550/3665]	lr: 1.707e-04, eta: 3:58:31, time: 0.508, data_time: 0.021, memory: 5252, loss_cls: 0.3080, loss_bbox: 0.2950, loss: 0.6030
2022-11-03 09:23:26,552 - mmdet - INFO - Epoch [4][3600/3665]	lr: 1.707e-04, eta: 3:58:10, time: 0.504, data_time: 0.021, memory: 5252, loss_cls: 0.3076, loss_bbox: 0.2980, loss: 0.6056
2022-11-03 09:23:51,776 - mmdet - INFO - Epoch [4][3650/3665]	lr: 1.707e-04, eta: 3:57:49, time: 0.505, data_time: 0.021, memory: 5252, loss_cls: 0.3070, loss_bbox: 0.2976, loss: 0.6046
2022-11-03 09:23:59,416 - mmdet - INFO - Saving checkpoint at 4 epochs
2022-11-03 09:24:54,964 - mmdet - INFO - Evaluating bbox...
2022-11-03 09:26:01,422 - mmdet - INFO - 
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.481
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.317
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.166
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.322
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.403
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.480
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.480
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.286
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.515
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.633

2022-11-03 09:26:02,810 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 09:26:02,811 - mmdet - INFO - Epoch(val) [4][625]	bbox_mAP: 0.2980, bbox_mAP_50: 0.4810, bbox_mAP_75: 0.3170, bbox_mAP_s: 0.1660, bbox_mAP_m: 0.3220, bbox_mAP_l: 0.4030, bbox_mAP_copypaste: 0.298 0.481 0.317 0.166 0.322 0.403
2022-11-03 09:26:32,064 - mmdet - INFO - Epoch [5][50/3665]	lr: 1.500e-04, eta: 3:57:06, time: 0.573, data_time: 0.079, memory: 5252, loss_cls: 0.2841, loss_bbox: 0.2839, loss: 0.5680
2022-11-03 09:26:57,274 - mmdet - INFO - Epoch [5][100/3665]	lr: 1.500e-04, eta: 3:56:45, time: 0.504, data_time: 0.017, memory: 5252, loss_cls: 0.2842, loss_bbox: 0.2832, loss: 0.5674
2022-11-03 09:27:22,330 - mmdet - INFO - Epoch [5][150/3665]	lr: 1.500e-04, eta: 3:56:24, time: 0.501, data_time: 0.018, memory: 5252, loss_cls: 0.2864, loss_bbox: 0.2869, loss: 0.5733
2022-11-03 09:27:47,880 - mmdet - INFO - Epoch [5][200/3665]	lr: 1.500e-04, eta: 3:56:04, time: 0.511, data_time: 0.017, memory: 5252, loss_cls: 0.2830, loss_bbox: 0.2882, loss: 0.5712
2022-11-03 09:28:12,986 - mmdet - INFO - Epoch [5][250/3665]	lr: 1.500e-04, eta: 3:55:43, time: 0.502, data_time: 0.025, memory: 5252, loss_cls: 0.2912, loss_bbox: 0.2905, loss: 0.5818
2022-11-03 09:28:37,831 - mmdet - INFO - Epoch [5][300/3665]	lr: 1.500e-04, eta: 3:55:20, time: 0.497, data_time: 0.019, memory: 5252, loss_cls: 0.2910, loss_bbox: 0.2896, loss: 0.5806
2022-11-03 09:29:03,410 - mmdet - INFO - Epoch [5][350/3665]	lr: 1.500e-04, eta: 3:55:01, time: 0.512, data_time: 0.022, memory: 5252, loss_cls: 0.2906, loss_bbox: 0.2915, loss: 0.5822
2022-11-03 09:29:28,472 - mmdet - INFO - Epoch [5][400/3665]	lr: 1.500e-04, eta: 3:54:39, time: 0.501, data_time: 0.018, memory: 5252, loss_cls: 0.2875, loss_bbox: 0.2866, loss: 0.5742
2022-11-03 09:29:54,450 - mmdet - INFO - Epoch [5][450/3665]	lr: 1.500e-04, eta: 3:54:21, time: 0.520, data_time: 0.023, memory: 5252, loss_cls: 0.2928, loss_bbox: 0.2908, loss: 0.5836
2022-11-03 09:30:19,532 - mmdet - INFO - Epoch [5][500/3665]	lr: 1.500e-04, eta: 3:53:59, time: 0.502, data_time: 0.017, memory: 5252, loss_cls: 0.2905, loss_bbox: 0.2881, loss: 0.5786
2022-11-03 09:30:44,392 - mmdet - INFO - Epoch [5][550/3665]	lr: 1.500e-04, eta: 3:53:37, time: 0.497, data_time: 0.017, memory: 5252, loss_cls: 0.2884, loss_bbox: 0.2864, loss: 0.5748
2022-11-03 09:31:09,494 - mmdet - INFO - Epoch [5][600/3665]	lr: 1.500e-04, eta: 3:53:15, time: 0.502, data_time: 0.018, memory: 5252, loss_cls: 0.2898, loss_bbox: 0.2888, loss: 0.5786
2022-11-03 09:31:34,926 - mmdet - INFO - Epoch [5][650/3665]	lr: 1.500e-04, eta: 3:52:55, time: 0.509, data_time: 0.019, memory: 5252, loss_cls: 0.2919, loss_bbox: 0.2890, loss: 0.5809
2022-11-03 09:32:00,235 - mmdet - INFO - Epoch [5][700/3665]	lr: 1.500e-04, eta: 3:52:34, time: 0.506, data_time: 0.031, memory: 5252, loss_cls: 0.2854, loss_bbox: 0.2856, loss: 0.5710
2022-11-03 09:32:25,083 - mmdet - INFO - Epoch [5][750/3665]	lr: 1.500e-04, eta: 3:52:11, time: 0.497, data_time: 0.018, memory: 5252, loss_cls: 0.2866, loss_bbox: 0.2876, loss: 0.5742
2022-11-03 09:32:50,873 - mmdet - INFO - Epoch [5][800/3665]	lr: 1.500e-04, eta: 3:51:51, time: 0.516, data_time: 0.018, memory: 5252, loss_cls: 0.2871, loss_bbox: 0.2887, loss: 0.5758
2022-11-03 09:33:16,428 - mmdet - INFO - Epoch [5][850/3665]	lr: 1.500e-04, eta: 3:51:31, time: 0.511, data_time: 0.018, memory: 5252, loss_cls: 0.2822, loss_bbox: 0.2810, loss: 0.5632
2022-11-03 09:33:41,725 - mmdet - INFO - Epoch [5][900/3665]	lr: 1.500e-04, eta: 3:51:10, time: 0.506, data_time: 0.018, memory: 5252, loss_cls: 0.2874, loss_bbox: 0.2868, loss: 0.5743
2022-11-03 09:34:06,934 - mmdet - INFO - Epoch [5][950/3665]	lr: 1.500e-04, eta: 3:50:48, time: 0.504, data_time: 0.017, memory: 5252, loss_cls: 0.2930, loss_bbox: 0.2904, loss: 0.5834
2022-11-03 09:34:32,160 - mmdet - INFO - Epoch [5][1000/3665]	lr: 1.500e-04, eta: 3:50:26, time: 0.505, data_time: 0.018, memory: 5252, loss_cls: 0.2837, loss_bbox: 0.2859, loss: 0.5696
2022-11-03 09:34:57,294 - mmdet - INFO - Epoch [5][1050/3665]	lr: 1.500e-04, eta: 3:50:04, time: 0.503, data_time: 0.017, memory: 5252, loss_cls: 0.2884, loss_bbox: 0.2874, loss: 0.5758
2022-11-03 09:35:22,265 - mmdet - INFO - Epoch [5][1100/3665]	lr: 1.500e-04, eta: 3:49:42, time: 0.499, data_time: 0.018, memory: 5252, loss_cls: 0.2847, loss_bbox: 0.2856, loss: 0.5704
2022-11-03 09:35:46,998 - mmdet - INFO - Epoch [5][1150/3665]	lr: 1.500e-04, eta: 3:49:19, time: 0.495, data_time: 0.017, memory: 5252, loss_cls: 0.2887, loss_bbox: 0.2868, loss: 0.5755
2022-11-03 09:36:12,662 - mmdet - INFO - Epoch [5][1200/3665]	lr: 1.500e-04, eta: 3:48:58, time: 0.513, data_time: 0.015, memory: 5252, loss_cls: 0.2915, loss_bbox: 0.2866, loss: 0.5782
2022-11-03 09:36:37,751 - mmdet - INFO - Epoch [5][1250/3665]	lr: 1.500e-04, eta: 3:48:36, time: 0.502, data_time: 0.015, memory: 5252, loss_cls: 0.2886, loss_bbox: 0.2864, loss: 0.5749
2022-11-03 09:37:02,719 - mmdet - INFO - Epoch [5][1300/3665]	lr: 1.500e-04, eta: 3:48:13, time: 0.499, data_time: 0.015, memory: 5252, loss_cls: 0.2886, loss_bbox: 0.2915, loss: 0.5801
2022-11-03 09:37:27,733 - mmdet - INFO - Epoch [5][1350/3665]	lr: 1.500e-04, eta: 3:47:51, time: 0.500, data_time: 0.015, memory: 5252, loss_cls: 0.2907, loss_bbox: 0.2926, loss: 0.5832
2022-11-03 09:37:52,832 - mmdet - INFO - Epoch [5][1400/3665]	lr: 1.500e-04, eta: 3:47:28, time: 0.502, data_time: 0.016, memory: 5252, loss_cls: 0.2886, loss_bbox: 0.2858, loss: 0.5744
2022-11-03 09:38:17,838 - mmdet - INFO - Epoch [5][1450/3665]	lr: 1.500e-04, eta: 3:47:06, time: 0.500, data_time: 0.016, memory: 5252, loss_cls: 0.2890, loss_bbox: 0.2907, loss: 0.5797
2022-11-03 09:38:42,757 - mmdet - INFO - Epoch [5][1500/3665]	lr: 1.500e-04, eta: 3:46:43, time: 0.498, data_time: 0.016, memory: 5252, loss_cls: 0.2848, loss_bbox: 0.2840, loss: 0.5688
2022-11-03 09:39:08,117 - mmdet - INFO - Epoch [5][1550/3665]	lr: 1.500e-04, eta: 3:46:21, time: 0.507, data_time: 0.016, memory: 5252, loss_cls: 0.2917, loss_bbox: 0.2915, loss: 0.5831
2022-11-03 09:39:34,538 - mmdet - INFO - Epoch [5][1600/3665]	lr: 1.500e-04, eta: 3:46:03, time: 0.528, data_time: 0.022, memory: 5252, loss_cls: 0.2986, loss_bbox: 0.2867, loss: 0.5852
2022-11-03 09:39:59,048 - mmdet - INFO - Epoch [5][1650/3665]	lr: 1.500e-04, eta: 3:45:38, time: 0.490, data_time: 0.015, memory: 5252, loss_cls: 0.2922, loss_bbox: 0.2892, loss: 0.5814
2022-11-03 09:40:24,456 - mmdet - INFO - Epoch [5][1700/3665]	lr: 1.500e-04, eta: 3:45:17, time: 0.508, data_time: 0.015, memory: 5252, loss_cls: 0.2900, loss_bbox: 0.2875, loss: 0.5775
2022-11-03 09:40:49,408 - mmdet - INFO - Epoch [5][1750/3665]	lr: 1.500e-04, eta: 3:44:54, time: 0.499, data_time: 0.016, memory: 5252, loss_cls: 0.2938, loss_bbox: 0.2923, loss: 0.5862
2022-11-03 09:41:14,496 - mmdet - INFO - Epoch [5][1800/3665]	lr: 1.500e-04, eta: 3:44:31, time: 0.502, data_time: 0.016, memory: 5252, loss_cls: 0.2854, loss_bbox: 0.2848, loss: 0.5702
2022-11-03 09:41:40,109 - mmdet - INFO - Epoch [5][1850/3665]	lr: 1.500e-04, eta: 3:44:10, time: 0.512, data_time: 0.016, memory: 5252, loss_cls: 0.2913, loss_bbox: 0.2872, loss: 0.5785
2022-11-03 09:42:05,432 - mmdet - INFO - Epoch [5][1900/3665]	lr: 1.500e-04, eta: 3:43:48, time: 0.506, data_time: 0.016, memory: 5252, loss_cls: 0.2930, loss_bbox: 0.2937, loss: 0.5867
2022-11-03 09:42:29,829 - mmdet - INFO - Epoch [5][1950/3665]	lr: 1.500e-04, eta: 3:43:23, time: 0.488, data_time: 0.016, memory: 5252, loss_cls: 0.2910, loss_bbox: 0.2885, loss: 0.5794
2022-11-03 09:42:55,284 - mmdet - INFO - Epoch [5][2000/3665]	lr: 1.500e-04, eta: 3:43:02, time: 0.509, data_time: 0.014, memory: 5252, loss_cls: 0.2914, loss_bbox: 0.2900, loss: 0.5814
2022-11-03 09:43:20,026 - mmdet - INFO - Epoch [5][2050/3665]	lr: 1.500e-04, eta: 3:42:38, time: 0.495, data_time: 0.015, memory: 5252, loss_cls: 0.2925, loss_bbox: 0.2912, loss: 0.5836
2022-11-03 09:43:45,063 - mmdet - INFO - Epoch [5][2100/3665]	lr: 1.500e-04, eta: 3:42:15, time: 0.501, data_time: 0.015, memory: 5252, loss_cls: 0.2882, loss_bbox: 0.2915, loss: 0.5797
2022-11-03 09:44:10,136 - mmdet - INFO - Epoch [5][2150/3665]	lr: 1.500e-04, eta: 3:41:52, time: 0.501, data_time: 0.015, memory: 5252, loss_cls: 0.2979, loss_bbox: 0.2930, loss: 0.5908
2022-11-03 09:44:35,513 - mmdet - INFO - Epoch [5][2200/3665]	lr: 1.500e-04, eta: 3:41:30, time: 0.508, data_time: 0.016, memory: 5252, loss_cls: 0.2880, loss_bbox: 0.2858, loss: 0.5738
2022-11-03 09:45:00,423 - mmdet - INFO - Epoch [5][2250/3665]	lr: 1.500e-04, eta: 3:41:07, time: 0.498, data_time: 0.015, memory: 5252, loss_cls: 0.2894, loss_bbox: 0.2891, loss: 0.5785
2022-11-03 09:45:25,359 - mmdet - INFO - Epoch [5][2300/3665]	lr: 1.500e-04, eta: 3:40:44, time: 0.499, data_time: 0.016, memory: 5252, loss_cls: 0.2851, loss_bbox: 0.2869, loss: 0.5720
2022-11-03 09:45:50,251 - mmdet - INFO - Epoch [5][2350/3665]	lr: 1.500e-04, eta: 3:40:20, time: 0.498, data_time: 0.015, memory: 5252, loss_cls: 0.2915, loss_bbox: 0.2918, loss: 0.5834
2022-11-03 09:46:15,032 - mmdet - INFO - Epoch [5][2400/3665]	lr: 1.500e-04, eta: 3:39:56, time: 0.496, data_time: 0.015, memory: 5252, loss_cls: 0.2837, loss_bbox: 0.2801, loss: 0.5638
2022-11-03 09:46:39,888 - mmdet - INFO - Epoch [5][2450/3665]	lr: 1.500e-04, eta: 3:39:33, time: 0.497, data_time: 0.016, memory: 5252, loss_cls: 0.2891, loss_bbox: 0.2906, loss: 0.5798
2022-11-03 09:47:03,702 - mmdet - INFO - Epoch [5][2500/3665]	lr: 1.500e-04, eta: 3:39:06, time: 0.476, data_time: 0.015, memory: 5252, loss_cls: 0.2962, loss_bbox: 0.2946, loss: 0.5909
2022-11-03 09:47:28,762 - mmdet - INFO - Epoch [5][2550/3665]	lr: 1.500e-04, eta: 3:38:43, time: 0.501, data_time: 0.016, memory: 5252, loss_cls: 0.2842, loss_bbox: 0.2861, loss: 0.5703
2022-11-03 09:47:53,518 - mmdet - INFO - Epoch [5][2600/3665]	lr: 1.500e-04, eta: 3:38:20, time: 0.495, data_time: 0.015, memory: 5252, loss_cls: 0.2870, loss_bbox: 0.2869, loss: 0.5739
2022-11-03 09:48:18,496 - mmdet - INFO - Epoch [5][2650/3665]	lr: 1.500e-04, eta: 3:37:56, time: 0.500, data_time: 0.024, memory: 5252, loss_cls: 0.2898, loss_bbox: 0.2854, loss: 0.5752
2022-11-03 09:48:43,910 - mmdet - INFO - Epoch [5][2700/3665]	lr: 1.500e-04, eta: 3:37:34, time: 0.508, data_time: 0.021, memory: 5252, loss_cls: 0.2866, loss_bbox: 0.2867, loss: 0.5733
2022-11-03 09:49:08,345 - mmdet - INFO - Epoch [5][2750/3665]	lr: 1.500e-04, eta: 3:37:09, time: 0.489, data_time: 0.016, memory: 5252, loss_cls: 0.2883, loss_bbox: 0.2862, loss: 0.5745
2022-11-03 09:49:34,044 - mmdet - INFO - Epoch [5][2800/3665]	lr: 1.500e-04, eta: 3:36:48, time: 0.514, data_time: 0.028, memory: 5252, loss_cls: 0.2854, loss_bbox: 0.2924, loss: 0.5777
2022-11-03 09:49:59,286 - mmdet - INFO - Epoch [5][2850/3665]	lr: 1.500e-04, eta: 3:36:25, time: 0.505, data_time: 0.021, memory: 5252, loss_cls: 0.2846, loss_bbox: 0.2839, loss: 0.5686
2022-11-03 09:50:23,916 - mmdet - INFO - Epoch [5][2900/3665]	lr: 1.500e-04, eta: 3:36:01, time: 0.493, data_time: 0.017, memory: 5252, loss_cls: 0.2932, loss_bbox: 0.2909, loss: 0.5841
2022-11-03 09:50:48,872 - mmdet - INFO - Epoch [5][2950/3665]	lr: 1.500e-04, eta: 3:35:38, time: 0.499, data_time: 0.017, memory: 5252, loss_cls: 0.2874, loss_bbox: 0.2892, loss: 0.5766
2022-11-03 09:51:14,235 - mmdet - INFO - Epoch [5][3000/3665]	lr: 1.500e-04, eta: 3:35:15, time: 0.507, data_time: 0.026, memory: 5252, loss_cls: 0.2899, loss_bbox: 0.2886, loss: 0.5786
2022-11-03 09:51:38,403 - mmdet - INFO - Epoch [5][3050/3665]	lr: 1.500e-04, eta: 3:34:50, time: 0.483, data_time: 0.016, memory: 5252, loss_cls: 0.2939, loss_bbox: 0.2883, loss: 0.5822
2022-11-03 09:52:03,235 - mmdet - INFO - Epoch [5][3100/3665]	lr: 1.500e-04, eta: 3:34:26, time: 0.497, data_time: 0.019, memory: 5252, loss_cls: 0.2877, loss_bbox: 0.2857, loss: 0.5733
2022-11-03 09:52:27,747 - mmdet - INFO - Epoch [5][3150/3665]	lr: 1.500e-04, eta: 3:34:01, time: 0.490, data_time: 0.019, memory: 5252, loss_cls: 0.2917, loss_bbox: 0.2823, loss: 0.5740
2022-11-03 09:52:52,013 - mmdet - INFO - Epoch [5][3200/3665]	lr: 1.500e-04, eta: 3:33:36, time: 0.485, data_time: 0.015, memory: 5252, loss_cls: 0.2916, loss_bbox: 0.2907, loss: 0.5823
2022-11-03 09:53:16,984 - mmdet - INFO - Epoch [5][3250/3665]	lr: 1.500e-04, eta: 3:33:13, time: 0.500, data_time: 0.017, memory: 5252, loss_cls: 0.2997, loss_bbox: 0.2920, loss: 0.5917
2022-11-03 09:53:42,949 - mmdet - INFO - Epoch [5][3300/3665]	lr: 1.500e-04, eta: 3:32:52, time: 0.519, data_time: 0.017, memory: 5252, loss_cls: 0.2897, loss_bbox: 0.2836, loss: 0.5733
2022-11-03 09:54:07,209 - mmdet - INFO - Epoch [5][3350/3665]	lr: 1.500e-04, eta: 3:32:26, time: 0.485, data_time: 0.016, memory: 5252, loss_cls: 0.2867, loss_bbox: 0.2847, loss: 0.5714
2022-11-03 09:54:31,723 - mmdet - INFO - Epoch [5][3400/3665]	lr: 1.500e-04, eta: 3:32:02, time: 0.490, data_time: 0.017, memory: 5252, loss_cls: 0.2923, loss_bbox: 0.2873, loss: 0.5796
2022-11-03 09:54:57,114 - mmdet - INFO - Epoch [5][3450/3665]	lr: 1.500e-04, eta: 3:31:39, time: 0.508, data_time: 0.017, memory: 5252, loss_cls: 0.2869, loss_bbox: 0.2874, loss: 0.5743
2022-11-03 09:55:22,227 - mmdet - INFO - Epoch [5][3500/3665]	lr: 1.500e-04, eta: 3:31:16, time: 0.502, data_time: 0.017, memory: 5252, loss_cls: 0.2885, loss_bbox: 0.2842, loss: 0.5728
2022-11-03 09:55:47,275 - mmdet - INFO - Epoch [5][3550/3665]	lr: 1.500e-04, eta: 3:30:53, time: 0.501, data_time: 0.017, memory: 5252, loss_cls: 0.2920, loss_bbox: 0.2913, loss: 0.5833
2022-11-03 09:56:12,127 - mmdet - INFO - Epoch [5][3600/3665]	lr: 1.500e-04, eta: 3:30:29, time: 0.497, data_time: 0.017, memory: 5252, loss_cls: 0.2835, loss_bbox: 0.2840, loss: 0.5675
2022-11-03 09:56:36,905 - mmdet - INFO - Epoch [5][3650/3665]	lr: 1.500e-04, eta: 3:30:05, time: 0.495, data_time: 0.017, memory: 5252, loss_cls: 0.2875, loss_bbox: 0.2881, loss: 0.5756
2022-11-03 09:56:44,684 - mmdet - INFO - Saving checkpoint at 5 epochs
2022-11-03 09:57:42,738 - mmdet - INFO - Evaluating bbox...
2022-11-03 09:58:47,066 - mmdet - INFO - 
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.499
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.324
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.181
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.336
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.420
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.494
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.494
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.297
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.531
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.651

2022-11-03 09:58:48,236 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 09:58:48,237 - mmdet - INFO - Epoch(val) [5][625]	bbox_mAP: 0.3100, bbox_mAP_50: 0.4990, bbox_mAP_75: 0.3240, bbox_mAP_s: 0.1810, bbox_mAP_m: 0.3360, bbox_mAP_l: 0.4200, bbox_mAP_copypaste: 0.310 0.499 0.324 0.181 0.336 0.420
2022-11-03 09:59:16,293 - mmdet - INFO - Epoch [6][50/3665]	lr: 1.259e-04, eta: 3:29:24, time: 0.561, data_time: 0.079, memory: 5252, loss_cls: 0.2755, loss_bbox: 0.2810, loss: 0.5565
2022-11-03 09:59:40,913 - mmdet - INFO - Epoch [6][100/3665]	lr: 1.259e-04, eta: 3:29:00, time: 0.493, data_time: 0.019, memory: 5252, loss_cls: 0.2693, loss_bbox: 0.2749, loss: 0.5441
2022-11-03 10:00:05,733 - mmdet - INFO - Epoch [6][150/3665]	lr: 1.259e-04, eta: 3:28:36, time: 0.496, data_time: 0.018, memory: 5252, loss_cls: 0.2736, loss_bbox: 0.2811, loss: 0.5547
2022-11-03 10:00:30,208 - mmdet - INFO - Epoch [6][200/3665]	lr: 1.259e-04, eta: 3:28:11, time: 0.490, data_time: 0.019, memory: 5252, loss_cls: 0.2702, loss_bbox: 0.2794, loss: 0.5496
2022-11-03 10:00:55,291 - mmdet - INFO - Epoch [6][250/3665]	lr: 1.259e-04, eta: 3:27:48, time: 0.502, data_time: 0.018, memory: 5252, loss_cls: 0.2711, loss_bbox: 0.2729, loss: 0.5440
2022-11-03 10:01:20,538 - mmdet - INFO - Epoch [6][300/3665]	lr: 1.259e-04, eta: 3:27:25, time: 0.505, data_time: 0.018, memory: 5252, loss_cls: 0.2703, loss_bbox: 0.2774, loss: 0.5477
2022-11-03 10:01:45,152 - mmdet - INFO - Epoch [6][350/3665]	lr: 1.259e-04, eta: 3:27:00, time: 0.492, data_time: 0.018, memory: 5252, loss_cls: 0.2754, loss_bbox: 0.2810, loss: 0.5565
2022-11-03 10:02:09,639 - mmdet - INFO - Epoch [6][400/3665]	lr: 1.259e-04, eta: 3:26:36, time: 0.489, data_time: 0.018, memory: 5252, loss_cls: 0.2705, loss_bbox: 0.2764, loss: 0.5468
2022-11-03 10:02:34,664 - mmdet - INFO - Epoch [6][450/3665]	lr: 1.259e-04, eta: 3:26:12, time: 0.501, data_time: 0.019, memory: 5252, loss_cls: 0.2661, loss_bbox: 0.2717, loss: 0.5378
2022-11-03 10:02:59,468 - mmdet - INFO - Epoch [6][500/3665]	lr: 1.259e-04, eta: 3:25:48, time: 0.496, data_time: 0.019, memory: 5252, loss_cls: 0.2697, loss_bbox: 0.2757, loss: 0.5454
2022-11-03 10:03:25,329 - mmdet - INFO - Epoch [6][550/3665]	lr: 1.259e-04, eta: 3:25:27, time: 0.517, data_time: 0.021, memory: 5252, loss_cls: 0.2733, loss_bbox: 0.2795, loss: 0.5528
2022-11-03 10:03:50,582 - mmdet - INFO - Epoch [6][600/3665]	lr: 1.259e-04, eta: 3:25:03, time: 0.505, data_time: 0.017, memory: 5252, loss_cls: 0.2733, loss_bbox: 0.2773, loss: 0.5506
2022-11-03 10:04:14,722 - mmdet - INFO - Epoch [6][650/3665]	lr: 1.259e-04, eta: 3:24:38, time: 0.483, data_time: 0.019, memory: 5252, loss_cls: 0.2721, loss_bbox: 0.2763, loss: 0.5483
2022-11-03 10:04:39,368 - mmdet - INFO - Epoch [6][700/3665]	lr: 1.259e-04, eta: 3:24:14, time: 0.493, data_time: 0.027, memory: 5252, loss_cls: 0.2710, loss_bbox: 0.2762, loss: 0.5472
2022-11-03 10:05:04,623 - mmdet - INFO - Epoch [6][750/3665]	lr: 1.259e-04, eta: 3:23:51, time: 0.505, data_time: 0.018, memory: 5252, loss_cls: 0.2752, loss_bbox: 0.2809, loss: 0.5561
2022-11-03 10:05:29,786 - mmdet - INFO - Epoch [6][800/3665]	lr: 1.259e-04, eta: 3:23:27, time: 0.503, data_time: 0.018, memory: 5252, loss_cls: 0.2772, loss_bbox: 0.2796, loss: 0.5568
2022-11-03 10:05:55,219 - mmdet - INFO - Epoch [6][850/3665]	lr: 1.259e-04, eta: 3:23:05, time: 0.509, data_time: 0.017, memory: 5252, loss_cls: 0.2744, loss_bbox: 0.2822, loss: 0.5566
2022-11-03 10:06:20,904 - mmdet - INFO - Epoch [6][900/3665]	lr: 1.259e-04, eta: 3:22:42, time: 0.514, data_time: 0.019, memory: 5252, loss_cls: 0.2760, loss_bbox: 0.2779, loss: 0.5539
2022-11-03 10:06:45,846 - mmdet - INFO - Epoch [6][950/3665]	lr: 1.259e-04, eta: 3:22:19, time: 0.499, data_time: 0.019, memory: 5252, loss_cls: 0.2788, loss_bbox: 0.2808, loss: 0.5596
2022-11-03 10:07:10,700 - mmdet - INFO - Epoch [6][1000/3665]	lr: 1.259e-04, eta: 3:21:55, time: 0.497, data_time: 0.018, memory: 5252, loss_cls: 0.2797, loss_bbox: 0.2799, loss: 0.5596
2022-11-03 10:07:35,599 - mmdet - INFO - Epoch [6][1050/3665]	lr: 1.259e-04, eta: 3:21:31, time: 0.498, data_time: 0.018, memory: 5252, loss_cls: 0.2745, loss_bbox: 0.2810, loss: 0.5555
2022-11-03 10:08:00,319 - mmdet - INFO - Epoch [6][1100/3665]	lr: 1.259e-04, eta: 3:21:06, time: 0.494, data_time: 0.017, memory: 5252, loss_cls: 0.2797, loss_bbox: 0.2831, loss: 0.5627
2022-11-03 10:08:24,703 - mmdet - INFO - Epoch [6][1150/3665]	lr: 1.259e-04, eta: 3:20:42, time: 0.488, data_time: 0.018, memory: 5252, loss_cls: 0.2709, loss_bbox: 0.2748, loss: 0.5457
2022-11-03 10:08:49,476 - mmdet - INFO - Epoch [6][1200/3665]	lr: 1.259e-04, eta: 3:20:17, time: 0.495, data_time: 0.017, memory: 5252, loss_cls: 0.2732, loss_bbox: 0.2704, loss: 0.5436
2022-11-03 10:09:14,330 - mmdet - INFO - Epoch [6][1250/3665]	lr: 1.259e-04, eta: 3:19:53, time: 0.497, data_time: 0.018, memory: 5252, loss_cls: 0.2696, loss_bbox: 0.2788, loss: 0.5483
2022-11-03 10:09:38,893 - mmdet - INFO - Epoch [6][1300/3665]	lr: 1.259e-04, eta: 3:19:29, time: 0.491, data_time: 0.017, memory: 5252, loss_cls: 0.2773, loss_bbox: 0.2800, loss: 0.5573
2022-11-03 10:10:04,757 - mmdet - INFO - Epoch [6][1350/3665]	lr: 1.259e-04, eta: 3:19:07, time: 0.517, data_time: 0.018, memory: 5252, loss_cls: 0.2765, loss_bbox: 0.2776, loss: 0.5541
2022-11-03 10:10:30,142 - mmdet - INFO - Epoch [6][1400/3665]	lr: 1.259e-04, eta: 3:18:44, time: 0.508, data_time: 0.019, memory: 5252, loss_cls: 0.2781, loss_bbox: 0.2804, loss: 0.5586
2022-11-03 10:10:55,653 - mmdet - INFO - Epoch [6][1450/3665]	lr: 1.259e-04, eta: 3:18:21, time: 0.510, data_time: 0.017, memory: 5252, loss_cls: 0.2715, loss_bbox: 0.2791, loss: 0.5506
2022-11-03 10:11:20,859 - mmdet - INFO - Epoch [6][1500/3665]	lr: 1.259e-04, eta: 3:17:58, time: 0.504, data_time: 0.018, memory: 5252, loss_cls: 0.2674, loss_bbox: 0.2728, loss: 0.5403
2022-11-03 10:11:46,272 - mmdet - INFO - Epoch [6][1550/3665]	lr: 1.259e-04, eta: 3:17:35, time: 0.508, data_time: 0.018, memory: 5252, loss_cls: 0.2717, loss_bbox: 0.2766, loss: 0.5483
2022-11-03 10:12:11,604 - mmdet - INFO - Epoch [6][1600/3665]	lr: 1.259e-04, eta: 3:17:11, time: 0.506, data_time: 0.018, memory: 5252, loss_cls: 0.2722, loss_bbox: 0.2765, loss: 0.5488
2022-11-03 10:12:37,408 - mmdet - INFO - Epoch [6][1650/3665]	lr: 1.259e-04, eta: 3:16:49, time: 0.516, data_time: 0.019, memory: 5252, loss_cls: 0.2764, loss_bbox: 0.2784, loss: 0.5548
2022-11-03 10:13:02,211 - mmdet - INFO - Epoch [6][1700/3665]	lr: 1.259e-04, eta: 3:16:25, time: 0.496, data_time: 0.017, memory: 5252, loss_cls: 0.2757, loss_bbox: 0.2834, loss: 0.5591
2022-11-03 10:13:27,410 - mmdet - INFO - Epoch [6][1750/3665]	lr: 1.259e-04, eta: 3:16:01, time: 0.504, data_time: 0.019, memory: 5252, loss_cls: 0.2788, loss_bbox: 0.2842, loss: 0.5630
2022-11-03 10:13:53,011 - mmdet - INFO - Epoch [6][1800/3665]	lr: 1.259e-04, eta: 3:15:39, time: 0.512, data_time: 0.018, memory: 5252, loss_cls: 0.2788, loss_bbox: 0.2800, loss: 0.5588
2022-11-03 10:14:17,502 - mmdet - INFO - Epoch [6][1850/3665]	lr: 1.259e-04, eta: 3:15:14, time: 0.490, data_time: 0.017, memory: 5252, loss_cls: 0.2715, loss_bbox: 0.2767, loss: 0.5482
2022-11-03 10:14:32,834 - mmdet - INFO - Epoch [6][1900/3665]	lr: 1.259e-04, eta: 3:14:32, time: 0.307, data_time: 0.018, memory: 5252, loss_cls: 0.2766, loss_bbox: 0.2818, loss: 0.5584
2022-11-03 10:14:48,384 - mmdet - INFO - Epoch [6][1950/3665]	lr: 1.259e-04, eta: 3:13:51, time: 0.311, data_time: 0.015, memory: 5252, loss_cls: 0.2686, loss_bbox: 0.2774, loss: 0.5460
2022-11-03 10:15:03,762 - mmdet - INFO - Epoch [6][2000/3665]	lr: 1.259e-04, eta: 3:13:10, time: 0.308, data_time: 0.016, memory: 5252, loss_cls: 0.2678, loss_bbox: 0.2754, loss: 0.5432
2022-11-03 10:15:19,188 - mmdet - INFO - Epoch [6][2050/3665]	lr: 1.259e-04, eta: 3:12:29, time: 0.308, data_time: 0.016, memory: 5252, loss_cls: 0.2725, loss_bbox: 0.2812, loss: 0.5536
2022-11-03 10:15:35,944 - mmdet - INFO - Epoch [6][2100/3665]	lr: 1.259e-04, eta: 3:11:51, time: 0.335, data_time: 0.016, memory: 5252, loss_cls: 0.2674, loss_bbox: 0.2750, loss: 0.5424
2022-11-03 10:16:12,011 - mmdet - INFO - Epoch [6][2150/3665]	lr: 1.259e-04, eta: 3:11:47, time: 0.721, data_time: 0.017, memory: 5252, loss_cls: 0.2709, loss_bbox: 0.2791, loss: 0.5500
2022-11-03 10:16:50,670 - mmdet - INFO - Epoch [6][2200/3665]	lr: 1.259e-04, eta: 3:11:48, time: 0.773, data_time: 0.016, memory: 5252, loss_cls: 0.2754, loss_bbox: 0.2786, loss: 0.5540
2022-11-03 10:17:28,440 - mmdet - INFO - Epoch [6][2250/3665]	lr: 1.259e-04, eta: 3:11:47, time: 0.755, data_time: 0.016, memory: 5252, loss_cls: 0.2702, loss_bbox: 0.2787, loss: 0.5489
2022-11-03 10:17:54,331 - mmdet - INFO - Epoch [6][2300/3665]	lr: 1.259e-04, eta: 3:11:24, time: 0.518, data_time: 0.017, memory: 5252, loss_cls: 0.2832, loss_bbox: 0.2804, loss: 0.5636
2022-11-03 10:18:19,650 - mmdet - INFO - Epoch [6][2350/3665]	lr: 1.259e-04, eta: 3:11:01, time: 0.506, data_time: 0.036, memory: 5252, loss_cls: 0.2784, loss_bbox: 0.2800, loss: 0.5584
2022-11-03 10:18:44,253 - mmdet - INFO - Epoch [6][2400/3665]	lr: 1.259e-04, eta: 3:10:36, time: 0.492, data_time: 0.019, memory: 5252, loss_cls: 0.2715, loss_bbox: 0.2773, loss: 0.5487
2022-11-03 10:19:08,238 - mmdet - INFO - Epoch [6][2450/3665]	lr: 1.259e-04, eta: 3:10:11, time: 0.480, data_time: 0.017, memory: 5252, loss_cls: 0.2797, loss_bbox: 0.2775, loss: 0.5572
2022-11-03 10:19:32,247 - mmdet - INFO - Epoch [6][2500/3665]	lr: 1.259e-04, eta: 3:09:45, time: 0.480, data_time: 0.019, memory: 5252, loss_cls: 0.2745, loss_bbox: 0.2783, loss: 0.5529
2022-11-03 10:19:56,632 - mmdet - INFO - Epoch [6][2550/3665]	lr: 1.259e-04, eta: 3:09:20, time: 0.488, data_time: 0.018, memory: 5252, loss_cls: 0.2724, loss_bbox: 0.2789, loss: 0.5513
2022-11-03 10:20:20,831 - mmdet - INFO - Epoch [6][2600/3665]	lr: 1.259e-04, eta: 3:08:55, time: 0.484, data_time: 0.020, memory: 5252, loss_cls: 0.2792, loss_bbox: 0.2799, loss: 0.5592
2022-11-03 10:20:45,739 - mmdet - INFO - Epoch [6][2650/3665]	lr: 1.259e-04, eta: 3:08:31, time: 0.498, data_time: 0.020, memory: 5252, loss_cls: 0.2729, loss_bbox: 0.2778, loss: 0.5507
2022-11-03 10:21:09,100 - mmdet - INFO - Epoch [6][2700/3665]	lr: 1.259e-04, eta: 3:08:04, time: 0.468, data_time: 0.020, memory: 5252, loss_cls: 0.2684, loss_bbox: 0.2773, loss: 0.5457
2022-11-03 10:21:33,256 - mmdet - INFO - Epoch [6][2750/3665]	lr: 1.259e-04, eta: 3:07:39, time: 0.483, data_time: 0.020, memory: 5252, loss_cls: 0.2722, loss_bbox: 0.2763, loss: 0.5485
2022-11-03 10:21:57,849 - mmdet - INFO - Epoch [6][2800/3665]	lr: 1.259e-04, eta: 3:07:14, time: 0.492, data_time: 0.019, memory: 5252, loss_cls: 0.2769, loss_bbox: 0.2818, loss: 0.5587
2022-11-03 10:22:21,733 - mmdet - INFO - Epoch [6][2850/3665]	lr: 1.259e-04, eta: 3:06:49, time: 0.478, data_time: 0.019, memory: 5252, loss_cls: 0.2732, loss_bbox: 0.2759, loss: 0.5491
2022-11-03 10:22:45,786 - mmdet - INFO - Epoch [6][2900/3665]	lr: 1.259e-04, eta: 3:06:23, time: 0.481, data_time: 0.020, memory: 5252, loss_cls: 0.2748, loss_bbox: 0.2778, loss: 0.5526
2022-11-03 10:23:09,052 - mmdet - INFO - Epoch [6][2950/3665]	lr: 1.259e-04, eta: 3:05:57, time: 0.465, data_time: 0.019, memory: 5252, loss_cls: 0.2722, loss_bbox: 0.2768, loss: 0.5490
2022-11-03 10:23:33,179 - mmdet - INFO - Epoch [6][3000/3665]	lr: 1.259e-04, eta: 3:05:31, time: 0.483, data_time: 0.019, memory: 5252, loss_cls: 0.2794, loss_bbox: 0.2793, loss: 0.5587
2022-11-03 10:23:57,591 - mmdet - INFO - Epoch [6][3050/3665]	lr: 1.259e-04, eta: 3:05:07, time: 0.488, data_time: 0.018, memory: 5252, loss_cls: 0.2712, loss_bbox: 0.2765, loss: 0.5477
2022-11-03 10:24:22,549 - mmdet - INFO - Epoch [6][3100/3665]	lr: 1.259e-04, eta: 3:04:43, time: 0.499, data_time: 0.019, memory: 5252, loss_cls: 0.2744, loss_bbox: 0.2756, loss: 0.5499
2022-11-03 10:24:46,563 - mmdet - INFO - Epoch [6][3150/3665]	lr: 1.259e-04, eta: 3:04:17, time: 0.480, data_time: 0.018, memory: 5252, loss_cls: 0.2676, loss_bbox: 0.2756, loss: 0.5431
2022-11-03 10:25:10,031 - mmdet - INFO - Epoch [6][3200/3665]	lr: 1.259e-04, eta: 3:03:51, time: 0.470, data_time: 0.018, memory: 5252, loss_cls: 0.2728, loss_bbox: 0.2815, loss: 0.5543
2022-11-03 10:25:35,105 - mmdet - INFO - Epoch [6][3250/3665]	lr: 1.259e-04, eta: 3:03:27, time: 0.502, data_time: 0.019, memory: 5252, loss_cls: 0.2739, loss_bbox: 0.2786, loss: 0.5525
2022-11-03 10:25:59,231 - mmdet - INFO - Epoch [6][3300/3665]	lr: 1.259e-04, eta: 3:03:02, time: 0.483, data_time: 0.018, memory: 5252, loss_cls: 0.2719, loss_bbox: 0.2832, loss: 0.5552
2022-11-03 10:26:23,560 - mmdet - INFO - Epoch [6][3350/3665]	lr: 1.259e-04, eta: 3:02:37, time: 0.487, data_time: 0.019, memory: 5252, loss_cls: 0.2752, loss_bbox: 0.2762, loss: 0.5514
2022-11-03 10:26:48,355 - mmdet - INFO - Epoch [6][3400/3665]	lr: 1.259e-04, eta: 3:02:13, time: 0.496, data_time: 0.018, memory: 5252, loss_cls: 0.2729, loss_bbox: 0.2767, loss: 0.5496
2022-11-03 10:27:12,659 - mmdet - INFO - Epoch [6][3450/3665]	lr: 1.259e-04, eta: 3:01:48, time: 0.486, data_time: 0.018, memory: 5252, loss_cls: 0.2718, loss_bbox: 0.2776, loss: 0.5494
2022-11-03 10:27:37,364 - mmdet - INFO - Epoch [6][3500/3665]	lr: 1.259e-04, eta: 3:01:23, time: 0.494, data_time: 0.018, memory: 5252, loss_cls: 0.2751, loss_bbox: 0.2795, loss: 0.5546
2022-11-03 10:28:01,297 - mmdet - INFO - Epoch [6][3550/3665]	lr: 1.259e-04, eta: 3:00:58, time: 0.479, data_time: 0.018, memory: 5252, loss_cls: 0.2670, loss_bbox: 0.2786, loss: 0.5456
2022-11-03 10:28:25,764 - mmdet - INFO - Epoch [6][3600/3665]	lr: 1.259e-04, eta: 3:00:33, time: 0.489, data_time: 0.018, memory: 5252, loss_cls: 0.2695, loss_bbox: 0.2833, loss: 0.5528
2022-11-03 10:28:50,237 - mmdet - INFO - Epoch [6][3650/3665]	lr: 1.259e-04, eta: 3:00:08, time: 0.489, data_time: 0.017, memory: 5252, loss_cls: 0.2713, loss_bbox: 0.2790, loss: 0.5503
2022-11-03 10:28:58,246 - mmdet - INFO - Saving checkpoint at 6 epochs
2022-11-03 10:29:50,807 - mmdet - INFO - Evaluating bbox...
2022-11-03 10:30:48,411 - mmdet - INFO - 
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.520
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.338
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.191
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.347
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.430
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.505
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.505
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.319
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.544
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.650

2022-11-03 10:30:49,325 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 10:30:49,325 - mmdet - INFO - Epoch(val) [6][625]	bbox_mAP: 0.3240, bbox_mAP_50: 0.5200, bbox_mAP_75: 0.3380, bbox_mAP_s: 0.1910, bbox_mAP_m: 0.3470, bbox_mAP_l: 0.4300, bbox_mAP_copypaste: 0.324 0.520 0.338 0.191 0.347 0.430
2022-11-03 10:31:17,314 - mmdet - INFO - Epoch [7][50/3665]	lr: 1.000e-04, eta: 2:59:31, time: 0.559, data_time: 0.073, memory: 5252, loss_cls: 0.2569, loss_bbox: 0.2707, loss: 0.5276
2022-11-03 10:31:42,482 - mmdet - INFO - Epoch [7][100/3665]	lr: 1.000e-04, eta: 2:59:07, time: 0.503, data_time: 0.016, memory: 5252, loss_cls: 0.2533, loss_bbox: 0.2720, loss: 0.5253
2022-11-03 10:32:06,602 - mmdet - INFO - Epoch [7][150/3665]	lr: 1.000e-04, eta: 2:58:42, time: 0.482, data_time: 0.015, memory: 5252, loss_cls: 0.2569, loss_bbox: 0.2712, loss: 0.5281
2022-11-03 10:32:31,741 - mmdet - INFO - Epoch [7][200/3665]	lr: 1.000e-04, eta: 2:58:18, time: 0.503, data_time: 0.015, memory: 5252, loss_cls: 0.2589, loss_bbox: 0.2669, loss: 0.5258
2022-11-03 10:32:56,631 - mmdet - INFO - Epoch [7][250/3665]	lr: 1.000e-04, eta: 2:57:54, time: 0.498, data_time: 0.015, memory: 5252, loss_cls: 0.2605, loss_bbox: 0.2738, loss: 0.5342
2022-11-03 10:33:21,016 - mmdet - INFO - Epoch [7][300/3665]	lr: 1.000e-04, eta: 2:57:29, time: 0.487, data_time: 0.015, memory: 5252, loss_cls: 0.2512, loss_bbox: 0.2637, loss: 0.5148
2022-11-03 10:33:44,838 - mmdet - INFO - Epoch [7][350/3665]	lr: 1.000e-04, eta: 2:57:04, time: 0.477, data_time: 0.015, memory: 5252, loss_cls: 0.2530, loss_bbox: 0.2669, loss: 0.5199
2022-11-03 10:34:09,333 - mmdet - INFO - Epoch [7][400/3665]	lr: 1.000e-04, eta: 2:56:39, time: 0.490, data_time: 0.015, memory: 5252, loss_cls: 0.2569, loss_bbox: 0.2729, loss: 0.5297
2022-11-03 10:34:33,669 - mmdet - INFO - Epoch [7][450/3665]	lr: 1.000e-04, eta: 2:56:14, time: 0.487, data_time: 0.016, memory: 5252, loss_cls: 0.2559, loss_bbox: 0.2700, loss: 0.5259
2022-11-03 10:34:57,914 - mmdet - INFO - Epoch [7][500/3665]	lr: 1.000e-04, eta: 2:55:49, time: 0.485, data_time: 0.016, memory: 5252, loss_cls: 0.2585, loss_bbox: 0.2659, loss: 0.5244
2022-11-03 10:35:22,262 - mmdet - INFO - Epoch [7][550/3665]	lr: 1.000e-04, eta: 2:55:24, time: 0.487, data_time: 0.016, memory: 5252, loss_cls: 0.2571, loss_bbox: 0.2712, loss: 0.5283
2022-11-03 10:35:46,860 - mmdet - INFO - Epoch [7][600/3665]	lr: 1.000e-04, eta: 2:55:00, time: 0.492, data_time: 0.016, memory: 5252, loss_cls: 0.2604, loss_bbox: 0.2679, loss: 0.5283
2022-11-03 10:36:11,736 - mmdet - INFO - Epoch [7][650/3665]	lr: 1.000e-04, eta: 2:54:36, time: 0.498, data_time: 0.016, memory: 5252, loss_cls: 0.2551, loss_bbox: 0.2656, loss: 0.5207
2022-11-03 10:36:35,573 - mmdet - INFO - Epoch [7][700/3665]	lr: 1.000e-04, eta: 2:54:10, time: 0.477, data_time: 0.016, memory: 5252, loss_cls: 0.2613, loss_bbox: 0.2672, loss: 0.5285
2022-11-03 10:36:59,948 - mmdet - INFO - Epoch [7][750/3665]	lr: 1.000e-04, eta: 2:53:46, time: 0.487, data_time: 0.016, memory: 5252, loss_cls: 0.2611, loss_bbox: 0.2686, loss: 0.5297
2022-11-03 10:37:24,299 - mmdet - INFO - Epoch [7][800/3665]	lr: 1.000e-04, eta: 2:53:21, time: 0.487, data_time: 0.016, memory: 5252, loss_cls: 0.2648, loss_bbox: 0.2779, loss: 0.5428
2022-11-03 10:37:48,887 - mmdet - INFO - Epoch [7][850/3665]	lr: 1.000e-04, eta: 2:52:56, time: 0.492, data_time: 0.016, memory: 5252, loss_cls: 0.2626, loss_bbox: 0.2713, loss: 0.5338
2022-11-03 10:38:13,774 - mmdet - INFO - Epoch [7][900/3665]	lr: 1.000e-04, eta: 2:52:32, time: 0.498, data_time: 0.016, memory: 5252, loss_cls: 0.2528, loss_bbox: 0.2678, loss: 0.5205
2022-11-03 10:38:38,506 - mmdet - INFO - Epoch [7][950/3665]	lr: 1.000e-04, eta: 2:52:08, time: 0.494, data_time: 0.016, memory: 5252, loss_cls: 0.2581, loss_bbox: 0.2677, loss: 0.5258
2022-11-03 10:39:03,779 - mmdet - INFO - Epoch [7][1000/3665]	lr: 1.000e-04, eta: 2:51:44, time: 0.506, data_time: 0.016, memory: 5252, loss_cls: 0.2608, loss_bbox: 0.2729, loss: 0.5337
2022-11-03 10:39:27,908 - mmdet - INFO - Epoch [7][1050/3665]	lr: 1.000e-04, eta: 2:51:19, time: 0.483, data_time: 0.016, memory: 5252, loss_cls: 0.2641, loss_bbox: 0.2781, loss: 0.5422
2022-11-03 10:39:52,041 - mmdet - INFO - Epoch [7][1100/3665]	lr: 1.000e-04, eta: 2:50:54, time: 0.483, data_time: 0.017, memory: 5252, loss_cls: 0.2580, loss_bbox: 0.2686, loss: 0.5267
2022-11-03 10:40:15,965 - mmdet - INFO - Epoch [7][1150/3665]	lr: 1.000e-04, eta: 2:50:29, time: 0.479, data_time: 0.016, memory: 5252, loss_cls: 0.2521, loss_bbox: 0.2674, loss: 0.5196
2022-11-03 10:40:40,474 - mmdet - INFO - Epoch [7][1200/3665]	lr: 1.000e-04, eta: 2:50:04, time: 0.490, data_time: 0.016, memory: 5252, loss_cls: 0.2622, loss_bbox: 0.2693, loss: 0.5315
2022-11-03 10:41:05,576 - mmdet - INFO - Epoch [7][1250/3665]	lr: 1.000e-04, eta: 2:49:40, time: 0.502, data_time: 0.016, memory: 5252, loss_cls: 0.2620, loss_bbox: 0.2655, loss: 0.5275
2022-11-03 10:41:30,267 - mmdet - INFO - Epoch [7][1300/3665]	lr: 1.000e-04, eta: 2:49:16, time: 0.494, data_time: 0.016, memory: 5252, loss_cls: 0.2605, loss_bbox: 0.2699, loss: 0.5304
2022-11-03 10:41:54,189 - mmdet - INFO - Epoch [7][1350/3665]	lr: 1.000e-04, eta: 2:48:51, time: 0.478, data_time: 0.016, memory: 5252, loss_cls: 0.2603, loss_bbox: 0.2626, loss: 0.5228
2022-11-03 10:42:18,217 - mmdet - INFO - Epoch [7][1400/3665]	lr: 1.000e-04, eta: 2:48:25, time: 0.481, data_time: 0.017, memory: 5252, loss_cls: 0.2579, loss_bbox: 0.2714, loss: 0.5294
2022-11-03 10:42:42,315 - mmdet - INFO - Epoch [7][1450/3665]	lr: 1.000e-04, eta: 2:48:00, time: 0.482, data_time: 0.015, memory: 5252, loss_cls: 0.2566, loss_bbox: 0.2701, loss: 0.5267
2022-11-03 10:43:06,981 - mmdet - INFO - Epoch [7][1500/3665]	lr: 1.000e-04, eta: 2:47:36, time: 0.493, data_time: 0.017, memory: 5252, loss_cls: 0.2544, loss_bbox: 0.2670, loss: 0.5215
2022-11-03 10:43:30,760 - mmdet - INFO - Epoch [7][1550/3665]	lr: 1.000e-04, eta: 2:47:10, time: 0.476, data_time: 0.017, memory: 5252, loss_cls: 0.2613, loss_bbox: 0.2666, loss: 0.5279
2022-11-03 10:43:54,696 - mmdet - INFO - Epoch [7][1600/3665]	lr: 1.000e-04, eta: 2:46:45, time: 0.479, data_time: 0.017, memory: 5252, loss_cls: 0.2557, loss_bbox: 0.2698, loss: 0.5254
2022-11-03 10:44:19,321 - mmdet - INFO - Epoch [7][1650/3665]	lr: 1.000e-04, eta: 2:46:21, time: 0.492, data_time: 0.018, memory: 5252, loss_cls: 0.2637, loss_bbox: 0.2688, loss: 0.5325
2022-11-03 10:44:43,576 - mmdet - INFO - Epoch [7][1700/3665]	lr: 1.000e-04, eta: 2:45:56, time: 0.485, data_time: 0.018, memory: 5252, loss_cls: 0.2567, loss_bbox: 0.2724, loss: 0.5291
2022-11-03 10:45:06,892 - mmdet - INFO - Epoch [7][1750/3665]	lr: 1.000e-04, eta: 2:45:30, time: 0.466, data_time: 0.017, memory: 5252, loss_cls: 0.2638, loss_bbox: 0.2764, loss: 0.5402
2022-11-03 10:45:30,559 - mmdet - INFO - Epoch [7][1800/3665]	lr: 1.000e-04, eta: 2:45:04, time: 0.474, data_time: 0.017, memory: 5252, loss_cls: 0.2600, loss_bbox: 0.2757, loss: 0.5356
2022-11-03 10:45:54,653 - mmdet - INFO - Epoch [7][1850/3665]	lr: 1.000e-04, eta: 2:44:39, time: 0.482, data_time: 0.016, memory: 5252, loss_cls: 0.2664, loss_bbox: 0.2732, loss: 0.5396
2022-11-03 10:46:19,430 - mmdet - INFO - Epoch [7][1900/3665]	lr: 1.000e-04, eta: 2:44:15, time: 0.496, data_time: 0.017, memory: 5252, loss_cls: 0.2569, loss_bbox: 0.2710, loss: 0.5280
2022-11-03 10:46:43,701 - mmdet - INFO - Epoch [7][1950/3665]	lr: 1.000e-04, eta: 2:43:50, time: 0.485, data_time: 0.015, memory: 5252, loss_cls: 0.2598, loss_bbox: 0.2726, loss: 0.5324
2022-11-03 10:47:07,776 - mmdet - INFO - Epoch [7][2000/3665]	lr: 1.000e-04, eta: 2:43:25, time: 0.481, data_time: 0.016, memory: 5252, loss_cls: 0.2679, loss_bbox: 0.2729, loss: 0.5408
2022-11-03 10:47:32,368 - mmdet - INFO - Epoch [7][2050/3665]	lr: 1.000e-04, eta: 2:43:01, time: 0.492, data_time: 0.017, memory: 5252, loss_cls: 0.2588, loss_bbox: 0.2697, loss: 0.5286
2022-11-03 10:47:56,170 - mmdet - INFO - Epoch [7][2100/3665]	lr: 1.000e-04, eta: 2:42:35, time: 0.476, data_time: 0.016, memory: 5252, loss_cls: 0.2584, loss_bbox: 0.2686, loss: 0.5271
2022-11-03 10:48:20,489 - mmdet - INFO - Epoch [7][2150/3665]	lr: 1.000e-04, eta: 2:42:10, time: 0.486, data_time: 0.016, memory: 5252, loss_cls: 0.2619, loss_bbox: 0.2716, loss: 0.5336
2022-11-03 10:48:44,758 - mmdet - INFO - Epoch [7][2200/3665]	lr: 1.000e-04, eta: 2:41:46, time: 0.485, data_time: 0.015, memory: 5252, loss_cls: 0.2571, loss_bbox: 0.2664, loss: 0.5235
2022-11-03 10:49:08,761 - mmdet - INFO - Epoch [7][2250/3665]	lr: 1.000e-04, eta: 2:41:20, time: 0.480, data_time: 0.015, memory: 5252, loss_cls: 0.2559, loss_bbox: 0.2690, loss: 0.5249
2022-11-03 10:49:32,674 - mmdet - INFO - Epoch [7][2300/3665]	lr: 1.000e-04, eta: 2:40:55, time: 0.478, data_time: 0.016, memory: 5252, loss_cls: 0.2569, loss_bbox: 0.2697, loss: 0.5266
2022-11-03 10:49:56,551 - mmdet - INFO - Epoch [7][2350/3665]	lr: 1.000e-04, eta: 2:40:30, time: 0.477, data_time: 0.016, memory: 5252, loss_cls: 0.2564, loss_bbox: 0.2705, loss: 0.5269
2022-11-03 10:50:20,963 - mmdet - INFO - Epoch [7][2400/3665]	lr: 1.000e-04, eta: 2:40:05, time: 0.488, data_time: 0.016, memory: 5252, loss_cls: 0.2579, loss_bbox: 0.2685, loss: 0.5264
2022-11-03 10:50:45,293 - mmdet - INFO - Epoch [7][2450/3665]	lr: 1.000e-04, eta: 2:39:41, time: 0.487, data_time: 0.015, memory: 5252, loss_cls: 0.2636, loss_bbox: 0.2690, loss: 0.5325
2022-11-03 10:51:09,810 - mmdet - INFO - Epoch [7][2500/3665]	lr: 1.000e-04, eta: 2:39:16, time: 0.490, data_time: 0.015, memory: 5252, loss_cls: 0.2573, loss_bbox: 0.2706, loss: 0.5279
2022-11-03 10:51:34,560 - mmdet - INFO - Epoch [7][2550/3665]	lr: 1.000e-04, eta: 2:38:52, time: 0.495, data_time: 0.022, memory: 5252, loss_cls: 0.2591, loss_bbox: 0.2704, loss: 0.5296
2022-11-03 10:51:59,063 - mmdet - INFO - Epoch [7][2600/3665]	lr: 1.000e-04, eta: 2:38:27, time: 0.490, data_time: 0.016, memory: 5252, loss_cls: 0.2578, loss_bbox: 0.2722, loss: 0.5299
2022-11-03 10:52:24,304 - mmdet - INFO - Epoch [7][2650/3665]	lr: 1.000e-04, eta: 2:38:04, time: 0.505, data_time: 0.016, memory: 5252, loss_cls: 0.2603, loss_bbox: 0.2796, loss: 0.5399
2022-11-03 10:52:48,200 - mmdet - INFO - Epoch [7][2700/3665]	lr: 1.000e-04, eta: 2:37:38, time: 0.478, data_time: 0.016, memory: 5252, loss_cls: 0.2494, loss_bbox: 0.2624, loss: 0.5117
2022-11-03 10:53:11,841 - mmdet - INFO - Epoch [7][2750/3665]	lr: 1.000e-04, eta: 2:37:13, time: 0.473, data_time: 0.016, memory: 5252, loss_cls: 0.2627, loss_bbox: 0.2721, loss: 0.5348
2022-11-03 10:53:35,918 - mmdet - INFO - Epoch [7][2800/3665]	lr: 1.000e-04, eta: 2:36:48, time: 0.482, data_time: 0.016, memory: 5252, loss_cls: 0.2600, loss_bbox: 0.2684, loss: 0.5284
2022-11-03 10:54:00,248 - mmdet - INFO - Epoch [7][2850/3665]	lr: 1.000e-04, eta: 2:36:23, time: 0.487, data_time: 0.016, memory: 5252, loss_cls: 0.2602, loss_bbox: 0.2699, loss: 0.5301
2022-11-03 10:54:24,448 - mmdet - INFO - Epoch [7][2900/3665]	lr: 1.000e-04, eta: 2:35:58, time: 0.484, data_time: 0.015, memory: 5252, loss_cls: 0.2567, loss_bbox: 0.2679, loss: 0.5246
2022-11-03 10:54:47,983 - mmdet - INFO - Epoch [7][2950/3665]	lr: 1.000e-04, eta: 2:35:33, time: 0.471, data_time: 0.016, memory: 5252, loss_cls: 0.2601, loss_bbox: 0.2689, loss: 0.5290
2022-11-03 10:55:11,773 - mmdet - INFO - Epoch [7][3000/3665]	lr: 1.000e-04, eta: 2:35:07, time: 0.476, data_time: 0.016, memory: 5252, loss_cls: 0.2582, loss_bbox: 0.2664, loss: 0.5246
2022-11-03 10:55:36,091 - mmdet - INFO - Epoch [7][3050/3665]	lr: 1.000e-04, eta: 2:34:43, time: 0.486, data_time: 0.015, memory: 5252, loss_cls: 0.2651, loss_bbox: 0.2740, loss: 0.5392
2022-11-03 10:56:00,438 - mmdet - INFO - Epoch [7][3100/3665]	lr: 1.000e-04, eta: 2:34:18, time: 0.487, data_time: 0.015, memory: 5252, loss_cls: 0.2586, loss_bbox: 0.2677, loss: 0.5263
2022-11-03 10:56:24,342 - mmdet - INFO - Epoch [7][3150/3665]	lr: 1.000e-04, eta: 2:33:53, time: 0.478, data_time: 0.014, memory: 5252, loss_cls: 0.2612, loss_bbox: 0.2686, loss: 0.5297
2022-11-03 10:56:48,551 - mmdet - INFO - Epoch [7][3200/3665]	lr: 1.000e-04, eta: 2:33:28, time: 0.484, data_time: 0.015, memory: 5252, loss_cls: 0.2522, loss_bbox: 0.2666, loss: 0.5188
2022-11-03 10:57:12,609 - mmdet - INFO - Epoch [7][3250/3665]	lr: 1.000e-04, eta: 2:33:03, time: 0.481, data_time: 0.019, memory: 5252, loss_cls: 0.2590, loss_bbox: 0.2710, loss: 0.5301
2022-11-03 10:57:36,760 - mmdet - INFO - Epoch [7][3300/3665]	lr: 1.000e-04, eta: 2:32:38, time: 0.483, data_time: 0.016, memory: 5252, loss_cls: 0.2590, loss_bbox: 0.2758, loss: 0.5348
2022-11-03 10:58:00,531 - mmdet - INFO - Epoch [7][3350/3665]	lr: 1.000e-04, eta: 2:32:13, time: 0.475, data_time: 0.015, memory: 5252, loss_cls: 0.2689, loss_bbox: 0.2693, loss: 0.5382
2022-11-03 10:58:24,705 - mmdet - INFO - Epoch [7][3400/3665]	lr: 1.000e-04, eta: 2:31:48, time: 0.483, data_time: 0.016, memory: 5252, loss_cls: 0.2565, loss_bbox: 0.2681, loss: 0.5246
2022-11-03 10:58:48,746 - mmdet - INFO - Epoch [7][3450/3665]	lr: 1.000e-04, eta: 2:31:23, time: 0.481, data_time: 0.017, memory: 5252, loss_cls: 0.2640, loss_bbox: 0.2705, loss: 0.5345
2022-11-03 10:59:13,000 - mmdet - INFO - Epoch [7][3500/3665]	lr: 1.000e-04, eta: 2:30:58, time: 0.485, data_time: 0.016, memory: 5252, loss_cls: 0.2569, loss_bbox: 0.2720, loss: 0.5289
2022-11-03 10:59:37,471 - mmdet - INFO - Epoch [7][3550/3665]	lr: 1.000e-04, eta: 2:30:34, time: 0.489, data_time: 0.016, memory: 5252, loss_cls: 0.2552, loss_bbox: 0.2666, loss: 0.5219
2022-11-03 11:00:02,238 - mmdet - INFO - Epoch [7][3600/3665]	lr: 1.000e-04, eta: 2:30:10, time: 0.495, data_time: 0.016, memory: 5252, loss_cls: 0.2562, loss_bbox: 0.2675, loss: 0.5238
2022-11-03 11:00:26,324 - mmdet - INFO - Epoch [7][3650/3665]	lr: 1.000e-04, eta: 2:29:45, time: 0.482, data_time: 0.015, memory: 5252, loss_cls: 0.2552, loss_bbox: 0.2644, loss: 0.5196
2022-11-03 11:00:34,042 - mmdet - INFO - Saving checkpoint at 7 epochs
2022-11-03 11:01:27,119 - mmdet - INFO - Evaluating bbox...
2022-11-03 11:02:32,480 - mmdet - INFO - 
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.532
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.350
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.198
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.364
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.449
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.514
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.514
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.327
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.548
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.667

2022-11-03 11:02:33,730 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 11:02:33,731 - mmdet - INFO - Epoch(val) [7][625]	bbox_mAP: 0.3340, bbox_mAP_50: 0.5320, bbox_mAP_75: 0.3500, bbox_mAP_s: 0.1980, bbox_mAP_m: 0.3640, bbox_mAP_l: 0.4490, bbox_mAP_copypaste: 0.334 0.532 0.350 0.198 0.364 0.449
2022-11-03 11:03:00,155 - mmdet - INFO - Epoch [8][50/3665]	lr: 7.412e-05, eta: 2:29:08, time: 0.528, data_time: 0.077, memory: 5252, loss_cls: 0.2440, loss_bbox: 0.2604, loss: 0.5045
2022-11-03 11:03:23,649 - mmdet - INFO - Epoch [8][100/3665]	lr: 7.412e-05, eta: 2:28:42, time: 0.470, data_time: 0.017, memory: 5252, loss_cls: 0.2479, loss_bbox: 0.2662, loss: 0.5141
2022-11-03 11:03:47,549 - mmdet - INFO - Epoch [8][150/3665]	lr: 7.412e-05, eta: 2:28:17, time: 0.478, data_time: 0.016, memory: 5252, loss_cls: 0.2390, loss_bbox: 0.2551, loss: 0.4941
2022-11-03 11:04:10,985 - mmdet - INFO - Epoch [8][200/3665]	lr: 7.412e-05, eta: 2:27:52, time: 0.469, data_time: 0.015, memory: 5252, loss_cls: 0.2457, loss_bbox: 0.2621, loss: 0.5078
2022-11-03 11:04:35,336 - mmdet - INFO - Epoch [8][250/3665]	lr: 7.412e-05, eta: 2:27:27, time: 0.487, data_time: 0.015, memory: 5252, loss_cls: 0.2443, loss_bbox: 0.2631, loss: 0.5074
2022-11-03 11:04:58,830 - mmdet - INFO - Epoch [8][300/3665]	lr: 7.412e-05, eta: 2:27:02, time: 0.470, data_time: 0.015, memory: 5252, loss_cls: 0.2483, loss_bbox: 0.2600, loss: 0.5083
2022-11-03 11:05:23,093 - mmdet - INFO - Epoch [8][350/3665]	lr: 7.412e-05, eta: 2:26:37, time: 0.485, data_time: 0.016, memory: 5252, loss_cls: 0.2446, loss_bbox: 0.2626, loss: 0.5072
2022-11-03 11:05:46,663 - mmdet - INFO - Epoch [8][400/3665]	lr: 7.412e-05, eta: 2:26:12, time: 0.471, data_time: 0.015, memory: 5252, loss_cls: 0.2504, loss_bbox: 0.2642, loss: 0.5146
2022-11-03 11:06:10,503 - mmdet - INFO - Epoch [8][450/3665]	lr: 7.412e-05, eta: 2:25:46, time: 0.477, data_time: 0.015, memory: 5252, loss_cls: 0.2445, loss_bbox: 0.2638, loss: 0.5082
2022-11-03 11:06:34,181 - mmdet - INFO - Epoch [8][500/3665]	lr: 7.412e-05, eta: 2:25:21, time: 0.474, data_time: 0.016, memory: 5252, loss_cls: 0.2470, loss_bbox: 0.2609, loss: 0.5079
2022-11-03 11:06:57,745 - mmdet - INFO - Epoch [8][550/3665]	lr: 7.412e-05, eta: 2:24:56, time: 0.471, data_time: 0.015, memory: 5252, loss_cls: 0.2352, loss_bbox: 0.2542, loss: 0.4894
2022-11-03 11:07:22,006 - mmdet - INFO - Epoch [8][600/3665]	lr: 7.412e-05, eta: 2:24:31, time: 0.485, data_time: 0.016, memory: 5252, loss_cls: 0.2461, loss_bbox: 0.2622, loss: 0.5083
2022-11-03 11:07:46,075 - mmdet - INFO - Epoch [8][650/3665]	lr: 7.412e-05, eta: 2:24:06, time: 0.482, data_time: 0.016, memory: 5252, loss_cls: 0.2429, loss_bbox: 0.2615, loss: 0.5044
2022-11-03 11:08:09,562 - mmdet - INFO - Epoch [8][700/3665]	lr: 7.412e-05, eta: 2:23:41, time: 0.470, data_time: 0.016, memory: 5252, loss_cls: 0.2453, loss_bbox: 0.2623, loss: 0.5076
2022-11-03 11:08:33,407 - mmdet - INFO - Epoch [8][750/3665]	lr: 7.412e-05, eta: 2:23:16, time: 0.477, data_time: 0.018, memory: 5252, loss_cls: 0.2459, loss_bbox: 0.2628, loss: 0.5088
2022-11-03 11:08:57,510 - mmdet - INFO - Epoch [8][800/3665]	lr: 7.412e-05, eta: 2:22:51, time: 0.482, data_time: 0.018, memory: 5252, loss_cls: 0.2436, loss_bbox: 0.2629, loss: 0.5066
2022-11-03 11:09:22,084 - mmdet - INFO - Epoch [8][850/3665]	lr: 7.412e-05, eta: 2:22:27, time: 0.491, data_time: 0.018, memory: 5252, loss_cls: 0.2397, loss_bbox: 0.2592, loss: 0.4989
2022-11-03 11:09:45,954 - mmdet - INFO - Epoch [8][900/3665]	lr: 7.412e-05, eta: 2:22:02, time: 0.477, data_time: 0.018, memory: 5252, loss_cls: 0.2408, loss_bbox: 0.2615, loss: 0.5024
2022-11-03 11:10:10,049 - mmdet - INFO - Epoch [8][950/3665]	lr: 7.412e-05, eta: 2:21:37, time: 0.482, data_time: 0.019, memory: 5252, loss_cls: 0.2436, loss_bbox: 0.2637, loss: 0.5073
2022-11-03 11:10:30,186 - mmdet - INFO - Epoch [8][1000/3665]	lr: 7.412e-05, eta: 2:21:09, time: 0.403, data_time: 0.022, memory: 5252, loss_cls: 0.2433, loss_bbox: 0.2579, loss: 0.5012
2022-11-03 11:10:45,820 - mmdet - INFO - Epoch [8][1050/3665]	lr: 7.412e-05, eta: 2:20:37, time: 0.313, data_time: 0.021, memory: 5252, loss_cls: 0.2470, loss_bbox: 0.2630, loss: 0.5100
2022-11-03 11:11:01,291 - mmdet - INFO - Epoch [8][1100/3665]	lr: 7.412e-05, eta: 2:20:04, time: 0.309, data_time: 0.020, memory: 5252, loss_cls: 0.2370, loss_bbox: 0.2564, loss: 0.4935
2022-11-03 11:11:16,843 - mmdet - INFO - Epoch [8][1150/3665]	lr: 7.412e-05, eta: 2:19:32, time: 0.311, data_time: 0.021, memory: 5252, loss_cls: 0.2434, loss_bbox: 0.2633, loss: 0.5067
2022-11-03 11:11:32,772 - mmdet - INFO - Epoch [8][1200/3665]	lr: 7.412e-05, eta: 2:19:00, time: 0.319, data_time: 0.021, memory: 5252, loss_cls: 0.2358, loss_bbox: 0.2622, loss: 0.4980
2022-11-03 11:12:01,504 - mmdet - INFO - Epoch [8][1250/3665]	lr: 7.412e-05, eta: 2:18:40, time: 0.575, data_time: 0.018, memory: 5252, loss_cls: 0.2438, loss_bbox: 0.2617, loss: 0.5055
2022-11-03 11:12:39,640 - mmdet - INFO - Epoch [8][1300/3665]	lr: 7.412e-05, eta: 2:18:27, time: 0.763, data_time: 0.015, memory: 5252, loss_cls: 0.2429, loss_bbox: 0.2588, loss: 0.5017
2022-11-03 11:13:18,072 - mmdet - INFO - Epoch [8][1350/3665]	lr: 7.412e-05, eta: 2:18:15, time: 0.769, data_time: 0.016, memory: 5252, loss_cls: 0.2512, loss_bbox: 0.2639, loss: 0.5151
2022-11-03 11:13:43,311 - mmdet - INFO - Epoch [8][1400/3665]	lr: 7.412e-05, eta: 2:17:51, time: 0.505, data_time: 0.016, memory: 5252, loss_cls: 0.2454, loss_bbox: 0.2636, loss: 0.5089
2022-11-03 11:14:07,852 - mmdet - INFO - Epoch [8][1450/3665]	lr: 7.412e-05, eta: 2:17:27, time: 0.491, data_time: 0.017, memory: 5252, loss_cls: 0.2427, loss_bbox: 0.2593, loss: 0.5020
2022-11-03 11:14:31,431 - mmdet - INFO - Epoch [8][1500/3665]	lr: 7.412e-05, eta: 2:17:02, time: 0.472, data_time: 0.020, memory: 5252, loss_cls: 0.2433, loss_bbox: 0.2645, loss: 0.5078
2022-11-03 11:14:55,886 - mmdet - INFO - Epoch [8][1550/3665]	lr: 7.412e-05, eta: 2:16:37, time: 0.489, data_time: 0.019, memory: 5252, loss_cls: 0.2488, loss_bbox: 0.2599, loss: 0.5087
2022-11-03 11:15:20,381 - mmdet - INFO - Epoch [8][1600/3665]	lr: 7.412e-05, eta: 2:16:13, time: 0.490, data_time: 0.020, memory: 5252, loss_cls: 0.2462, loss_bbox: 0.2605, loss: 0.5067
2022-11-03 11:15:44,523 - mmdet - INFO - Epoch [8][1650/3665]	lr: 7.412e-05, eta: 2:15:48, time: 0.483, data_time: 0.020, memory: 5252, loss_cls: 0.2437, loss_bbox: 0.2584, loss: 0.5021
2022-11-03 11:16:08,582 - mmdet - INFO - Epoch [8][1700/3665]	lr: 7.412e-05, eta: 2:15:23, time: 0.481, data_time: 0.019, memory: 5252, loss_cls: 0.2466, loss_bbox: 0.2631, loss: 0.5098
2022-11-03 11:16:33,020 - mmdet - INFO - Epoch [8][1750/3665]	lr: 7.412e-05, eta: 2:14:59, time: 0.489, data_time: 0.021, memory: 5252, loss_cls: 0.2502, loss_bbox: 0.2625, loss: 0.5127
2022-11-03 11:16:56,736 - mmdet - INFO - Epoch [8][1800/3665]	lr: 7.412e-05, eta: 2:14:34, time: 0.474, data_time: 0.020, memory: 5252, loss_cls: 0.2426, loss_bbox: 0.2579, loss: 0.5006
2022-11-03 11:17:20,687 - mmdet - INFO - Epoch [8][1850/3665]	lr: 7.412e-05, eta: 2:14:09, time: 0.479, data_time: 0.020, memory: 5252, loss_cls: 0.2474, loss_bbox: 0.2583, loss: 0.5057
2022-11-03 11:17:44,398 - mmdet - INFO - Epoch [8][1900/3665]	lr: 7.412e-05, eta: 2:13:44, time: 0.474, data_time: 0.020, memory: 5252, loss_cls: 0.2393, loss_bbox: 0.2623, loss: 0.5016
2022-11-03 11:18:08,974 - mmdet - INFO - Epoch [8][1950/3665]	lr: 7.412e-05, eta: 2:13:20, time: 0.491, data_time: 0.020, memory: 5252, loss_cls: 0.2478, loss_bbox: 0.2632, loss: 0.5110
2022-11-03 11:18:32,553 - mmdet - INFO - Epoch [8][2000/3665]	lr: 7.412e-05, eta: 2:12:55, time: 0.472, data_time: 0.020, memory: 5252, loss_cls: 0.2490, loss_bbox: 0.2669, loss: 0.5159
2022-11-03 11:18:56,671 - mmdet - INFO - Epoch [8][2050/3665]	lr: 7.412e-05, eta: 2:12:30, time: 0.482, data_time: 0.019, memory: 5252, loss_cls: 0.2413, loss_bbox: 0.2558, loss: 0.4972
2022-11-03 11:19:21,153 - mmdet - INFO - Epoch [8][2100/3665]	lr: 7.412e-05, eta: 2:12:06, time: 0.490, data_time: 0.019, memory: 5252, loss_cls: 0.2465, loss_bbox: 0.2668, loss: 0.5133
2022-11-03 11:19:45,089 - mmdet - INFO - Epoch [8][2150/3665]	lr: 7.412e-05, eta: 2:11:41, time: 0.479, data_time: 0.019, memory: 5252, loss_cls: 0.2492, loss_bbox: 0.2560, loss: 0.5052
2022-11-03 11:20:09,207 - mmdet - INFO - Epoch [8][2200/3665]	lr: 7.412e-05, eta: 2:11:16, time: 0.482, data_time: 0.020, memory: 5252, loss_cls: 0.2443, loss_bbox: 0.2573, loss: 0.5016
2022-11-03 11:20:33,206 - mmdet - INFO - Epoch [8][2250/3665]	lr: 7.412e-05, eta: 2:10:51, time: 0.480, data_time: 0.020, memory: 5252, loss_cls: 0.2451, loss_bbox: 0.2591, loss: 0.5042
2022-11-03 11:20:56,767 - mmdet - INFO - Epoch [8][2300/3665]	lr: 7.412e-05, eta: 2:10:26, time: 0.471, data_time: 0.019, memory: 5252, loss_cls: 0.2489, loss_bbox: 0.2596, loss: 0.5085
2022-11-03 11:21:21,438 - mmdet - INFO - Epoch [8][2350/3665]	lr: 7.412e-05, eta: 2:10:02, time: 0.493, data_time: 0.021, memory: 5252, loss_cls: 0.2420, loss_bbox: 0.2624, loss: 0.5044
2022-11-03 11:21:45,329 - mmdet - INFO - Epoch [8][2400/3665]	lr: 7.412e-05, eta: 2:09:37, time: 0.478, data_time: 0.020, memory: 5252, loss_cls: 0.2448, loss_bbox: 0.2575, loss: 0.5023
2022-11-03 11:22:08,741 - mmdet - INFO - Epoch [8][2450/3665]	lr: 7.412e-05, eta: 2:09:12, time: 0.468, data_time: 0.019, memory: 5252, loss_cls: 0.2461, loss_bbox: 0.2564, loss: 0.5025
2022-11-03 11:22:32,255 - mmdet - INFO - Epoch [8][2500/3665]	lr: 7.412e-05, eta: 2:08:47, time: 0.470, data_time: 0.021, memory: 5252, loss_cls: 0.2477, loss_bbox: 0.2587, loss: 0.5063
2022-11-03 11:22:56,720 - mmdet - INFO - Epoch [8][2550/3665]	lr: 7.412e-05, eta: 2:08:23, time: 0.489, data_time: 0.020, memory: 5252, loss_cls: 0.2467, loss_bbox: 0.2638, loss: 0.5105
2022-11-03 11:23:20,727 - mmdet - INFO - Epoch [8][2600/3665]	lr: 7.412e-05, eta: 2:07:58, time: 0.480, data_time: 0.021, memory: 5252, loss_cls: 0.2517, loss_bbox: 0.2642, loss: 0.5159
2022-11-03 11:23:44,598 - mmdet - INFO - Epoch [8][2650/3665]	lr: 7.412e-05, eta: 2:07:33, time: 0.477, data_time: 0.021, memory: 5252, loss_cls: 0.2391, loss_bbox: 0.2588, loss: 0.4979
2022-11-03 11:24:08,805 - mmdet - INFO - Epoch [8][2700/3665]	lr: 7.412e-05, eta: 2:07:09, time: 0.484, data_time: 0.020, memory: 5252, loss_cls: 0.2533, loss_bbox: 0.2649, loss: 0.5182
2022-11-03 11:24:33,094 - mmdet - INFO - Epoch [8][2750/3665]	lr: 7.412e-05, eta: 2:06:44, time: 0.486, data_time: 0.021, memory: 5252, loss_cls: 0.2463, loss_bbox: 0.2611, loss: 0.5074
2022-11-03 11:24:57,493 - mmdet - INFO - Epoch [8][2800/3665]	lr: 7.412e-05, eta: 2:06:20, time: 0.488, data_time: 0.020, memory: 5252, loss_cls: 0.2446, loss_bbox: 0.2639, loss: 0.5085
2022-11-03 11:25:22,723 - mmdet - INFO - Epoch [8][2850/3665]	lr: 7.412e-05, eta: 2:05:56, time: 0.504, data_time: 0.020, memory: 5252, loss_cls: 0.2462, loss_bbox: 0.2601, loss: 0.5064
2022-11-03 11:25:46,552 - mmdet - INFO - Epoch [8][2900/3665]	lr: 7.412e-05, eta: 2:05:31, time: 0.477, data_time: 0.021, memory: 5252, loss_cls: 0.2358, loss_bbox: 0.2557, loss: 0.4915
2022-11-03 11:26:11,090 - mmdet - INFO - Epoch [8][2950/3665]	lr: 7.412e-05, eta: 2:05:07, time: 0.491, data_time: 0.020, memory: 5252, loss_cls: 0.2462, loss_bbox: 0.2588, loss: 0.5050
2022-11-03 11:26:35,223 - mmdet - INFO - Epoch [8][3000/3665]	lr: 7.412e-05, eta: 2:04:42, time: 0.483, data_time: 0.021, memory: 5252, loss_cls: 0.2457, loss_bbox: 0.2633, loss: 0.5091
2022-11-03 11:26:59,012 - mmdet - INFO - Epoch [8][3050/3665]	lr: 7.412e-05, eta: 2:04:17, time: 0.476, data_time: 0.019, memory: 5252, loss_cls: 0.2500, loss_bbox: 0.2656, loss: 0.5156
2022-11-03 11:27:23,250 - mmdet - INFO - Epoch [8][3100/3665]	lr: 7.412e-05, eta: 2:03:53, time: 0.485, data_time: 0.021, memory: 5252, loss_cls: 0.2419, loss_bbox: 0.2580, loss: 0.4999
2022-11-03 11:27:47,702 - mmdet - INFO - Epoch [8][3150/3665]	lr: 7.412e-05, eta: 2:03:28, time: 0.489, data_time: 0.020, memory: 5252, loss_cls: 0.2530, loss_bbox: 0.2667, loss: 0.5197
2022-11-03 11:28:12,713 - mmdet - INFO - Epoch [8][3200/3665]	lr: 7.412e-05, eta: 2:03:04, time: 0.500, data_time: 0.020, memory: 5252, loss_cls: 0.2475, loss_bbox: 0.2600, loss: 0.5075
2022-11-03 11:28:36,915 - mmdet - INFO - Epoch [8][3250/3665]	lr: 7.412e-05, eta: 2:02:40, time: 0.484, data_time: 0.021, memory: 5252, loss_cls: 0.2430, loss_bbox: 0.2609, loss: 0.5039
2022-11-03 11:29:00,419 - mmdet - INFO - Epoch [8][3300/3665]	lr: 7.412e-05, eta: 2:02:15, time: 0.470, data_time: 0.019, memory: 5252, loss_cls: 0.2444, loss_bbox: 0.2643, loss: 0.5087
2022-11-03 11:29:24,797 - mmdet - INFO - Epoch [8][3350/3665]	lr: 7.412e-05, eta: 2:01:50, time: 0.488, data_time: 0.021, memory: 5252, loss_cls: 0.2507, loss_bbox: 0.2621, loss: 0.5129
2022-11-03 11:29:49,193 - mmdet - INFO - Epoch [8][3400/3665]	lr: 7.412e-05, eta: 2:01:26, time: 0.488, data_time: 0.020, memory: 5252, loss_cls: 0.2387, loss_bbox: 0.2609, loss: 0.4996
2022-11-03 11:30:13,779 - mmdet - INFO - Epoch [8][3450/3665]	lr: 7.412e-05, eta: 2:01:02, time: 0.492, data_time: 0.021, memory: 5252, loss_cls: 0.2517, loss_bbox: 0.2630, loss: 0.5147
2022-11-03 11:30:37,762 - mmdet - INFO - Epoch [8][3500/3665]	lr: 7.412e-05, eta: 2:00:37, time: 0.480, data_time: 0.020, memory: 5252, loss_cls: 0.2480, loss_bbox: 0.2621, loss: 0.5100
2022-11-03 11:31:02,297 - mmdet - INFO - Epoch [8][3550/3665]	lr: 7.412e-05, eta: 2:00:12, time: 0.491, data_time: 0.019, memory: 5252, loss_cls: 0.2505, loss_bbox: 0.2653, loss: 0.5158
2022-11-03 11:31:26,442 - mmdet - INFO - Epoch [8][3600/3665]	lr: 7.412e-05, eta: 1:59:48, time: 0.483, data_time: 0.020, memory: 5252, loss_cls: 0.2427, loss_bbox: 0.2592, loss: 0.5019
2022-11-03 11:31:50,342 - mmdet - INFO - Epoch [8][3650/3665]	lr: 7.412e-05, eta: 1:59:23, time: 0.478, data_time: 0.019, memory: 5252, loss_cls: 0.2571, loss_bbox: 0.2654, loss: 0.5225
2022-11-03 11:31:57,848 - mmdet - INFO - Saving checkpoint at 8 epochs
2022-11-03 11:32:53,171 - mmdet - INFO - Evaluating bbox...
2022-11-03 11:33:52,166 - mmdet - INFO - 
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.543
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.362
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.203
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.368
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.455
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.521
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.521
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.334
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.556
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.665

2022-11-03 11:33:53,044 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 11:33:53,045 - mmdet - INFO - Epoch(val) [8][625]	bbox_mAP: 0.3440, bbox_mAP_50: 0.5430, bbox_mAP_75: 0.3620, bbox_mAP_s: 0.2030, bbox_mAP_m: 0.3680, bbox_mAP_l: 0.4550, bbox_mAP_copypaste: 0.344 0.543 0.362 0.203 0.368 0.455
2022-11-03 11:34:19,665 - mmdet - INFO - Epoch [9][50/3665]	lr: 5.000e-05, eta: 1:58:48, time: 0.532, data_time: 0.073, memory: 5252, loss_cls: 0.2345, loss_bbox: 0.2527, loss: 0.4872
2022-11-03 11:34:43,372 - mmdet - INFO - Epoch [9][100/3665]	lr: 5.000e-05, eta: 1:58:23, time: 0.474, data_time: 0.015, memory: 5252, loss_cls: 0.2294, loss_bbox: 0.2525, loss: 0.4818
2022-11-03 11:35:07,747 - mmdet - INFO - Epoch [9][150/3665]	lr: 5.000e-05, eta: 1:57:59, time: 0.487, data_time: 0.015, memory: 5252, loss_cls: 0.2286, loss_bbox: 0.2484, loss: 0.4771
2022-11-03 11:35:32,299 - mmdet - INFO - Epoch [9][200/3665]	lr: 5.000e-05, eta: 1:57:34, time: 0.491, data_time: 0.015, memory: 5252, loss_cls: 0.2386, loss_bbox: 0.2569, loss: 0.4955
2022-11-03 11:35:56,131 - mmdet - INFO - Epoch [9][250/3665]	lr: 5.000e-05, eta: 1:57:10, time: 0.477, data_time: 0.016, memory: 5252, loss_cls: 0.2357, loss_bbox: 0.2520, loss: 0.4877
2022-11-03 11:36:20,022 - mmdet - INFO - Epoch [9][300/3665]	lr: 5.000e-05, eta: 1:56:45, time: 0.478, data_time: 0.015, memory: 5252, loss_cls: 0.2385, loss_bbox: 0.2572, loss: 0.4957
2022-11-03 11:36:44,170 - mmdet - INFO - Epoch [9][350/3665]	lr: 5.000e-05, eta: 1:56:20, time: 0.483, data_time: 0.016, memory: 5252, loss_cls: 0.2240, loss_bbox: 0.2480, loss: 0.4720
2022-11-03 11:37:08,248 - mmdet - INFO - Epoch [9][400/3665]	lr: 5.000e-05, eta: 1:55:56, time: 0.482, data_time: 0.016, memory: 5252, loss_cls: 0.2353, loss_bbox: 0.2526, loss: 0.4879
2022-11-03 11:37:31,905 - mmdet - INFO - Epoch [9][450/3665]	lr: 5.000e-05, eta: 1:55:31, time: 0.473, data_time: 0.016, memory: 5252, loss_cls: 0.2261, loss_bbox: 0.2501, loss: 0.4762
2022-11-03 11:37:55,769 - mmdet - INFO - Epoch [9][500/3665]	lr: 5.000e-05, eta: 1:55:06, time: 0.478, data_time: 0.016, memory: 5252, loss_cls: 0.2314, loss_bbox: 0.2523, loss: 0.4837
2022-11-03 11:38:19,902 - mmdet - INFO - Epoch [9][550/3665]	lr: 5.000e-05, eta: 1:54:42, time: 0.483, data_time: 0.016, memory: 5252, loss_cls: 0.2326, loss_bbox: 0.2523, loss: 0.4849
2022-11-03 11:38:44,290 - mmdet - INFO - Epoch [9][600/3665]	lr: 5.000e-05, eta: 1:54:17, time: 0.488, data_time: 0.015, memory: 5252, loss_cls: 0.2363, loss_bbox: 0.2576, loss: 0.4939
2022-11-03 11:39:08,075 - mmdet - INFO - Epoch [9][650/3665]	lr: 5.000e-05, eta: 1:53:53, time: 0.476, data_time: 0.016, memory: 5252, loss_cls: 0.2336, loss_bbox: 0.2518, loss: 0.4854
2022-11-03 11:39:31,944 - mmdet - INFO - Epoch [9][700/3665]	lr: 5.000e-05, eta: 1:53:28, time: 0.477, data_time: 0.015, memory: 5252, loss_cls: 0.2340, loss_bbox: 0.2521, loss: 0.4861
2022-11-03 11:39:56,598 - mmdet - INFO - Epoch [9][750/3665]	lr: 5.000e-05, eta: 1:53:04, time: 0.493, data_time: 0.016, memory: 5252, loss_cls: 0.2382, loss_bbox: 0.2573, loss: 0.4955
2022-11-03 11:40:20,837 - mmdet - INFO - Epoch [9][800/3665]	lr: 5.000e-05, eta: 1:52:39, time: 0.485, data_time: 0.015, memory: 5252, loss_cls: 0.2302, loss_bbox: 0.2516, loss: 0.4818
2022-11-03 11:40:44,883 - mmdet - INFO - Epoch [9][850/3665]	lr: 5.000e-05, eta: 1:52:15, time: 0.481, data_time: 0.015, memory: 5252, loss_cls: 0.2291, loss_bbox: 0.2490, loss: 0.4782
2022-11-03 11:41:08,605 - mmdet - INFO - Epoch [9][900/3665]	lr: 5.000e-05, eta: 1:51:50, time: 0.475, data_time: 0.016, memory: 5252, loss_cls: 0.2407, loss_bbox: 0.2615, loss: 0.5022
2022-11-03 11:41:33,150 - mmdet - INFO - Epoch [9][950/3665]	lr: 5.000e-05, eta: 1:51:26, time: 0.491, data_time: 0.016, memory: 5252, loss_cls: 0.2355, loss_bbox: 0.2555, loss: 0.4909
2022-11-03 11:41:57,145 - mmdet - INFO - Epoch [9][1000/3665]	lr: 5.000e-05, eta: 1:51:01, time: 0.480, data_time: 0.016, memory: 5252, loss_cls: 0.2376, loss_bbox: 0.2555, loss: 0.4932
2022-11-03 11:42:21,039 - mmdet - INFO - Epoch [9][1050/3665]	lr: 5.000e-05, eta: 1:50:36, time: 0.478, data_time: 0.015, memory: 5252, loss_cls: 0.2305, loss_bbox: 0.2556, loss: 0.4861
2022-11-03 11:42:44,813 - mmdet - INFO - Epoch [9][1100/3665]	lr: 5.000e-05, eta: 1:50:11, time: 0.475, data_time: 0.015, memory: 5252, loss_cls: 0.2340, loss_bbox: 0.2554, loss: 0.4894
2022-11-03 11:43:08,271 - mmdet - INFO - Epoch [9][1150/3665]	lr: 5.000e-05, eta: 1:49:47, time: 0.469, data_time: 0.015, memory: 5252, loss_cls: 0.2326, loss_bbox: 0.2516, loss: 0.4842
2022-11-03 11:43:32,232 - mmdet - INFO - Epoch [9][1200/3665]	lr: 5.000e-05, eta: 1:49:22, time: 0.479, data_time: 0.014, memory: 5252, loss_cls: 0.2296, loss_bbox: 0.2532, loss: 0.4828
2022-11-03 11:43:55,575 - mmdet - INFO - Epoch [9][1250/3665]	lr: 5.000e-05, eta: 1:48:57, time: 0.467, data_time: 0.015, memory: 5252, loss_cls: 0.2331, loss_bbox: 0.2477, loss: 0.4808
2022-11-03 11:44:19,105 - mmdet - INFO - Epoch [9][1300/3665]	lr: 5.000e-05, eta: 1:48:32, time: 0.471, data_time: 0.015, memory: 5252, loss_cls: 0.2306, loss_bbox: 0.2513, loss: 0.4818
2022-11-03 11:44:43,389 - mmdet - INFO - Epoch [9][1350/3665]	lr: 5.000e-05, eta: 1:48:08, time: 0.486, data_time: 0.015, memory: 5252, loss_cls: 0.2328, loss_bbox: 0.2501, loss: 0.4828
2022-11-03 11:45:07,565 - mmdet - INFO - Epoch [9][1400/3665]	lr: 5.000e-05, eta: 1:47:43, time: 0.483, data_time: 0.015, memory: 5252, loss_cls: 0.2307, loss_bbox: 0.2520, loss: 0.4827
2022-11-03 11:45:31,563 - mmdet - INFO - Epoch [9][1450/3665]	lr: 5.000e-05, eta: 1:47:19, time: 0.480, data_time: 0.015, memory: 5252, loss_cls: 0.2317, loss_bbox: 0.2546, loss: 0.4862
2022-11-03 11:45:55,240 - mmdet - INFO - Epoch [9][1500/3665]	lr: 5.000e-05, eta: 1:46:54, time: 0.474, data_time: 0.015, memory: 5252, loss_cls: 0.2280, loss_bbox: 0.2514, loss: 0.4793
2022-11-03 11:46:19,379 - mmdet - INFO - Epoch [9][1550/3665]	lr: 5.000e-05, eta: 1:46:29, time: 0.483, data_time: 0.014, memory: 5252, loss_cls: 0.2296, loss_bbox: 0.2529, loss: 0.4824
2022-11-03 11:46:43,201 - mmdet - INFO - Epoch [9][1600/3665]	lr: 5.000e-05, eta: 1:46:05, time: 0.476, data_time: 0.015, memory: 5252, loss_cls: 0.2327, loss_bbox: 0.2568, loss: 0.4895
2022-11-03 11:47:07,184 - mmdet - INFO - Epoch [9][1650/3665]	lr: 5.000e-05, eta: 1:45:40, time: 0.480, data_time: 0.014, memory: 5252, loss_cls: 0.2365, loss_bbox: 0.2559, loss: 0.4924
2022-11-03 11:47:30,838 - mmdet - INFO - Epoch [9][1700/3665]	lr: 5.000e-05, eta: 1:45:15, time: 0.473, data_time: 0.014, memory: 5252, loss_cls: 0.2350, loss_bbox: 0.2597, loss: 0.4947
2022-11-03 11:47:54,876 - mmdet - INFO - Epoch [9][1750/3665]	lr: 5.000e-05, eta: 1:44:51, time: 0.481, data_time: 0.015, memory: 5252, loss_cls: 0.2351, loss_bbox: 0.2550, loss: 0.4900
2022-11-03 11:48:18,881 - mmdet - INFO - Epoch [9][1800/3665]	lr: 5.000e-05, eta: 1:44:26, time: 0.480, data_time: 0.014, memory: 5252, loss_cls: 0.2344, loss_bbox: 0.2583, loss: 0.4927
2022-11-03 11:48:42,352 - mmdet - INFO - Epoch [9][1850/3665]	lr: 5.000e-05, eta: 1:44:01, time: 0.469, data_time: 0.015, memory: 5252, loss_cls: 0.2345, loss_bbox: 0.2538, loss: 0.4883
2022-11-03 11:49:05,909 - mmdet - INFO - Epoch [9][1900/3665]	lr: 5.000e-05, eta: 1:43:37, time: 0.471, data_time: 0.015, memory: 5252, loss_cls: 0.2323, loss_bbox: 0.2567, loss: 0.4891
2022-11-03 11:49:29,648 - mmdet - INFO - Epoch [9][1950/3665]	lr: 5.000e-05, eta: 1:43:12, time: 0.475, data_time: 0.015, memory: 5252, loss_cls: 0.2399, loss_bbox: 0.2573, loss: 0.4971
2022-11-03 11:49:53,595 - mmdet - INFO - Epoch [9][2000/3665]	lr: 5.000e-05, eta: 1:42:47, time: 0.479, data_time: 0.015, memory: 5252, loss_cls: 0.2288, loss_bbox: 0.2506, loss: 0.4794
2022-11-03 11:50:17,458 - mmdet - INFO - Epoch [9][2050/3665]	lr: 5.000e-05, eta: 1:42:23, time: 0.477, data_time: 0.014, memory: 5252, loss_cls: 0.2315, loss_bbox: 0.2530, loss: 0.4845
2022-11-03 11:50:41,197 - mmdet - INFO - Epoch [9][2100/3665]	lr: 5.000e-05, eta: 1:41:58, time: 0.475, data_time: 0.015, memory: 5252, loss_cls: 0.2374, loss_bbox: 0.2511, loss: 0.4885
2022-11-03 11:51:04,757 - mmdet - INFO - Epoch [9][2150/3665]	lr: 5.000e-05, eta: 1:41:33, time: 0.471, data_time: 0.016, memory: 5252, loss_cls: 0.2301, loss_bbox: 0.2552, loss: 0.4853
2022-11-03 11:51:28,505 - mmdet - INFO - Epoch [9][2200/3665]	lr: 5.000e-05, eta: 1:41:09, time: 0.475, data_time: 0.017, memory: 5252, loss_cls: 0.2293, loss_bbox: 0.2508, loss: 0.4801
2022-11-03 11:51:52,440 - mmdet - INFO - Epoch [9][2250/3665]	lr: 5.000e-05, eta: 1:40:44, time: 0.479, data_time: 0.016, memory: 5252, loss_cls: 0.2343, loss_bbox: 0.2589, loss: 0.4932
2022-11-03 11:52:15,945 - mmdet - INFO - Epoch [9][2300/3665]	lr: 5.000e-05, eta: 1:40:19, time: 0.470, data_time: 0.015, memory: 5252, loss_cls: 0.2329, loss_bbox: 0.2552, loss: 0.4881
2022-11-03 11:52:39,594 - mmdet - INFO - Epoch [9][2350/3665]	lr: 5.000e-05, eta: 1:39:55, time: 0.473, data_time: 0.015, memory: 5252, loss_cls: 0.2353, loss_bbox: 0.2537, loss: 0.4890
2022-11-03 11:53:02,808 - mmdet - INFO - Epoch [9][2400/3665]	lr: 5.000e-05, eta: 1:39:30, time: 0.464, data_time: 0.016, memory: 5252, loss_cls: 0.2303, loss_bbox: 0.2495, loss: 0.4799
2022-11-03 11:53:27,456 - mmdet - INFO - Epoch [9][2450/3665]	lr: 5.000e-05, eta: 1:39:05, time: 0.493, data_time: 0.016, memory: 5252, loss_cls: 0.2332, loss_bbox: 0.2519, loss: 0.4852
2022-11-03 11:53:51,155 - mmdet - INFO - Epoch [9][2500/3665]	lr: 5.000e-05, eta: 1:38:41, time: 0.474, data_time: 0.016, memory: 5252, loss_cls: 0.2353, loss_bbox: 0.2569, loss: 0.4922
2022-11-03 11:54:15,197 - mmdet - INFO - Epoch [9][2550/3665]	lr: 5.000e-05, eta: 1:38:16, time: 0.481, data_time: 0.016, memory: 5252, loss_cls: 0.2344, loss_bbox: 0.2575, loss: 0.4919
2022-11-03 11:54:39,356 - mmdet - INFO - Epoch [9][2600/3665]	lr: 5.000e-05, eta: 1:37:52, time: 0.483, data_time: 0.016, memory: 5252, loss_cls: 0.2309, loss_bbox: 0.2543, loss: 0.4852
2022-11-03 11:55:03,461 - mmdet - INFO - Epoch [9][2650/3665]	lr: 5.000e-05, eta: 1:37:27, time: 0.482, data_time: 0.016, memory: 5252, loss_cls: 0.2288, loss_bbox: 0.2570, loss: 0.4858
2022-11-03 11:55:27,421 - mmdet - INFO - Epoch [9][2700/3665]	lr: 5.000e-05, eta: 1:37:03, time: 0.479, data_time: 0.016, memory: 5252, loss_cls: 0.2328, loss_bbox: 0.2528, loss: 0.4856
2022-11-03 11:55:51,900 - mmdet - INFO - Epoch [9][2750/3665]	lr: 5.000e-05, eta: 1:36:39, time: 0.489, data_time: 0.016, memory: 5252, loss_cls: 0.2380, loss_bbox: 0.2543, loss: 0.4924
2022-11-03 11:56:16,371 - mmdet - INFO - Epoch [9][2800/3665]	lr: 5.000e-05, eta: 1:36:14, time: 0.490, data_time: 0.016, memory: 5252, loss_cls: 0.2331, loss_bbox: 0.2533, loss: 0.4864
2022-11-03 11:56:40,884 - mmdet - INFO - Epoch [9][2850/3665]	lr: 5.000e-05, eta: 1:35:50, time: 0.490, data_time: 0.016, memory: 5252, loss_cls: 0.2373, loss_bbox: 0.2553, loss: 0.4926
2022-11-03 11:57:05,355 - mmdet - INFO - Epoch [9][2900/3665]	lr: 5.000e-05, eta: 1:35:26, time: 0.489, data_time: 0.015, memory: 5252, loss_cls: 0.2337, loss_bbox: 0.2563, loss: 0.4901
2022-11-03 11:57:28,782 - mmdet - INFO - Epoch [9][2950/3665]	lr: 5.000e-05, eta: 1:35:01, time: 0.468, data_time: 0.016, memory: 5252, loss_cls: 0.2348, loss_bbox: 0.2516, loss: 0.4864
2022-11-03 11:57:53,345 - mmdet - INFO - Epoch [9][3000/3665]	lr: 5.000e-05, eta: 1:34:37, time: 0.491, data_time: 0.016, memory: 5252, loss_cls: 0.2342, loss_bbox: 0.2526, loss: 0.4868
2022-11-03 11:58:17,852 - mmdet - INFO - Epoch [9][3050/3665]	lr: 5.000e-05, eta: 1:34:12, time: 0.490, data_time: 0.016, memory: 5252, loss_cls: 0.2358, loss_bbox: 0.2563, loss: 0.4920
2022-11-03 11:58:42,736 - mmdet - INFO - Epoch [9][3100/3665]	lr: 5.000e-05, eta: 1:33:48, time: 0.498, data_time: 0.016, memory: 5252, loss_cls: 0.2386, loss_bbox: 0.2582, loss: 0.4968
2022-11-03 11:59:06,449 - mmdet - INFO - Epoch [9][3150/3665]	lr: 5.000e-05, eta: 1:33:24, time: 0.474, data_time: 0.017, memory: 5252, loss_cls: 0.2360, loss_bbox: 0.2547, loss: 0.4907
2022-11-03 11:59:29,883 - mmdet - INFO - Epoch [9][3200/3665]	lr: 5.000e-05, eta: 1:32:59, time: 0.469, data_time: 0.015, memory: 5252, loss_cls: 0.2363, loss_bbox: 0.2574, loss: 0.4938
2022-11-03 11:59:54,585 - mmdet - INFO - Epoch [9][3250/3665]	lr: 5.000e-05, eta: 1:32:35, time: 0.494, data_time: 0.016, memory: 5252, loss_cls: 0.2391, loss_bbox: 0.2558, loss: 0.4948
2022-11-03 12:00:21,134 - mmdet - INFO - Epoch [9][3300/3665]	lr: 5.000e-05, eta: 1:32:11, time: 0.531, data_time: 0.015, memory: 5252, loss_cls: 0.2424, loss_bbox: 0.2584, loss: 0.5009
2022-11-03 12:00:46,056 - mmdet - INFO - Epoch [9][3350/3665]	lr: 5.000e-05, eta: 1:31:47, time: 0.498, data_time: 0.016, memory: 5252, loss_cls: 0.2319, loss_bbox: 0.2513, loss: 0.4832
2022-11-03 12:01:15,512 - mmdet - INFO - Epoch [9][3400/3665]	lr: 5.000e-05, eta: 1:31:25, time: 0.589, data_time: 0.129, memory: 5252, loss_cls: 0.2345, loss_bbox: 0.2528, loss: 0.4873
2022-11-03 12:01:39,617 - mmdet - INFO - Epoch [9][3450/3665]	lr: 5.000e-05, eta: 1:31:01, time: 0.482, data_time: 0.016, memory: 5252, loss_cls: 0.2375, loss_bbox: 0.2581, loss: 0.4956
2022-11-03 12:02:03,130 - mmdet - INFO - Epoch [9][3500/3665]	lr: 5.000e-05, eta: 1:30:36, time: 0.470, data_time: 0.015, memory: 5252, loss_cls: 0.2327, loss_bbox: 0.2556, loss: 0.4883
2022-11-03 12:02:27,099 - mmdet - INFO - Epoch [9][3550/3665]	lr: 5.000e-05, eta: 1:30:11, time: 0.479, data_time: 0.016, memory: 5252, loss_cls: 0.2329, loss_bbox: 0.2568, loss: 0.4897
2022-11-03 12:02:51,147 - mmdet - INFO - Epoch [9][3600/3665]	lr: 5.000e-05, eta: 1:29:47, time: 0.481, data_time: 0.016, memory: 5252, loss_cls: 0.2348, loss_bbox: 0.2552, loss: 0.4900
2022-11-03 12:03:15,606 - mmdet - INFO - Epoch [9][3650/3665]	lr: 5.000e-05, eta: 1:29:23, time: 0.489, data_time: 0.015, memory: 5252, loss_cls: 0.2270, loss_bbox: 0.2497, loss: 0.4767
2022-11-03 12:03:23,414 - mmdet - INFO - Saving checkpoint at 9 epochs
2022-11-03 12:04:15,571 - mmdet - INFO - Evaluating bbox...
2022-11-03 12:05:11,296 - mmdet - INFO - 
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.554
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.371
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.212
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.378
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.468
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.529
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.529
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.342
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.565
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.677

2022-11-03 12:05:12,249 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 12:05:12,249 - mmdet - INFO - Epoch(val) [9][625]	bbox_mAP: 0.3520, bbox_mAP_50: 0.5540, bbox_mAP_75: 0.3710, bbox_mAP_s: 0.2120, bbox_mAP_m: 0.3780, bbox_mAP_l: 0.4680, bbox_mAP_copypaste: 0.352 0.554 0.371 0.212 0.378 0.468
2022-11-03 12:05:38,773 - mmdet - INFO - Epoch [10][50/3665]	lr: 2.929e-05, eta: 1:28:49, time: 0.530, data_time: 0.074, memory: 5252, loss_cls: 0.2283, loss_bbox: 0.2509, loss: 0.4792
2022-11-03 12:06:02,293 - mmdet - INFO - Epoch [10][100/3665]	lr: 2.929e-05, eta: 1:28:24, time: 0.471, data_time: 0.017, memory: 5252, loss_cls: 0.2225, loss_bbox: 0.2445, loss: 0.4670
2022-11-03 12:06:17,127 - mmdet - INFO - Epoch [10][150/3665]	lr: 2.929e-05, eta: 1:27:56, time: 0.297, data_time: 0.019, memory: 5252, loss_cls: 0.2256, loss_bbox: 0.2488, loss: 0.4743
2022-11-03 12:06:32,510 - mmdet - INFO - Epoch [10][200/3665]	lr: 2.929e-05, eta: 1:27:28, time: 0.308, data_time: 0.016, memory: 5252, loss_cls: 0.2203, loss_bbox: 0.2455, loss: 0.4658
2022-11-03 12:06:47,826 - mmdet - INFO - Epoch [10][250/3665]	lr: 2.929e-05, eta: 1:27:00, time: 0.306, data_time: 0.017, memory: 5252, loss_cls: 0.2332, loss_bbox: 0.2546, loss: 0.4878
2022-11-03 12:07:03,123 - mmdet - INFO - Epoch [10][300/3665]	lr: 2.929e-05, eta: 1:26:32, time: 0.306, data_time: 0.017, memory: 5252, loss_cls: 0.2244, loss_bbox: 0.2497, loss: 0.4741
2022-11-03 12:07:20,997 - mmdet - INFO - Epoch [10][350/3665]	lr: 2.929e-05, eta: 1:26:05, time: 0.357, data_time: 0.031, memory: 5252, loss_cls: 0.2183, loss_bbox: 0.2482, loss: 0.4665
2022-11-03 12:07:57,765 - mmdet - INFO - Epoch [10][400/3665]	lr: 2.929e-05, eta: 1:25:46, time: 0.735, data_time: 0.017, memory: 5252, loss_cls: 0.2236, loss_bbox: 0.2517, loss: 0.4753
2022-11-03 12:08:35,849 - mmdet - INFO - Epoch [10][450/3665]	lr: 2.929e-05, eta: 1:25:27, time: 0.762, data_time: 0.017, memory: 5252, loss_cls: 0.2284, loss_bbox: 0.2500, loss: 0.4784
2022-11-03 12:09:08,284 - mmdet - INFO - Epoch [10][500/3665]	lr: 2.929e-05, eta: 1:25:06, time: 0.649, data_time: 0.017, memory: 5252, loss_cls: 0.2252, loss_bbox: 0.2488, loss: 0.4740
2022-11-03 12:09:33,179 - mmdet - INFO - Epoch [10][550/3665]	lr: 2.929e-05, eta: 1:24:42, time: 0.498, data_time: 0.019, memory: 5252, loss_cls: 0.2237, loss_bbox: 0.2482, loss: 0.4719
2022-11-03 12:09:57,660 - mmdet - INFO - Epoch [10][600/3665]	lr: 2.929e-05, eta: 1:24:17, time: 0.490, data_time: 0.019, memory: 5252, loss_cls: 0.2238, loss_bbox: 0.2460, loss: 0.4698
2022-11-03 12:10:21,890 - mmdet - INFO - Epoch [10][650/3665]	lr: 2.929e-05, eta: 1:23:53, time: 0.484, data_time: 0.018, memory: 5252, loss_cls: 0.2202, loss_bbox: 0.2443, loss: 0.4645
2022-11-03 12:10:46,027 - mmdet - INFO - Epoch [10][700/3665]	lr: 2.929e-05, eta: 1:23:29, time: 0.483, data_time: 0.018, memory: 5252, loss_cls: 0.2215, loss_bbox: 0.2432, loss: 0.4647
2022-11-03 12:11:09,733 - mmdet - INFO - Epoch [10][750/3665]	lr: 2.929e-05, eta: 1:23:04, time: 0.474, data_time: 0.018, memory: 5252, loss_cls: 0.2183, loss_bbox: 0.2425, loss: 0.4608
2022-11-03 12:11:33,932 - mmdet - INFO - Epoch [10][800/3665]	lr: 2.929e-05, eta: 1:22:40, time: 0.484, data_time: 0.018, memory: 5252, loss_cls: 0.2204, loss_bbox: 0.2462, loss: 0.4666
2022-11-03 12:11:57,273 - mmdet - INFO - Epoch [10][850/3665]	lr: 2.929e-05, eta: 1:22:15, time: 0.467, data_time: 0.018, memory: 5252, loss_cls: 0.2240, loss_bbox: 0.2500, loss: 0.4740
2022-11-03 12:12:22,477 - mmdet - INFO - Epoch [10][900/3665]	lr: 2.929e-05, eta: 1:21:51, time: 0.504, data_time: 0.017, memory: 5252, loss_cls: 0.2235, loss_bbox: 0.2441, loss: 0.4676
2022-11-03 12:12:47,792 - mmdet - INFO - Epoch [10][950/3665]	lr: 2.929e-05, eta: 1:21:27, time: 0.506, data_time: 0.019, memory: 5252, loss_cls: 0.2260, loss_bbox: 0.2473, loss: 0.4734
2022-11-03 12:13:11,575 - mmdet - INFO - Epoch [10][1000/3665]	lr: 2.929e-05, eta: 1:21:03, time: 0.476, data_time: 0.019, memory: 5252, loss_cls: 0.2218, loss_bbox: 0.2428, loss: 0.4646
2022-11-03 12:13:35,375 - mmdet - INFO - Epoch [10][1050/3665]	lr: 2.929e-05, eta: 1:20:38, time: 0.476, data_time: 0.018, memory: 5252, loss_cls: 0.2223, loss_bbox: 0.2472, loss: 0.4695
2022-11-03 12:13:59,273 - mmdet - INFO - Epoch [10][1100/3665]	lr: 2.929e-05, eta: 1:20:14, time: 0.478, data_time: 0.019, memory: 5252, loss_cls: 0.2212, loss_bbox: 0.2452, loss: 0.4665
2022-11-03 12:14:23,711 - mmdet - INFO - Epoch [10][1150/3665]	lr: 2.929e-05, eta: 1:19:49, time: 0.489, data_time: 0.019, memory: 5252, loss_cls: 0.2242, loss_bbox: 0.2472, loss: 0.4713
2022-11-03 12:14:48,012 - mmdet - INFO - Epoch [10][1200/3665]	lr: 2.929e-05, eta: 1:19:25, time: 0.486, data_time: 0.020, memory: 5252, loss_cls: 0.2242, loss_bbox: 0.2485, loss: 0.4727
2022-11-03 12:15:12,625 - mmdet - INFO - Epoch [10][1250/3665]	lr: 2.929e-05, eta: 1:19:01, time: 0.492, data_time: 0.019, memory: 5252, loss_cls: 0.2219, loss_bbox: 0.2474, loss: 0.4693
2022-11-03 12:15:36,388 - mmdet - INFO - Epoch [10][1300/3665]	lr: 2.929e-05, eta: 1:18:36, time: 0.475, data_time: 0.019, memory: 5252, loss_cls: 0.2237, loss_bbox: 0.2481, loss: 0.4717
2022-11-03 12:16:00,475 - mmdet - INFO - Epoch [10][1350/3665]	lr: 2.929e-05, eta: 1:18:12, time: 0.482, data_time: 0.019, memory: 5252, loss_cls: 0.2207, loss_bbox: 0.2455, loss: 0.4662
2022-11-03 12:16:24,789 - mmdet - INFO - Epoch [10][1400/3665]	lr: 2.929e-05, eta: 1:17:47, time: 0.486, data_time: 0.019, memory: 5252, loss_cls: 0.2255, loss_bbox: 0.2483, loss: 0.4738
2022-11-03 12:16:49,354 - mmdet - INFO - Epoch [10][1450/3665]	lr: 2.929e-05, eta: 1:17:23, time: 0.491, data_time: 0.019, memory: 5252, loss_cls: 0.2182, loss_bbox: 0.2461, loss: 0.4643
2022-11-03 12:17:13,671 - mmdet - INFO - Epoch [10][1500/3665]	lr: 2.929e-05, eta: 1:16:59, time: 0.487, data_time: 0.019, memory: 5252, loss_cls: 0.2229, loss_bbox: 0.2468, loss: 0.4696
2022-11-03 12:17:38,253 - mmdet - INFO - Epoch [10][1550/3665]	lr: 2.929e-05, eta: 1:16:35, time: 0.492, data_time: 0.020, memory: 5252, loss_cls: 0.2215, loss_bbox: 0.2467, loss: 0.4682
2022-11-03 12:18:02,455 - mmdet - INFO - Epoch [10][1600/3665]	lr: 2.929e-05, eta: 1:16:10, time: 0.484, data_time: 0.019, memory: 5252, loss_cls: 0.2254, loss_bbox: 0.2520, loss: 0.4774
2022-11-03 12:18:26,497 - mmdet - INFO - Epoch [10][1650/3665]	lr: 2.929e-05, eta: 1:15:46, time: 0.481, data_time: 0.018, memory: 5252, loss_cls: 0.2260, loss_bbox: 0.2488, loss: 0.4748
2022-11-03 12:18:50,162 - mmdet - INFO - Epoch [10][1700/3665]	lr: 2.929e-05, eta: 1:15:21, time: 0.473, data_time: 0.018, memory: 5252, loss_cls: 0.2277, loss_bbox: 0.2466, loss: 0.4744
2022-11-03 12:19:14,108 - mmdet - INFO - Epoch [10][1750/3665]	lr: 2.929e-05, eta: 1:14:57, time: 0.479, data_time: 0.019, memory: 5252, loss_cls: 0.2214, loss_bbox: 0.2434, loss: 0.4647
2022-11-03 12:19:38,005 - mmdet - INFO - Epoch [10][1800/3665]	lr: 2.929e-05, eta: 1:14:32, time: 0.478, data_time: 0.019, memory: 5252, loss_cls: 0.2193, loss_bbox: 0.2460, loss: 0.4653
2022-11-03 12:20:02,143 - mmdet - INFO - Epoch [10][1850/3665]	lr: 2.929e-05, eta: 1:14:08, time: 0.483, data_time: 0.020, memory: 5252, loss_cls: 0.2232, loss_bbox: 0.2464, loss: 0.4695
2022-11-03 12:20:26,825 - mmdet - INFO - Epoch [10][1900/3665]	lr: 2.929e-05, eta: 1:13:44, time: 0.493, data_time: 0.020, memory: 5252, loss_cls: 0.2233, loss_bbox: 0.2449, loss: 0.4682
2022-11-03 12:20:51,099 - mmdet - INFO - Epoch [10][1950/3665]	lr: 2.929e-05, eta: 1:13:19, time: 0.486, data_time: 0.019, memory: 5252, loss_cls: 0.2225, loss_bbox: 0.2446, loss: 0.4671
2022-11-03 12:21:15,609 - mmdet - INFO - Epoch [10][2000/3665]	lr: 2.929e-05, eta: 1:12:55, time: 0.490, data_time: 0.019, memory: 5252, loss_cls: 0.2209, loss_bbox: 0.2463, loss: 0.4672
2022-11-03 12:21:39,384 - mmdet - INFO - Epoch [10][2050/3665]	lr: 2.929e-05, eta: 1:12:31, time: 0.475, data_time: 0.019, memory: 5252, loss_cls: 0.2227, loss_bbox: 0.2494, loss: 0.4721
2022-11-03 12:22:04,265 - mmdet - INFO - Epoch [10][2100/3665]	lr: 2.929e-05, eta: 1:12:07, time: 0.498, data_time: 0.019, memory: 5252, loss_cls: 0.2255, loss_bbox: 0.2483, loss: 0.4738
2022-11-03 12:22:29,080 - mmdet - INFO - Epoch [10][2150/3665]	lr: 2.929e-05, eta: 1:11:42, time: 0.496, data_time: 0.018, memory: 5252, loss_cls: 0.2297, loss_bbox: 0.2522, loss: 0.4819
2022-11-03 12:22:53,658 - mmdet - INFO - Epoch [10][2200/3665]	lr: 2.929e-05, eta: 1:11:18, time: 0.491, data_time: 0.018, memory: 5252, loss_cls: 0.2259, loss_bbox: 0.2493, loss: 0.4752
2022-11-03 12:23:18,301 - mmdet - INFO - Epoch [10][2250/3665]	lr: 2.929e-05, eta: 1:10:54, time: 0.493, data_time: 0.018, memory: 5252, loss_cls: 0.2258, loss_bbox: 0.2475, loss: 0.4734
2022-11-03 12:23:42,969 - mmdet - INFO - Epoch [10][2300/3665]	lr: 2.929e-05, eta: 1:10:30, time: 0.493, data_time: 0.018, memory: 5252, loss_cls: 0.2276, loss_bbox: 0.2483, loss: 0.4759
2022-11-03 12:24:08,141 - mmdet - INFO - Epoch [10][2350/3665]	lr: 2.929e-05, eta: 1:10:06, time: 0.503, data_time: 0.017, memory: 5252, loss_cls: 0.2214, loss_bbox: 0.2485, loss: 0.4700
2022-11-03 12:24:32,731 - mmdet - INFO - Epoch [10][2400/3665]	lr: 2.929e-05, eta: 1:09:41, time: 0.492, data_time: 0.017, memory: 5252, loss_cls: 0.2254, loss_bbox: 0.2482, loss: 0.4736
2022-11-03 12:24:57,343 - mmdet - INFO - Epoch [10][2450/3665]	lr: 2.929e-05, eta: 1:09:17, time: 0.492, data_time: 0.018, memory: 5252, loss_cls: 0.2194, loss_bbox: 0.2418, loss: 0.4612
2022-11-03 12:25:22,131 - mmdet - INFO - Epoch [10][2500/3665]	lr: 2.929e-05, eta: 1:08:53, time: 0.496, data_time: 0.019, memory: 5252, loss_cls: 0.2253, loss_bbox: 0.2483, loss: 0.4735
2022-11-03 12:25:46,089 - mmdet - INFO - Epoch [10][2550/3665]	lr: 2.929e-05, eta: 1:08:29, time: 0.479, data_time: 0.018, memory: 5252, loss_cls: 0.2227, loss_bbox: 0.2432, loss: 0.4660
2022-11-03 12:26:10,331 - mmdet - INFO - Epoch [10][2600/3665]	lr: 2.929e-05, eta: 1:08:04, time: 0.485, data_time: 0.018, memory: 5252, loss_cls: 0.2236, loss_bbox: 0.2460, loss: 0.4696
2022-11-03 12:26:34,747 - mmdet - INFO - Epoch [10][2650/3665]	lr: 2.929e-05, eta: 1:07:40, time: 0.488, data_time: 0.018, memory: 5252, loss_cls: 0.2245, loss_bbox: 0.2472, loss: 0.4717
2022-11-03 12:26:59,768 - mmdet - INFO - Epoch [10][2700/3665]	lr: 2.929e-05, eta: 1:07:16, time: 0.501, data_time: 0.020, memory: 5252, loss_cls: 0.2187, loss_bbox: 0.2505, loss: 0.4692
2022-11-03 12:27:24,442 - mmdet - INFO - Epoch [10][2750/3665]	lr: 2.929e-05, eta: 1:06:51, time: 0.493, data_time: 0.019, memory: 5252, loss_cls: 0.2235, loss_bbox: 0.2483, loss: 0.4719
2022-11-03 12:27:48,486 - mmdet - INFO - Epoch [10][2800/3665]	lr: 2.929e-05, eta: 1:06:27, time: 0.481, data_time: 0.019, memory: 5252, loss_cls: 0.2239, loss_bbox: 0.2442, loss: 0.4681
2022-11-03 12:28:12,926 - mmdet - INFO - Epoch [10][2850/3665]	lr: 2.929e-05, eta: 1:06:03, time: 0.489, data_time: 0.019, memory: 5252, loss_cls: 0.2240, loss_bbox: 0.2475, loss: 0.4715
2022-11-03 12:28:37,544 - mmdet - INFO - Epoch [10][2900/3665]	lr: 2.929e-05, eta: 1:05:39, time: 0.492, data_time: 0.019, memory: 5252, loss_cls: 0.2314, loss_bbox: 0.2504, loss: 0.4818
2022-11-03 12:29:02,150 - mmdet - INFO - Epoch [10][2950/3665]	lr: 2.929e-05, eta: 1:05:14, time: 0.492, data_time: 0.019, memory: 5252, loss_cls: 0.2254, loss_bbox: 0.2526, loss: 0.4780
2022-11-03 12:29:26,110 - mmdet - INFO - Epoch [10][3000/3665]	lr: 2.929e-05, eta: 1:04:50, time: 0.479, data_time: 0.020, memory: 5252, loss_cls: 0.2250, loss_bbox: 0.2466, loss: 0.4716
2022-11-03 12:29:50,573 - mmdet - INFO - Epoch [10][3050/3665]	lr: 2.929e-05, eta: 1:04:26, time: 0.489, data_time: 0.018, memory: 5252, loss_cls: 0.2253, loss_bbox: 0.2492, loss: 0.4746
2022-11-03 12:30:14,965 - mmdet - INFO - Epoch [10][3100/3665]	lr: 2.929e-05, eta: 1:04:01, time: 0.488, data_time: 0.020, memory: 5252, loss_cls: 0.2262, loss_bbox: 0.2526, loss: 0.4787
2022-11-03 12:30:39,033 - mmdet - INFO - Epoch [10][3150/3665]	lr: 2.929e-05, eta: 1:03:37, time: 0.481, data_time: 0.019, memory: 5252, loss_cls: 0.2276, loss_bbox: 0.2467, loss: 0.4743
2022-11-03 12:31:03,476 - mmdet - INFO - Epoch [10][3200/3665]	lr: 2.929e-05, eta: 1:03:13, time: 0.489, data_time: 0.019, memory: 5252, loss_cls: 0.2211, loss_bbox: 0.2506, loss: 0.4717
2022-11-03 12:31:28,269 - mmdet - INFO - Epoch [10][3250/3665]	lr: 2.929e-05, eta: 1:02:48, time: 0.496, data_time: 0.019, memory: 5252, loss_cls: 0.2256, loss_bbox: 0.2489, loss: 0.4745
2022-11-03 12:31:52,439 - mmdet - INFO - Epoch [10][3300/3665]	lr: 2.929e-05, eta: 1:02:24, time: 0.483, data_time: 0.018, memory: 5252, loss_cls: 0.2289, loss_bbox: 0.2529, loss: 0.4818
2022-11-03 12:32:16,152 - mmdet - INFO - Epoch [10][3350/3665]	lr: 2.929e-05, eta: 1:01:59, time: 0.474, data_time: 0.018, memory: 5252, loss_cls: 0.2240, loss_bbox: 0.2455, loss: 0.4695
2022-11-03 12:32:39,995 - mmdet - INFO - Epoch [10][3400/3665]	lr: 2.929e-05, eta: 1:01:35, time: 0.477, data_time: 0.018, memory: 5252, loss_cls: 0.2212, loss_bbox: 0.2461, loss: 0.4673
2022-11-03 12:33:03,884 - mmdet - INFO - Epoch [10][3450/3665]	lr: 2.929e-05, eta: 1:01:11, time: 0.478, data_time: 0.017, memory: 5252, loss_cls: 0.2203, loss_bbox: 0.2454, loss: 0.4657
2022-11-03 12:33:27,972 - mmdet - INFO - Epoch [10][3500/3665]	lr: 2.929e-05, eta: 1:00:46, time: 0.482, data_time: 0.018, memory: 5252, loss_cls: 0.2214, loss_bbox: 0.2454, loss: 0.4668
2022-11-03 12:33:51,397 - mmdet - INFO - Epoch [10][3550/3665]	lr: 2.929e-05, eta: 1:00:22, time: 0.469, data_time: 0.019, memory: 5252, loss_cls: 0.2296, loss_bbox: 0.2540, loss: 0.4837
2022-11-03 12:34:15,258 - mmdet - INFO - Epoch [10][3600/3665]	lr: 2.929e-05, eta: 0:59:57, time: 0.477, data_time: 0.020, memory: 5252, loss_cls: 0.2240, loss_bbox: 0.2475, loss: 0.4715
2022-11-03 12:34:40,533 - mmdet - INFO - Epoch [10][3650/3665]	lr: 2.929e-05, eta: 0:59:33, time: 0.505, data_time: 0.019, memory: 5252, loss_cls: 0.2267, loss_bbox: 0.2514, loss: 0.4780
2022-11-03 12:34:48,261 - mmdet - INFO - Saving checkpoint at 10 epochs
2022-11-03 12:35:40,468 - mmdet - INFO - Evaluating bbox...
2022-11-03 12:36:35,048 - mmdet - INFO - 
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.560
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.375
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.210
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.385
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.478
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.531
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.531
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.346
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.564
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.677

2022-11-03 12:36:35,925 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 12:36:35,926 - mmdet - INFO - Epoch(val) [10][625]	bbox_mAP: 0.3570, bbox_mAP_50: 0.5600, bbox_mAP_75: 0.3750, bbox_mAP_s: 0.2100, bbox_mAP_m: 0.3850, bbox_mAP_l: 0.4780, bbox_mAP_copypaste: 0.357 0.560 0.375 0.210 0.385 0.478
2022-11-03 12:37:02,773 - mmdet - INFO - Epoch [11][50/3665]	lr: 1.340e-05, eta: 0:59:00, time: 0.537, data_time: 0.072, memory: 5252, loss_cls: 0.2129, loss_bbox: 0.2433, loss: 0.4562
2022-11-03 12:37:26,783 - mmdet - INFO - Epoch [11][100/3665]	lr: 1.340e-05, eta: 0:58:36, time: 0.480, data_time: 0.014, memory: 5252, loss_cls: 0.2112, loss_bbox: 0.2401, loss: 0.4512
2022-11-03 12:37:51,376 - mmdet - INFO - Epoch [11][150/3665]	lr: 1.340e-05, eta: 0:58:12, time: 0.492, data_time: 0.014, memory: 5252, loss_cls: 0.2192, loss_bbox: 0.2429, loss: 0.4621
2022-11-03 12:38:15,987 - mmdet - INFO - Epoch [11][200/3665]	lr: 1.340e-05, eta: 0:57:47, time: 0.492, data_time: 0.015, memory: 5252, loss_cls: 0.2159, loss_bbox: 0.2475, loss: 0.4634
2022-11-03 12:38:40,018 - mmdet - INFO - Epoch [11][250/3665]	lr: 1.340e-05, eta: 0:57:23, time: 0.481, data_time: 0.015, memory: 5252, loss_cls: 0.2151, loss_bbox: 0.2384, loss: 0.4535
2022-11-03 12:39:04,241 - mmdet - INFO - Epoch [11][300/3665]	lr: 1.340e-05, eta: 0:56:59, time: 0.484, data_time: 0.015, memory: 5252, loss_cls: 0.2128, loss_bbox: 0.2395, loss: 0.4524
2022-11-03 12:39:28,551 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 12:39:28,552 - mmdet - INFO - Epoch [11][350/3665]	lr: 1.340e-05, eta: 0:56:34, time: 0.486, data_time: 0.015, memory: 5252, loss_cls: 0.2145, loss_bbox: 0.2380, loss: 0.4525
2022-11-03 12:39:52,846 - mmdet - INFO - Epoch [11][400/3665]	lr: 1.340e-05, eta: 0:56:10, time: 0.486, data_time: 0.015, memory: 5252, loss_cls: 0.2187, loss_bbox: 0.2428, loss: 0.4615
2022-11-03 12:40:16,413 - mmdet - INFO - Epoch [11][450/3665]	lr: 1.340e-05, eta: 0:55:46, time: 0.471, data_time: 0.016, memory: 5252, loss_cls: 0.2189, loss_bbox: 0.2396, loss: 0.4585
2022-11-03 12:40:41,022 - mmdet - INFO - Epoch [11][500/3665]	lr: 1.340e-05, eta: 0:55:21, time: 0.492, data_time: 0.017, memory: 5252, loss_cls: 0.2177, loss_bbox: 0.2442, loss: 0.4619
2022-11-03 12:41:06,148 - mmdet - INFO - Epoch [11][550/3665]	lr: 1.340e-05, eta: 0:54:57, time: 0.503, data_time: 0.017, memory: 5252, loss_cls: 0.2164, loss_bbox: 0.2460, loss: 0.4623
2022-11-03 12:41:30,600 - mmdet - INFO - Epoch [11][600/3665]	lr: 1.340e-05, eta: 0:54:33, time: 0.489, data_time: 0.016, memory: 5252, loss_cls: 0.2168, loss_bbox: 0.2419, loss: 0.4588
2022-11-03 12:41:54,246 - mmdet - INFO - Epoch [11][650/3665]	lr: 1.340e-05, eta: 0:54:08, time: 0.473, data_time: 0.016, memory: 5252, loss_cls: 0.2228, loss_bbox: 0.2486, loss: 0.4713
2022-11-03 12:42:18,739 - mmdet - INFO - Epoch [11][700/3665]	lr: 1.340e-05, eta: 0:53:44, time: 0.490, data_time: 0.016, memory: 5252, loss_cls: 0.2154, loss_bbox: 0.2408, loss: 0.4562
2022-11-03 12:42:42,962 - mmdet - INFO - Epoch [11][750/3665]	lr: 1.340e-05, eta: 0:53:20, time: 0.485, data_time: 0.017, memory: 5252, loss_cls: 0.2093, loss_bbox: 0.2384, loss: 0.4477
2022-11-03 12:43:06,859 - mmdet - INFO - Epoch [11][800/3665]	lr: 1.340e-05, eta: 0:52:55, time: 0.478, data_time: 0.016, memory: 5252, loss_cls: 0.2147, loss_bbox: 0.2418, loss: 0.4566
2022-11-03 12:43:31,532 - mmdet - INFO - Epoch [11][850/3665]	lr: 1.340e-05, eta: 0:52:31, time: 0.493, data_time: 0.016, memory: 5252, loss_cls: 0.2148, loss_bbox: 0.2427, loss: 0.4575
2022-11-03 12:43:55,714 - mmdet - INFO - Epoch [11][900/3665]	lr: 1.340e-05, eta: 0:52:07, time: 0.484, data_time: 0.016, memory: 5252, loss_cls: 0.2225, loss_bbox: 0.2446, loss: 0.4671
2022-11-03 12:44:20,110 - mmdet - INFO - Epoch [11][950/3665]	lr: 1.340e-05, eta: 0:51:42, time: 0.488, data_time: 0.016, memory: 5252, loss_cls: 0.2211, loss_bbox: 0.2458, loss: 0.4669
2022-11-03 12:44:43,829 - mmdet - INFO - Epoch [11][1000/3665]	lr: 1.340e-05, eta: 0:51:18, time: 0.474, data_time: 0.016, memory: 5252, loss_cls: 0.2163, loss_bbox: 0.2425, loss: 0.4588
2022-11-03 12:45:07,887 - mmdet - INFO - Epoch [11][1050/3665]	lr: 1.340e-05, eta: 0:50:54, time: 0.481, data_time: 0.016, memory: 5252, loss_cls: 0.2153, loss_bbox: 0.2414, loss: 0.4567
2022-11-03 12:45:32,578 - mmdet - INFO - Epoch [11][1100/3665]	lr: 1.340e-05, eta: 0:50:29, time: 0.494, data_time: 0.015, memory: 5252, loss_cls: 0.2152, loss_bbox: 0.2417, loss: 0.4569
2022-11-03 12:45:56,389 - mmdet - INFO - Epoch [11][1150/3665]	lr: 1.340e-05, eta: 0:50:05, time: 0.476, data_time: 0.016, memory: 5252, loss_cls: 0.2164, loss_bbox: 0.2441, loss: 0.4605
2022-11-03 12:46:19,690 - mmdet - INFO - Epoch [11][1200/3665]	lr: 1.340e-05, eta: 0:49:40, time: 0.466, data_time: 0.015, memory: 5252, loss_cls: 0.2135, loss_bbox: 0.2414, loss: 0.4549
2022-11-03 12:46:43,310 - mmdet - INFO - Epoch [11][1250/3665]	lr: 1.340e-05, eta: 0:49:16, time: 0.473, data_time: 0.015, memory: 5252, loss_cls: 0.2163, loss_bbox: 0.2430, loss: 0.4594
2022-11-03 12:47:06,924 - mmdet - INFO - Epoch [11][1300/3665]	lr: 1.340e-05, eta: 0:48:52, time: 0.472, data_time: 0.016, memory: 5252, loss_cls: 0.2152, loss_bbox: 0.2418, loss: 0.4570
2022-11-03 12:47:31,032 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 12:47:31,032 - mmdet - INFO - Epoch [11][1350/3665]	lr: 1.340e-05, eta: 0:48:27, time: 0.482, data_time: 0.015, memory: 5252, loss_cls: 0.2182, loss_bbox: 0.2440, loss: 0.4622
2022-11-03 12:47:55,260 - mmdet - INFO - Epoch [11][1400/3665]	lr: 1.340e-05, eta: 0:48:03, time: 0.484, data_time: 0.015, memory: 5252, loss_cls: 0.2138, loss_bbox: 0.2418, loss: 0.4555
2022-11-03 12:48:19,244 - mmdet - INFO - Epoch [11][1450/3665]	lr: 1.340e-05, eta: 0:47:39, time: 0.480, data_time: 0.016, memory: 5252, loss_cls: 0.2157, loss_bbox: 0.2397, loss: 0.4553
2022-11-03 12:48:43,758 - mmdet - INFO - Epoch [11][1500/3665]	lr: 1.340e-05, eta: 0:47:14, time: 0.491, data_time: 0.015, memory: 5252, loss_cls: 0.2186, loss_bbox: 0.2418, loss: 0.4604
2022-11-03 12:49:07,988 - mmdet - INFO - Epoch [11][1550/3665]	lr: 1.340e-05, eta: 0:46:50, time: 0.485, data_time: 0.016, memory: 5252, loss_cls: 0.2181, loss_bbox: 0.2426, loss: 0.4607
2022-11-03 12:49:32,161 - mmdet - INFO - Epoch [11][1600/3665]	lr: 1.340e-05, eta: 0:46:26, time: 0.483, data_time: 0.015, memory: 5252, loss_cls: 0.2143, loss_bbox: 0.2399, loss: 0.4542
2022-11-03 12:49:56,174 - mmdet - INFO - Epoch [11][1650/3665]	lr: 1.340e-05, eta: 0:46:01, time: 0.480, data_time: 0.016, memory: 5252, loss_cls: 0.2221, loss_bbox: 0.2441, loss: 0.4662
2022-11-03 12:50:20,907 - mmdet - INFO - Epoch [11][1700/3665]	lr: 1.340e-05, eta: 0:45:37, time: 0.495, data_time: 0.015, memory: 5252, loss_cls: 0.2199, loss_bbox: 0.2446, loss: 0.4645
2022-11-03 12:50:45,208 - mmdet - INFO - Epoch [11][1750/3665]	lr: 1.340e-05, eta: 0:45:13, time: 0.486, data_time: 0.015, memory: 5252, loss_cls: 0.2175, loss_bbox: 0.2476, loss: 0.4651
2022-11-03 12:51:09,390 - mmdet - INFO - Epoch [11][1800/3665]	lr: 1.340e-05, eta: 0:44:48, time: 0.484, data_time: 0.015, memory: 5252, loss_cls: 0.2253, loss_bbox: 0.2479, loss: 0.4733
2022-11-03 12:51:33,628 - mmdet - INFO - Epoch [11][1850/3665]	lr: 1.340e-05, eta: 0:44:24, time: 0.485, data_time: 0.015, memory: 5252, loss_cls: 0.2151, loss_bbox: 0.2407, loss: 0.4558
2022-11-03 12:51:57,873 - mmdet - INFO - Epoch [11][1900/3665]	lr: 1.340e-05, eta: 0:44:00, time: 0.485, data_time: 0.015, memory: 5252, loss_cls: 0.2122, loss_bbox: 0.2373, loss: 0.4495
2022-11-03 12:52:21,901 - mmdet - INFO - Epoch [11][1950/3665]	lr: 1.340e-05, eta: 0:43:35, time: 0.481, data_time: 0.015, memory: 5252, loss_cls: 0.2130, loss_bbox: 0.2438, loss: 0.4568
2022-11-03 12:52:46,121 - mmdet - INFO - Epoch [11][2000/3665]	lr: 1.340e-05, eta: 0:43:11, time: 0.484, data_time: 0.016, memory: 5252, loss_cls: 0.2217, loss_bbox: 0.2473, loss: 0.4689
2022-11-03 12:53:10,043 - mmdet - INFO - Epoch [11][2050/3665]	lr: 1.340e-05, eta: 0:42:47, time: 0.478, data_time: 0.015, memory: 5252, loss_cls: 0.2207, loss_bbox: 0.2451, loss: 0.4659
2022-11-03 12:53:34,534 - mmdet - INFO - Epoch [11][2100/3665]	lr: 1.340e-05, eta: 0:42:22, time: 0.490, data_time: 0.016, memory: 5252, loss_cls: 0.2174, loss_bbox: 0.2445, loss: 0.4619
2022-11-03 12:53:57,773 - mmdet - INFO - Epoch [11][2150/3665]	lr: 1.340e-05, eta: 0:41:58, time: 0.465, data_time: 0.016, memory: 5252, loss_cls: 0.2108, loss_bbox: 0.2381, loss: 0.4490
2022-11-03 12:54:21,606 - mmdet - INFO - Epoch [11][2200/3665]	lr: 1.340e-05, eta: 0:41:33, time: 0.477, data_time: 0.015, memory: 5252, loss_cls: 0.2149, loss_bbox: 0.2423, loss: 0.4572
2022-11-03 12:54:45,174 - mmdet - INFO - Epoch [11][2250/3665]	lr: 1.340e-05, eta: 0:41:09, time: 0.471, data_time: 0.015, memory: 5252, loss_cls: 0.2154, loss_bbox: 0.2460, loss: 0.4614
2022-11-03 12:55:09,084 - mmdet - INFO - Epoch [11][2300/3665]	lr: 1.340e-05, eta: 0:40:45, time: 0.478, data_time: 0.016, memory: 5252, loss_cls: 0.2187, loss_bbox: 0.2442, loss: 0.4629
2022-11-03 12:55:33,587 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 12:55:33,588 - mmdet - INFO - Epoch [11][2350/3665]	lr: 1.340e-05, eta: 0:40:20, time: 0.490, data_time: 0.015, memory: 5252, loss_cls: 0.2145, loss_bbox: 0.2379, loss: 0.4524
2022-11-03 12:55:58,376 - mmdet - INFO - Epoch [11][2400/3665]	lr: 1.340e-05, eta: 0:39:56, time: 0.496, data_time: 0.016, memory: 5252, loss_cls: 0.2149, loss_bbox: 0.2395, loss: 0.4544
2022-11-03 12:56:22,104 - mmdet - INFO - Epoch [11][2450/3665]	lr: 1.340e-05, eta: 0:39:32, time: 0.475, data_time: 0.016, memory: 5252, loss_cls: 0.2134, loss_bbox: 0.2421, loss: 0.4556
2022-11-03 12:56:45,992 - mmdet - INFO - Epoch [11][2500/3665]	lr: 1.340e-05, eta: 0:39:07, time: 0.478, data_time: 0.016, memory: 5252, loss_cls: 0.2157, loss_bbox: 0.2447, loss: 0.4604
2022-11-03 12:57:09,842 - mmdet - INFO - Epoch [11][2550/3665]	lr: 1.340e-05, eta: 0:38:43, time: 0.477, data_time: 0.016, memory: 5252, loss_cls: 0.2164, loss_bbox: 0.2422, loss: 0.4586
2022-11-03 12:57:33,641 - mmdet - INFO - Epoch [11][2600/3665]	lr: 1.340e-05, eta: 0:38:19, time: 0.476, data_time: 0.016, memory: 5252, loss_cls: 0.2186, loss_bbox: 0.2413, loss: 0.4599
2022-11-03 12:57:57,544 - mmdet - INFO - Epoch [11][2650/3665]	lr: 1.340e-05, eta: 0:37:54, time: 0.478, data_time: 0.016, memory: 5252, loss_cls: 0.2130, loss_bbox: 0.2439, loss: 0.4569
2022-11-03 12:58:21,783 - mmdet - INFO - Epoch [11][2700/3665]	lr: 1.340e-05, eta: 0:37:30, time: 0.485, data_time: 0.016, memory: 5252, loss_cls: 0.2155, loss_bbox: 0.2442, loss: 0.4597
2022-11-03 12:58:45,877 - mmdet - INFO - Epoch [11][2750/3665]	lr: 1.340e-05, eta: 0:37:06, time: 0.482, data_time: 0.016, memory: 5252, loss_cls: 0.2172, loss_bbox: 0.2441, loss: 0.4612
2022-11-03 12:59:09,834 - mmdet - INFO - Epoch [11][2800/3665]	lr: 1.340e-05, eta: 0:36:41, time: 0.479, data_time: 0.016, memory: 5252, loss_cls: 0.2181, loss_bbox: 0.2454, loss: 0.4635
2022-11-03 12:59:34,516 - mmdet - INFO - Epoch [11][2850/3665]	lr: 1.340e-05, eta: 0:36:17, time: 0.493, data_time: 0.015, memory: 5252, loss_cls: 0.2222, loss_bbox: 0.2444, loss: 0.4666
2022-11-03 12:59:58,390 - mmdet - INFO - Epoch [11][2900/3665]	lr: 1.340e-05, eta: 0:35:53, time: 0.478, data_time: 0.015, memory: 5252, loss_cls: 0.2190, loss_bbox: 0.2439, loss: 0.4629
2022-11-03 13:00:18,354 - mmdet - INFO - Epoch [11][2950/3665]	lr: 1.340e-05, eta: 0:35:28, time: 0.399, data_time: 0.018, memory: 5252, loss_cls: 0.2192, loss_bbox: 0.2442, loss: 0.4634
2022-11-03 13:00:34,132 - mmdet - INFO - Epoch [11][3000/3665]	lr: 1.340e-05, eta: 0:35:02, time: 0.316, data_time: 0.014, memory: 5252, loss_cls: 0.2177, loss_bbox: 0.2462, loss: 0.4639
2022-11-03 13:00:49,891 - mmdet - INFO - Epoch [11][3050/3665]	lr: 1.340e-05, eta: 0:34:37, time: 0.315, data_time: 0.014, memory: 5252, loss_cls: 0.2169, loss_bbox: 0.2449, loss: 0.4618
2022-11-03 13:01:05,290 - mmdet - INFO - Epoch [11][3100/3665]	lr: 1.340e-05, eta: 0:34:12, time: 0.308, data_time: 0.014, memory: 5252, loss_cls: 0.2150, loss_bbox: 0.2401, loss: 0.4550
2022-11-03 13:01:20,996 - mmdet - INFO - Epoch [11][3150/3665]	lr: 1.340e-05, eta: 0:33:46, time: 0.314, data_time: 0.014, memory: 5252, loss_cls: 0.2148, loss_bbox: 0.2443, loss: 0.4591
2022-11-03 13:01:47,394 - mmdet - INFO - Epoch [11][3200/3665]	lr: 1.340e-05, eta: 0:33:22, time: 0.528, data_time: 0.017, memory: 5252, loss_cls: 0.2198, loss_bbox: 0.2520, loss: 0.4718
2022-11-03 13:02:25,492 - mmdet - INFO - Epoch [11][3250/3665]	lr: 1.340e-05, eta: 0:33:00, time: 0.762, data_time: 0.016, memory: 5252, loss_cls: 0.2217, loss_bbox: 0.2441, loss: 0.4658
2022-11-03 13:03:03,672 - mmdet - INFO - Epoch [11][3300/3665]	lr: 1.340e-05, eta: 0:32:37, time: 0.764, data_time: 0.016, memory: 5252, loss_cls: 0.2250, loss_bbox: 0.2479, loss: 0.4728
2022-11-03 13:03:34,508 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 13:03:34,508 - mmdet - INFO - Epoch [11][3350/3665]	lr: 1.340e-05, eta: 0:32:14, time: 0.617, data_time: 0.018, memory: 5252, loss_cls: 0.2206, loss_bbox: 0.2424, loss: 0.4630
2022-11-03 13:03:59,602 - mmdet - INFO - Epoch [11][3400/3665]	lr: 1.340e-05, eta: 0:31:49, time: 0.502, data_time: 0.018, memory: 5252, loss_cls: 0.2222, loss_bbox: 0.2455, loss: 0.4677
2022-11-03 13:04:25,019 - mmdet - INFO - Epoch [11][3450/3665]	lr: 1.340e-05, eta: 0:31:25, time: 0.508, data_time: 0.018, memory: 5252, loss_cls: 0.2136, loss_bbox: 0.2398, loss: 0.4534
2022-11-03 13:04:49,720 - mmdet - INFO - Epoch [11][3500/3665]	lr: 1.340e-05, eta: 0:31:01, time: 0.494, data_time: 0.017, memory: 5252, loss_cls: 0.2180, loss_bbox: 0.2480, loss: 0.4659
2022-11-03 13:05:14,043 - mmdet - INFO - Epoch [11][3550/3665]	lr: 1.340e-05, eta: 0:30:37, time: 0.487, data_time: 0.017, memory: 5252, loss_cls: 0.2152, loss_bbox: 0.2395, loss: 0.4548
2022-11-03 13:05:39,040 - mmdet - INFO - Epoch [11][3600/3665]	lr: 1.340e-05, eta: 0:30:12, time: 0.500, data_time: 0.018, memory: 5252, loss_cls: 0.2165, loss_bbox: 0.2410, loss: 0.4574
2022-11-03 13:06:04,501 - mmdet - INFO - Epoch [11][3650/3665]	lr: 1.340e-05, eta: 0:29:48, time: 0.510, data_time: 0.017, memory: 5252, loss_cls: 0.2191, loss_bbox: 0.2456, loss: 0.4647
2022-11-03 13:06:11,901 - mmdet - INFO - Saving checkpoint at 11 epochs
2022-11-03 13:07:04,000 - mmdet - INFO - Evaluating bbox...
2022-11-03 13:08:05,919 - mmdet - INFO - 
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.563
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.379
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.218
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.386
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.480
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.533
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.533
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.351
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.564
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.679

2022-11-03 13:08:06,980 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 13:08:06,980 - mmdet - INFO - Epoch(val) [11][625]	bbox_mAP: 0.3610, bbox_mAP_50: 0.5630, bbox_mAP_75: 0.3790, bbox_mAP_s: 0.2180, bbox_mAP_m: 0.3860, bbox_mAP_l: 0.4800, bbox_mAP_copypaste: 0.361 0.563 0.379 0.218 0.386 0.480
2022-11-03 13:08:35,701 - mmdet - INFO - Epoch [12][50/3665]	lr: 3.407e-06, eta: 0:29:16, time: 0.574, data_time: 0.076, memory: 5252, loss_cls: 0.2128, loss_bbox: 0.2378, loss: 0.4506
2022-11-03 13:09:00,794 - mmdet - INFO - Epoch [12][100/3665]	lr: 3.407e-06, eta: 0:28:52, time: 0.502, data_time: 0.014, memory: 5252, loss_cls: 0.2110, loss_bbox: 0.2372, loss: 0.4481
2022-11-03 13:09:26,429 - mmdet - INFO - Epoch [12][150/3665]	lr: 3.407e-06, eta: 0:28:28, time: 0.513, data_time: 0.014, memory: 5252, loss_cls: 0.2145, loss_bbox: 0.2389, loss: 0.4534
2022-11-03 13:09:52,016 - mmdet - INFO - Epoch [12][200/3665]	lr: 3.407e-06, eta: 0:28:04, time: 0.512, data_time: 0.013, memory: 5252, loss_cls: 0.2097, loss_bbox: 0.2329, loss: 0.4426
2022-11-03 13:10:17,584 - mmdet - INFO - Epoch [12][250/3665]	lr: 3.407e-06, eta: 0:27:40, time: 0.511, data_time: 0.014, memory: 5252, loss_cls: 0.2107, loss_bbox: 0.2379, loss: 0.4486
2022-11-03 13:10:42,446 - mmdet - INFO - Epoch [12][300/3665]	lr: 3.407e-06, eta: 0:27:15, time: 0.497, data_time: 0.013, memory: 5252, loss_cls: 0.2173, loss_bbox: 0.2410, loss: 0.4583
2022-11-03 13:11:08,042 - mmdet - INFO - Epoch [12][350/3665]	lr: 3.407e-06, eta: 0:26:51, time: 0.512, data_time: 0.013, memory: 5252, loss_cls: 0.2131, loss_bbox: 0.2406, loss: 0.4537
2022-11-03 13:11:32,907 - mmdet - INFO - Epoch [12][400/3665]	lr: 3.407e-06, eta: 0:26:27, time: 0.497, data_time: 0.013, memory: 5252, loss_cls: 0.2126, loss_bbox: 0.2408, loss: 0.4534
2022-11-03 13:11:57,462 - mmdet - INFO - Epoch [12][450/3665]	lr: 3.407e-06, eta: 0:26:03, time: 0.491, data_time: 0.013, memory: 5252, loss_cls: 0.2162, loss_bbox: 0.2433, loss: 0.4595
2022-11-03 13:12:22,302 - mmdet - INFO - Epoch [12][500/3665]	lr: 3.407e-06, eta: 0:25:38, time: 0.497, data_time: 0.014, memory: 5252, loss_cls: 0.2162, loss_bbox: 0.2407, loss: 0.4569
2022-11-03 13:12:47,477 - mmdet - INFO - Epoch [12][550/3665]	lr: 3.407e-06, eta: 0:25:14, time: 0.503, data_time: 0.013, memory: 5252, loss_cls: 0.2080, loss_bbox: 0.2390, loss: 0.4470
2022-11-03 13:13:12,448 - mmdet - INFO - Epoch [12][600/3665]	lr: 3.407e-06, eta: 0:24:50, time: 0.499, data_time: 0.014, memory: 5252, loss_cls: 0.2181, loss_bbox: 0.2438, loss: 0.4619
2022-11-03 13:13:37,625 - mmdet - INFO - Epoch [12][650/3665]	lr: 3.407e-06, eta: 0:24:26, time: 0.504, data_time: 0.014, memory: 5252, loss_cls: 0.2137, loss_bbox: 0.2428, loss: 0.4565
2022-11-03 13:14:02,525 - mmdet - INFO - Epoch [12][700/3665]	lr: 3.407e-06, eta: 0:24:01, time: 0.498, data_time: 0.013, memory: 5252, loss_cls: 0.2075, loss_bbox: 0.2372, loss: 0.4447
2022-11-03 13:14:27,645 - mmdet - INFO - Epoch [12][750/3665]	lr: 3.407e-06, eta: 0:23:37, time: 0.502, data_time: 0.014, memory: 5252, loss_cls: 0.2140, loss_bbox: 0.2402, loss: 0.4541
2022-11-03 13:14:53,970 - mmdet - INFO - Epoch [12][800/3665]	lr: 3.407e-06, eta: 0:23:13, time: 0.526, data_time: 0.013, memory: 5252, loss_cls: 0.2119, loss_bbox: 0.2425, loss: 0.4544
2022-11-03 13:15:19,130 - mmdet - INFO - Epoch [12][850/3665]	lr: 3.407e-06, eta: 0:22:49, time: 0.503, data_time: 0.016, memory: 5252, loss_cls: 0.2134, loss_bbox: 0.2423, loss: 0.4558
2022-11-03 13:15:44,125 - mmdet - INFO - Epoch [12][900/3665]	lr: 3.407e-06, eta: 0:22:25, time: 0.500, data_time: 0.018, memory: 5252, loss_cls: 0.2151, loss_bbox: 0.2406, loss: 0.4557
2022-11-03 13:16:09,423 - mmdet - INFO - Epoch [12][950/3665]	lr: 3.407e-06, eta: 0:22:00, time: 0.506, data_time: 0.018, memory: 5252, loss_cls: 0.2131, loss_bbox: 0.2362, loss: 0.4492
2022-11-03 13:16:35,505 - mmdet - INFO - Epoch [12][1000/3665]	lr: 3.407e-06, eta: 0:21:36, time: 0.522, data_time: 0.017, memory: 5252, loss_cls: 0.2097, loss_bbox: 0.2400, loss: 0.4497
2022-11-03 13:17:00,751 - mmdet - INFO - Epoch [12][1050/3665]	lr: 3.407e-06, eta: 0:21:12, time: 0.505, data_time: 0.017, memory: 5252, loss_cls: 0.2098, loss_bbox: 0.2351, loss: 0.4449
2022-11-03 13:17:26,071 - mmdet - INFO - Epoch [12][1100/3665]	lr: 3.407e-06, eta: 0:20:48, time: 0.506, data_time: 0.016, memory: 5252, loss_cls: 0.2091, loss_bbox: 0.2378, loss: 0.4468
2022-11-03 13:17:50,959 - mmdet - INFO - Epoch [12][1150/3665]	lr: 3.407e-06, eta: 0:20:23, time: 0.498, data_time: 0.016, memory: 5252, loss_cls: 0.2160, loss_bbox: 0.2437, loss: 0.4597
2022-11-03 13:18:15,838 - mmdet - INFO - Epoch [12][1200/3665]	lr: 3.407e-06, eta: 0:19:59, time: 0.498, data_time: 0.017, memory: 5252, loss_cls: 0.2036, loss_bbox: 0.2321, loss: 0.4357
2022-11-03 13:18:41,208 - mmdet - INFO - Epoch [12][1250/3665]	lr: 3.407e-06, eta: 0:19:35, time: 0.507, data_time: 0.017, memory: 5252, loss_cls: 0.2117, loss_bbox: 0.2388, loss: 0.4505
2022-11-03 13:19:06,989 - mmdet - INFO - Epoch [12][1300/3665]	lr: 3.407e-06, eta: 0:19:11, time: 0.516, data_time: 0.016, memory: 5252, loss_cls: 0.2092, loss_bbox: 0.2375, loss: 0.4468
2022-11-03 13:19:32,502 - mmdet - INFO - Epoch [12][1350/3665]	lr: 3.407e-06, eta: 0:18:46, time: 0.510, data_time: 0.017, memory: 5252, loss_cls: 0.2146, loss_bbox: 0.2420, loss: 0.4566
2022-11-03 13:19:57,718 - mmdet - INFO - Epoch [12][1400/3665]	lr: 3.407e-06, eta: 0:18:22, time: 0.504, data_time: 0.016, memory: 5252, loss_cls: 0.2067, loss_bbox: 0.2352, loss: 0.4419
2022-11-03 13:20:22,957 - mmdet - INFO - Epoch [12][1450/3665]	lr: 3.407e-06, eta: 0:17:58, time: 0.505, data_time: 0.017, memory: 5252, loss_cls: 0.2118, loss_bbox: 0.2415, loss: 0.4533
2022-11-03 13:20:48,066 - mmdet - INFO - Epoch [12][1500/3665]	lr: 3.407e-06, eta: 0:17:33, time: 0.502, data_time: 0.017, memory: 5252, loss_cls: 0.2120, loss_bbox: 0.2370, loss: 0.4490
2022-11-03 13:21:13,015 - mmdet - INFO - Epoch [12][1550/3665]	lr: 3.407e-06, eta: 0:17:09, time: 0.499, data_time: 0.017, memory: 5252, loss_cls: 0.2108, loss_bbox: 0.2423, loss: 0.4531
2022-11-03 13:21:38,090 - mmdet - INFO - Epoch [12][1600/3665]	lr: 3.407e-06, eta: 0:16:45, time: 0.502, data_time: 0.017, memory: 5252, loss_cls: 0.2135, loss_bbox: 0.2429, loss: 0.4563
2022-11-03 13:22:03,153 - mmdet - INFO - Epoch [12][1650/3665]	lr: 3.407e-06, eta: 0:16:21, time: 0.501, data_time: 0.017, memory: 5252, loss_cls: 0.2128, loss_bbox: 0.2435, loss: 0.4564
2022-11-03 13:22:28,496 - mmdet - INFO - Epoch [12][1700/3665]	lr: 3.407e-06, eta: 0:15:56, time: 0.507, data_time: 0.016, memory: 5252, loss_cls: 0.2125, loss_bbox: 0.2405, loss: 0.4530
2022-11-03 13:22:53,706 - mmdet - INFO - Epoch [12][1750/3665]	lr: 3.407e-06, eta: 0:15:32, time: 0.504, data_time: 0.016, memory: 5252, loss_cls: 0.2115, loss_bbox: 0.2361, loss: 0.4476
2022-11-03 13:23:18,981 - mmdet - INFO - Epoch [12][1800/3665]	lr: 3.407e-06, eta: 0:15:08, time: 0.506, data_time: 0.016, memory: 5252, loss_cls: 0.2116, loss_bbox: 0.2400, loss: 0.4517
2022-11-03 13:23:44,261 - mmdet - INFO - Epoch [12][1850/3665]	lr: 3.407e-06, eta: 0:14:43, time: 0.505, data_time: 0.017, memory: 5252, loss_cls: 0.2129, loss_bbox: 0.2389, loss: 0.4518
2022-11-03 13:24:08,838 - mmdet - INFO - Epoch [12][1900/3665]	lr: 3.407e-06, eta: 0:14:19, time: 0.492, data_time: 0.016, memory: 5252, loss_cls: 0.2150, loss_bbox: 0.2403, loss: 0.4552
2022-11-03 13:24:33,655 - mmdet - INFO - Epoch [12][1950/3665]	lr: 3.407e-06, eta: 0:13:55, time: 0.496, data_time: 0.017, memory: 5252, loss_cls: 0.2076, loss_bbox: 0.2402, loss: 0.4477
2022-11-03 13:24:57,922 - mmdet - INFO - Epoch [12][2000/3665]	lr: 3.407e-06, eta: 0:13:30, time: 0.485, data_time: 0.016, memory: 5252, loss_cls: 0.2082, loss_bbox: 0.2369, loss: 0.4451
2022-11-03 13:25:23,695 - mmdet - INFO - Epoch [12][2050/3665]	lr: 3.407e-06, eta: 0:13:06, time: 0.515, data_time: 0.017, memory: 5252, loss_cls: 0.2096, loss_bbox: 0.2392, loss: 0.4487
2022-11-03 13:25:48,539 - mmdet - INFO - Epoch [12][2100/3665]	lr: 3.407e-06, eta: 0:12:42, time: 0.497, data_time: 0.017, memory: 5252, loss_cls: 0.2146, loss_bbox: 0.2434, loss: 0.4580
2022-11-03 13:26:13,661 - mmdet - INFO - Epoch [12][2150/3665]	lr: 3.407e-06, eta: 0:12:17, time: 0.502, data_time: 0.017, memory: 5252, loss_cls: 0.2138, loss_bbox: 0.2430, loss: 0.4568
2022-11-03 13:26:38,997 - mmdet - INFO - Epoch [12][2200/3665]	lr: 3.407e-06, eta: 0:11:53, time: 0.507, data_time: 0.017, memory: 5252, loss_cls: 0.2188, loss_bbox: 0.2425, loss: 0.4613
2022-11-03 13:27:03,312 - mmdet - INFO - Epoch [12][2250/3665]	lr: 3.407e-06, eta: 0:11:29, time: 0.486, data_time: 0.017, memory: 5252, loss_cls: 0.2124, loss_bbox: 0.2399, loss: 0.4523
2022-11-03 13:27:28,574 - mmdet - INFO - Epoch [12][2300/3665]	lr: 3.407e-06, eta: 0:11:04, time: 0.505, data_time: 0.018, memory: 5252, loss_cls: 0.2106, loss_bbox: 0.2398, loss: 0.4503
2022-11-03 13:27:53,876 - mmdet - INFO - Epoch [12][2350/3665]	lr: 3.407e-06, eta: 0:10:40, time: 0.506, data_time: 0.017, memory: 5252, loss_cls: 0.2130, loss_bbox: 0.2417, loss: 0.4548
2022-11-03 13:28:19,399 - mmdet - INFO - Epoch [12][2400/3665]	lr: 3.407e-06, eta: 0:10:16, time: 0.510, data_time: 0.019, memory: 5252, loss_cls: 0.2120, loss_bbox: 0.2377, loss: 0.4497
2022-11-03 13:28:45,524 - mmdet - INFO - Epoch [12][2450/3665]	lr: 3.407e-06, eta: 0:09:51, time: 0.523, data_time: 0.019, memory: 5252, loss_cls: 0.2133, loss_bbox: 0.2416, loss: 0.4549
2022-11-03 13:29:11,102 - mmdet - INFO - Epoch [12][2500/3665]	lr: 3.407e-06, eta: 0:09:27, time: 0.511, data_time: 0.019, memory: 5252, loss_cls: 0.2164, loss_bbox: 0.2409, loss: 0.4573
2022-11-03 13:29:36,439 - mmdet - INFO - Epoch [12][2550/3665]	lr: 3.407e-06, eta: 0:09:03, time: 0.507, data_time: 0.019, memory: 5252, loss_cls: 0.2082, loss_bbox: 0.2388, loss: 0.4470
2022-11-03 13:30:01,695 - mmdet - INFO - Epoch [12][2600/3665]	lr: 3.407e-06, eta: 0:08:38, time: 0.505, data_time: 0.018, memory: 5252, loss_cls: 0.2064, loss_bbox: 0.2382, loss: 0.4446
2022-11-03 13:30:26,651 - mmdet - INFO - Epoch [12][2650/3665]	lr: 3.407e-06, eta: 0:08:14, time: 0.499, data_time: 0.020, memory: 5252, loss_cls: 0.2102, loss_bbox: 0.2380, loss: 0.4482
2022-11-03 13:30:51,958 - mmdet - INFO - Epoch [12][2700/3665]	lr: 3.407e-06, eta: 0:07:50, time: 0.506, data_time: 0.019, memory: 5252, loss_cls: 0.2103, loss_bbox: 0.2368, loss: 0.4471
2022-11-03 13:31:17,080 - mmdet - INFO - Epoch [12][2750/3665]	lr: 3.407e-06, eta: 0:07:25, time: 0.502, data_time: 0.018, memory: 5252, loss_cls: 0.2133, loss_bbox: 0.2395, loss: 0.4528
2022-11-03 13:31:41,741 - mmdet - INFO - Epoch [12][2800/3665]	lr: 3.407e-06, eta: 0:07:01, time: 0.493, data_time: 0.019, memory: 5252, loss_cls: 0.2151, loss_bbox: 0.2417, loss: 0.4568
2022-11-03 13:32:07,461 - mmdet - INFO - Epoch [12][2850/3665]	lr: 3.407e-06, eta: 0:06:37, time: 0.514, data_time: 0.018, memory: 5252, loss_cls: 0.2127, loss_bbox: 0.2397, loss: 0.4524
2022-11-03 13:32:32,323 - mmdet - INFO - Epoch [12][2900/3665]	lr: 3.407e-06, eta: 0:06:12, time: 0.497, data_time: 0.018, memory: 5252, loss_cls: 0.2191, loss_bbox: 0.2476, loss: 0.4668
2022-11-03 13:32:57,111 - mmdet - INFO - Epoch [12][2950/3665]	lr: 3.407e-06, eta: 0:05:48, time: 0.496, data_time: 0.017, memory: 5252, loss_cls: 0.2142, loss_bbox: 0.2406, loss: 0.4548
2022-11-03 13:33:22,637 - mmdet - INFO - Epoch [12][3000/3665]	lr: 3.407e-06, eta: 0:05:24, time: 0.511, data_time: 0.017, memory: 5252, loss_cls: 0.2094, loss_bbox: 0.2378, loss: 0.4471
2022-11-03 13:33:47,087 - mmdet - INFO - Epoch [12][3050/3665]	lr: 3.407e-06, eta: 0:04:59, time: 0.489, data_time: 0.017, memory: 5252, loss_cls: 0.2138, loss_bbox: 0.2417, loss: 0.4556
2022-11-03 13:34:12,875 - mmdet - INFO - Epoch [12][3100/3665]	lr: 3.407e-06, eta: 0:04:35, time: 0.516, data_time: 0.017, memory: 5252, loss_cls: 0.2153, loss_bbox: 0.2398, loss: 0.4550
2022-11-03 13:34:38,535 - mmdet - INFO - Epoch [12][3150/3665]	lr: 3.407e-06, eta: 0:04:11, time: 0.513, data_time: 0.018, memory: 5252, loss_cls: 0.2101, loss_bbox: 0.2415, loss: 0.4517
2022-11-03 13:35:04,033 - mmdet - INFO - Epoch [12][3200/3665]	lr: 3.407e-06, eta: 0:03:46, time: 0.510, data_time: 0.018, memory: 5252, loss_cls: 0.2168, loss_bbox: 0.2432, loss: 0.4600
2022-11-03 13:35:29,471 - mmdet - INFO - Epoch [12][3250/3665]	lr: 3.407e-06, eta: 0:03:22, time: 0.509, data_time: 0.018, memory: 5252, loss_cls: 0.2182, loss_bbox: 0.2434, loss: 0.4616
2022-11-03 13:35:55,311 - mmdet - INFO - Epoch [12][3300/3665]	lr: 3.407e-06, eta: 0:02:57, time: 0.517, data_time: 0.018, memory: 5252, loss_cls: 0.2149, loss_bbox: 0.2418, loss: 0.4567
2022-11-03 13:36:20,197 - mmdet - INFO - Epoch [12][3350/3665]	lr: 3.407e-06, eta: 0:02:33, time: 0.498, data_time: 0.018, memory: 5252, loss_cls: 0.2162, loss_bbox: 0.2394, loss: 0.4556
2022-11-03 13:36:45,256 - mmdet - INFO - Epoch [12][3400/3665]	lr: 3.407e-06, eta: 0:02:09, time: 0.501, data_time: 0.019, memory: 5252, loss_cls: 0.2124, loss_bbox: 0.2403, loss: 0.4527
2022-11-03 13:37:10,634 - mmdet - INFO - Epoch [12][3450/3665]	lr: 3.407e-06, eta: 0:01:44, time: 0.508, data_time: 0.018, memory: 5252, loss_cls: 0.2104, loss_bbox: 0.2386, loss: 0.4491
2022-11-03 13:37:35,920 - mmdet - INFO - Epoch [12][3500/3665]	lr: 3.407e-06, eta: 0:01:20, time: 0.506, data_time: 0.018, memory: 5252, loss_cls: 0.2151, loss_bbox: 0.2395, loss: 0.4546
2022-11-03 13:38:00,563 - mmdet - INFO - Epoch [12][3550/3665]	lr: 3.407e-06, eta: 0:00:56, time: 0.493, data_time: 0.017, memory: 5252, loss_cls: 0.2100, loss_bbox: 0.2359, loss: 0.4459
2022-11-03 13:38:25,315 - mmdet - INFO - Epoch [12][3600/3665]	lr: 3.407e-06, eta: 0:00:31, time: 0.495, data_time: 0.018, memory: 5252, loss_cls: 0.2171, loss_bbox: 0.2406, loss: 0.4578
2022-11-03 13:38:50,070 - mmdet - INFO - Epoch [12][3650/3665]	lr: 3.407e-06, eta: 0:00:07, time: 0.495, data_time: 0.017, memory: 5252, loss_cls: 0.2159, loss_bbox: 0.2417, loss: 0.4575
2022-11-03 13:38:58,023 - mmdet - INFO - Saving checkpoint at 12 epochs
2022-11-03 13:39:51,884 - mmdet - INFO - Evaluating bbox...
2022-11-03 13:40:52,608 - mmdet - INFO - 
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.566
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.381
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.217
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.388
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.481
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.535
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.535
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.354
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.565
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.683

2022-11-03 13:40:53,648 - mmdet - INFO - Exp name: retinanet_metamobile2M_fpn_1x_coco.py
2022-11-03 13:40:53,649 - mmdet - INFO - Epoch(val) [12][625]	bbox_mAP: 0.3620, bbox_mAP_50: 0.5660, bbox_mAP_75: 0.3810, bbox_mAP_s: 0.2170, bbox_mAP_m: 0.3880, bbox_mAP_l: 0.4810, bbox_mAP_copypaste: 0.362 0.566 0.381 0.217 0.388 0.481

